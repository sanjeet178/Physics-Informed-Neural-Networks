{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad57b21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1100, 1])) that is different to the input size (torch.Size([1100, 1100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1100, 1])) that is different to the input size (torch.Size([1100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 , loss =  6.351631\n",
      "eq1_loss =  6.4749303e-15\n",
      "ic1_loss =  0.041210253\n",
      "bc1_loss =  0.7845181\n",
      "bc2_loss =  5.4372864\n",
      "eq2_loss =  0.0011743663\n",
      "eq3_loss =  0.0013401903\n",
      "ic2_loss =  0.08610161\n",
      "epoch =  1000 , loss =  0.51221967\n",
      "eq1_loss =  0.00043244456\n",
      "ic1_loss =  0.25031537\n",
      "bc1_loss =  0.1634073\n",
      "bc2_loss =  0.098015174\n",
      "eq2_loss =  1.5454164e-06\n",
      "eq3_loss =  4.0576073e-05\n",
      "ic2_loss =  7.2271882e-06\n",
      "epoch =  2000 , loss =  0.47275153\n",
      "eq1_loss =  0.00019558385\n",
      "ic1_loss =  0.31139567\n",
      "bc1_loss =  0.1419041\n",
      "bc2_loss =  0.019125845\n",
      "eq2_loss =  4.680496e-06\n",
      "eq3_loss =  6.929255e-05\n",
      "ic2_loss =  5.6356632e-05\n",
      "epoch =  3000 , loss =  0.4699215\n",
      "eq1_loss =  0.00011734306\n",
      "ic1_loss =  0.3082314\n",
      "bc1_loss =  0.14322047\n",
      "bc2_loss =  0.018116454\n",
      "eq2_loss =  1.0791158e-05\n",
      "eq3_loss =  7.959743e-05\n",
      "ic2_loss =  0.00014542844\n",
      "epoch =  4000 , loss =  0.4658275\n",
      "eq1_loss =  5.8993148e-05\n",
      "ic1_loss =  0.30302605\n",
      "bc1_loss =  0.14505793\n",
      "bc2_loss =  0.0170503\n",
      "eq2_loss =  3.585665e-05\n",
      "eq3_loss =  0.0001578503\n",
      "ic2_loss =  0.00044052192\n",
      "epoch =  5000 , loss =  0.45806402\n",
      "eq1_loss =  1.5322794e-05\n",
      "ic1_loss =  0.29312247\n",
      "bc1_loss =  0.14656077\n",
      "bc2_loss =  0.016018959\n",
      "eq2_loss =  0.0001747492\n",
      "eq3_loss =  0.00049978046\n",
      "ic2_loss =  0.0016719738\n",
      "epoch =  6000 , loss =  0.43194047\n",
      "eq1_loss =  2.3092424e-07\n",
      "ic1_loss =  0.25822285\n",
      "bc1_loss =  0.14627342\n",
      "bc2_loss =  0.0120172715\n",
      "eq2_loss =  0.0012273013\n",
      "eq3_loss =  0.0040418818\n",
      "ic2_loss =  0.010157547\n",
      "epoch =  7000 , loss =  0.40157396\n",
      "eq1_loss =  5.824072e-08\n",
      "ic1_loss =  0.21379624\n",
      "bc1_loss =  0.15624161\n",
      "bc2_loss =  0.0054573277\n",
      "eq2_loss =  0.0012345026\n",
      "eq3_loss =  0.006347888\n",
      "ic2_loss =  0.018496305\n",
      "epoch =  8000 , loss =  0.390123\n",
      "eq1_loss =  9.5247394e-08\n",
      "ic1_loss =  0.20669064\n",
      "bc1_loss =  0.1577213\n",
      "bc2_loss =  0.0034228875\n",
      "eq2_loss =  0.0013593809\n",
      "eq3_loss =  0.003217692\n",
      "ic2_loss =  0.017711002\n",
      "epoch =  9000 , loss =  0.38587165\n",
      "eq1_loss =  7.585196e-08\n",
      "ic1_loss =  0.20360094\n",
      "bc1_loss =  0.15889958\n",
      "bc2_loss =  0.0028361343\n",
      "eq2_loss =  0.0015142742\n",
      "eq3_loss =  0.0019540042\n",
      "ic2_loss =  0.017066654\n",
      "epoch =  10000 , loss =  0.3827989\n",
      "eq1_loss =  4.7366534e-08\n",
      "ic1_loss =  0.20081167\n",
      "bc1_loss =  0.16020212\n",
      "bc2_loss =  0.002500788\n",
      "eq2_loss =  0.0016116399\n",
      "eq3_loss =  0.0011390969\n",
      "ic2_loss =  0.016533546\n",
      "epoch =  11000 , loss =  0.37984702\n",
      "eq1_loss =  1.917622e-08\n",
      "ic1_loss =  0.19768779\n",
      "bc1_loss =  0.16151915\n",
      "bc2_loss =  0.0022237748\n",
      "eq2_loss =  0.0016487236\n",
      "eq3_loss =  0.0007458627\n",
      "ic2_loss =  0.016021704\n",
      "epoch =  12000 , loss =  0.37704435\n",
      "eq1_loss =  1.5853346e-09\n",
      "ic1_loss =  0.19429937\n",
      "bc1_loss =  0.16269952\n",
      "bc2_loss =  0.002048581\n",
      "eq2_loss =  0.0015418285\n",
      "eq3_loss =  0.0008910247\n",
      "ic2_loss =  0.01556403\n",
      "epoch =  13000 , loss =  0.37450376\n",
      "eq1_loss =  6.743153e-10\n",
      "ic1_loss =  0.1922208\n",
      "bc1_loss =  0.16344573\n",
      "bc2_loss =  0.0020138698\n",
      "eq2_loss =  0.0013294836\n",
      "eq3_loss =  0.0007256785\n",
      "ic2_loss =  0.014768179\n",
      "epoch =  14000 , loss =  0.37239188\n",
      "eq1_loss =  6.297068e-09\n",
      "ic1_loss =  0.19183713\n",
      "bc1_loss =  0.16395955\n",
      "bc2_loss =  0.0019052827\n",
      "eq2_loss =  0.0011198494\n",
      "eq3_loss =  0.00015687283\n",
      "ic2_loss =  0.0134132\n",
      "epoch =  15000 , loss =  0.37190145\n",
      "eq1_loss =  5.280345e-08\n",
      "ic1_loss =  0.1910857\n",
      "bc1_loss =  0.1648129\n",
      "bc2_loss =  0.0019403624\n",
      "eq2_loss =  0.0010520495\n",
      "eq3_loss =  0.00010698353\n",
      "ic2_loss =  0.012903389\n",
      "epoch =  16000 , loss =  0.37161875\n",
      "eq1_loss =  1.5808416e-07\n",
      "ic1_loss =  0.18990043\n",
      "bc1_loss =  0.16579784\n",
      "bc2_loss =  0.0019009479\n",
      "eq2_loss =  0.0010469602\n",
      "eq3_loss =  0.00012456684\n",
      "ic2_loss =  0.012847848\n",
      "epoch =  17000 , loss =  0.37135696\n",
      "eq1_loss =  3.2150336e-07\n",
      "ic1_loss =  0.18868116\n",
      "bc1_loss =  0.16678563\n",
      "bc2_loss =  0.0018974858\n",
      "eq2_loss =  0.0010466303\n",
      "eq3_loss =  0.00013869576\n",
      "ic2_loss =  0.012807032\n",
      "epoch =  18000 , loss =  0.37107465\n",
      "eq1_loss =  5.786578e-07\n",
      "ic1_loss =  0.18746018\n",
      "bc1_loss =  0.16775617\n",
      "bc2_loss =  0.0018913327\n",
      "eq2_loss =  0.0010508725\n",
      "eq3_loss =  0.00014911467\n",
      "ic2_loss =  0.012766418\n",
      "epoch =  19000 , loss =  0.37073058\n",
      "eq1_loss =  9.835521e-07\n",
      "ic1_loss =  0.18628728\n",
      "bc1_loss =  0.16863398\n",
      "bc2_loss =  0.0018801368\n",
      "eq2_loss =  0.0010574306\n",
      "eq3_loss =  0.00016659749\n",
      "ic2_loss =  0.012704174\n",
      "epoch =  20000 , loss =  0.37021944\n",
      "eq1_loss =  1.607961e-06\n",
      "ic1_loss =  0.18525079\n",
      "bc1_loss =  0.16926447\n",
      "bc2_loss =  0.0018701917\n",
      "eq2_loss =  0.0010636812\n",
      "eq3_loss =  0.0001882043\n",
      "ic2_loss =  0.012580521\n",
      "epoch =  21000 , loss =  0.3693711\n",
      "eq1_loss =  2.4881158e-06\n",
      "ic1_loss =  0.18446384\n",
      "bc1_loss =  0.16944931\n",
      "bc2_loss =  0.0018868879\n",
      "eq2_loss =  0.001061013\n",
      "eq3_loss =  0.00018386495\n",
      "ic2_loss =  0.01232368\n",
      "epoch =  22000 , loss =  0.36853993\n",
      "eq1_loss =  3.5705007e-06\n",
      "ic1_loss =  0.18380931\n",
      "bc1_loss =  0.16945805\n",
      "bc2_loss =  0.0018973622\n",
      "eq2_loss =  0.0010588119\n",
      "eq3_loss =  0.00024990964\n",
      "ic2_loss =  0.012062894\n",
      "epoch =  23000 , loss =  0.3679324\n",
      "eq1_loss =  4.422915e-06\n",
      "ic1_loss =  0.1831561\n",
      "bc1_loss =  0.1695164\n",
      "bc2_loss =  0.0019174984\n",
      "eq2_loss =  0.0010511902\n",
      "eq3_loss =  0.0003260073\n",
      "ic2_loss =  0.011960814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16016/1312859499.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mic1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mT_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mT_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0mbc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mx_l\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mleft_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mbc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mTs1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmelt_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mTs2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmelt_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0meq2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdsdt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdTs1dx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdTs2dx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mic2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw6\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt_i\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0ms_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnull\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3111\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.regression import LogCoshError\n",
    "\n",
    "# Iterations v/s Loss Storage\n",
    "iters = [0]\n",
    "loss_store = []\n",
    "\n",
    "# Boundary Conditions \n",
    "left_temp = 1\n",
    "right_temp = 0\n",
    "melt_temp = 0.5\n",
    "x_l = 0\n",
    "x_r = 0.3\n",
    "t_i = 0\n",
    "t_f = 1\n",
    "s_i = 0.0001\n",
    "T_i = 0\n",
    "\n",
    "# Parameters of the equation\n",
    "k1 = 1\n",
    "k2 = 0.883\n",
    "c1 = 0.0116\n",
    "c2 = 0.0116\n",
    "\n",
    "\n",
    "# Setup training and test dataset\n",
    "N_div_train = 30\n",
    "N_bc = 100\n",
    "N_ic = 100\n",
    "a = 0.01\n",
    "r = (x_r/a)**(1/(N_div_train-1))\n",
    "\n",
    "x_train1 =[]\n",
    "t_train1 =[]\n",
    "for i in range(N_div_train):\n",
    "    for j in range(N_div_train):\n",
    "#         x_train1.append(x_l + (i-1)*(x_r-x_l)/N_div_train)\n",
    "        x_train1.append(a*r**i)\n",
    "        t_train1.append(t_i + (j-1)*t_f/N_div_train)\n",
    "\n",
    "x_train1 = torch.FloatTensor(x_train1)\n",
    "t_train1 = torch.FloatTensor(t_train1)   \n",
    "x_bc = torch.ones(N_bc)*x_l\n",
    "x_ic = torch.rand(N_ic)\n",
    "t_bc = torch.rand(N_bc)\n",
    "t_ic = torch.ones(N_ic)*t_i\n",
    "x_train2 = torch.cat((x_train1,x_bc,x_ic),0)\n",
    "t_train2 = torch.cat((t_train1,t_bc,t_ic),0)\n",
    "null = torch.zeros(N_div_train*N_div_train + N_bc + N_ic)\n",
    "\n",
    "x_train2 = x_train2.unsqueeze(-1)\n",
    "t_train2 = t_train2.unsqueeze(-1)\n",
    "x_train = x_train2.clone().detach().requires_grad_(True)\n",
    "t_train = t_train2.clone().detach().requires_grad_(True)\n",
    "null = null.unsqueeze(-1)\n",
    "\n",
    "# Setup NN\n",
    "n_input = 2\n",
    "n_output = 2\n",
    "n_nodes = 8\n",
    "\n",
    "# NN for liquid\n",
    "NN1 = nn.Sequential( nn.Linear(n_input, n_nodes), nn.Tanh(),\n",
    "                     nn.Linear(n_nodes, n_nodes), nn.Tanh(),\n",
    "                     nn.Linear(n_nodes, n_nodes), nn.Tanh(),\n",
    "                     nn.Linear(n_nodes, n_output) )\n",
    "\n",
    "# NN for interface\n",
    "n_input = 1\n",
    "n_output = 1\n",
    "NN3 = nn.Sequential( nn.Linear(1, n_nodes), nn.Tanh(),\n",
    "                     nn.Linear(n_nodes, n_nodes), nn.Tanh(),\n",
    "                     nn.Linear(n_nodes, n_output) )\n",
    "\n",
    "# Initialise Weights and Biases for NN\n",
    "for layer in NN1.modules():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "         layer.weight.data.normal_(mean=0, std=0.25)\n",
    "        \n",
    "for layer in NN3.modules():\n",
    "    if isinstance(layer, nn.Linear):\n",
    "         layer.weight.data.normal_(mean=0, std=0.25)\n",
    "\n",
    "# Hyper-parameters\n",
    "learning_rate = 9.5e-5\n",
    "n_iters = 70000\n",
    "            \n",
    "#loss function weights\n",
    "w1 = 1\n",
    "w2 = 6\n",
    "w3 = 6\n",
    "w4 = 6\n",
    "w5 = 3\n",
    "w6 = 12\n",
    "w7 = 10\n",
    "w8 = 1\n",
    "\n",
    "# Setup Loss function and Optimiser\n",
    "mse = nn.MSELoss()\n",
    "tanh = nn.Tanh()\n",
    "optimiser = torch.optim.Adam([*NN1.parameters(), *NN3.parameters()], lr=learning_rate)\n",
    "\n",
    "# For training NN\n",
    "for i in range(n_iters):\n",
    "    \n",
    "    output1 = NN1( torch.cat((x_train, t_train),1) )\n",
    "    T1 = output1[:,0]\n",
    "    T2 = output1[:,1]\n",
    "    s = NN3(t_train)\n",
    "        \n",
    "    dT1dt = torch.autograd.grad(T1, t_train, grad_outputs=torch.ones_like(T1), create_graph=True)[0]\n",
    "    dT1dx = torch.autograd.grad(T1, x_train, grad_outputs=torch.ones_like(T1), create_graph=True)[0]\n",
    "    dT1dx2 = torch.autograd.grad(dT1dx, x_train, grad_outputs=torch.ones_like(dT1dx), create_graph=True)[0]  \n",
    "\n",
    "    dT2dt = torch.autograd.grad(T2, t_train, grad_outputs=torch.ones_like(T2), create_graph=True)[0]\n",
    "    dT2dx = torch.autograd.grad(T2, x_train, grad_outputs=torch.ones_like(T2), create_graph=True)[0]\n",
    "    dT2dx2 = torch.autograd.grad(dT2dx, x_train, grad_outputs=torch.ones_like(dT2dx), create_graph=True)[0]\n",
    "\n",
    "    output2 = NN1( torch.cat((s, t_train),1) )\n",
    "    Ts1 = output2[:,0]\n",
    "    Ts2 = output2[:,1]\n",
    "    dTs1dx = torch.autograd.grad(Ts1, s, grad_outputs=torch.ones_like(Ts1), create_graph=True)[0]\n",
    "    dTs2dx = torch.autograd.grad(Ts2, s, grad_outputs=torch.ones_like(Ts2), create_graph=True)[0]\n",
    "    dsdt = torch.autograd.grad(s, t_train, grad_outputs=torch.ones_like(s), create_graph=True)[0]\n",
    "    \n",
    "    optimiser.zero_grad()\n",
    "    eq1 = w1*( mse(torch.mul ( 1/(1 + torch.exp(-50*(s - x_train))), (dT1dt-k1*dT1dx2)), null))\n",
    "    ic1 = w2*( mse( torch.mul(torch.where(t_train == t_i,1,0),(T2 - T_i)), null ) + mse( torch.mul(torch.where(t_train == t_i,1,0),(T1 - T_i)), null ) )\n",
    "    bc1 = w3*mse( torch.mul(torch.where(x_train == x_l,1,0),(T1 - left_temp)), null ) \n",
    "    bc2 = w4*(mse( Ts1 - melt_temp, null ) + mse( Ts2 - melt_temp, null ))\n",
    "    eq2 = w5*mse( dsdt+c1*dTs1dx-c2*dTs2dx, null ) \n",
    "    ic2 = w6*mse( torch.mul(torch.where(t_train == t_i,1,0),(s - s_i)), null ) \n",
    "#     l1 = w7*mse( (tanh(50*s)-1)/2, null )\n",
    "    eq3 = w8*( mse(torch.mul ( 1/(1 + torch.exp(-50*(- s + x_train))), (dT2dt-k2*dT2dx2)), null))\n",
    "    loss = eq1 + bc1 + bc2 + ic1 + eq2 + ic2  + eq3\n",
    "    loss.backward()   \n",
    "    optimiser.step()\n",
    "    \n",
    "    iters.append(iters[-1]+1)\n",
    "    loss_store.append(loss.detach().numpy())\n",
    "    \n",
    "#     if i%100 == 0:\n",
    "#         print('epoch = ',i,', loss = ',loss.detach().numpy())\n",
    "        \n",
    "    if i%1000 == 0:\n",
    "        print('epoch = ',i,', loss = ',loss.detach().numpy())\n",
    "        print('eq1_loss = ',eq1.detach().numpy())\n",
    "        print('ic1_loss = ',ic1.detach().numpy())\n",
    "        print('bc1_loss = ',bc1.detach().numpy())\n",
    "        print('bc2_loss = ',bc2.detach().numpy())\n",
    "        print('eq2_loss = ',eq2.detach().numpy())\n",
    "        print('eq3_loss = ',eq3.detach().numpy())\n",
    "        print('ic2_loss = ',ic2.detach().numpy())\n",
    "#         print('negative_loss = ',l1.detach().numpy())\n",
    "\n",
    "# Extract Weights and Biases\n",
    "w1 = list(NN1.parameters())\n",
    "w2 = list(NN2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293e9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lam Calculation\n",
    "x = []\n",
    "er_x = []\n",
    "er_x2 = []\n",
    "cnt = 0\n",
    "for i in np.arange(0.001, 5, 0.001):\n",
    "    x.append(i)\n",
    "    er_x.append(math.erf(x[-1]))\n",
    "    er_x2.append(math.erfc(x[-1]*math.sqrt(k1/k2)) )\n",
    "    cnt = cnt+1\n",
    "    \n",
    "x = np.array(x)\n",
    "er_x = np.array(er_x)\n",
    "er_x2 = np.array(er_x2)\n",
    "y =[]\n",
    "y = np.exp(-x*x)/(er_x) - math.sqrt(math.pi)*x*k1/((left_temp-melt_temp)*c1) + (c2/c1)*(math.sqrt(k1/k2))*(-melt_temp+right_temp)/(left_temp-melt_temp)*np.exp(-x*x*(k1/k2))/(er_x2) \n",
    "for i in range(1,cnt):\n",
    "    if(y[i]*y[i-1]<0):\n",
    "        lam = x[i]\n",
    "        print('lam = ',lam)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Distribution\n",
    "\n",
    "N_test = 2000\n",
    "\n",
    "t_pred = 0.9\n",
    "\n",
    "x_test = torch.linspace(0,x_r,N_test)\n",
    "t_test = torch.ones(N_test)*t_pred\n",
    "t_test = t_test.unsqueeze(-1)\n",
    "x_test = x_test.unsqueeze(-1)\n",
    "\n",
    "y1_pred = NN1( torch.cat((x_test, t_test),1) )\n",
    "y2_pred = NN2( torch.cat((x_test, t_test),1) )\n",
    "s_pred = NN3(t_test)\n",
    "\n",
    "y1_pred = y1_pred.detach().numpy()\n",
    "y2_pred = y2_pred.detach().numpy()\n",
    "x_test = x_test.detach().numpy()\n",
    "s_pred = s_pred.detach().numpy()\n",
    "t_test = t_test.detach().numpy()\n",
    "\n",
    "# PINN\n",
    "y_pred = []\n",
    "for i in range(N_test):\n",
    "    if (s_pred[i]>x_test[i]):\n",
    "        y_pred.append(y1_pred[i][0])\n",
    "    elif (s_pred[i]<x_test[i] and y2_pred[i][0]>0):\n",
    "        y_pred.append(y2_pred[i][0])\n",
    "    else:\n",
    "        y_pred.append(0)   \n",
    "        \n",
    "# Analytical\n",
    "y_an = []\n",
    "s_an = np.sqrt(k1*t_pred)*2*lam\n",
    "for i in range(N_test):\n",
    "    if (s_an>x_test[i]):\n",
    "        y_an.append( left_temp + (-left_temp+melt_temp)*math.erf( x_test[i]/( 2*np.sqrt(k1*t_test[i]) ) )/ math.erf(lam) )\n",
    "    else:\n",
    "        y_an.append( right_temp + (-right_temp+melt_temp)*math.erfc( x_test[i]/( 2*np.sqrt(k2*t_test[i]) ) )/ math.erfc(lam*math.sqrt(k1/k2)))   \n",
    "        \n",
    "plt.plot(x_test, y_pred)\n",
    "plt.plot(x_test, y_an)\n",
    "\n",
    "plt.legend(['PINN', 'Analytical'])\n",
    "plt.title('Time = '+ str(t_pred) )\n",
    "plt.ylabel('Temperature')\n",
    "plt.xlabel('Domain')\n",
    "plt.xlim([0, 0.3])\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f02829",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 2000\n",
    "\n",
    "t_test = torch.linspace(t_i, t_f, N_test)\n",
    "t_test = t_test.unsqueeze(-1)\n",
    "s_pred = NN3(t_test)\n",
    "\n",
    "t_test = t_test.detach().numpy()\n",
    "s_pred = s_pred.detach().numpy()\n",
    "\n",
    "plt.plot(t_test,s_pred)\n",
    "plt.plot(t_test, np.sqrt(k1*t_test)*2*lam)\n",
    "plt.legend(['PINN', 'Analytical'])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Interface Position')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
