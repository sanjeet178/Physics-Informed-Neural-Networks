{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802d1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292c4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(N_x, x_l, x_r, del_x, N_t, t_i, t_f, del_t, N_bc, N_ic):\n",
    "\n",
    "    x_train = np.geomspace(x_l+0.001, x_r-0.001, N_x)\n",
    "    x_train = np.tile(x_train, N_t)\n",
    "    x_bc1 = np.zeros(N_bc)\n",
    "    x_bc2 = np.ones(N_bc)*x_r\n",
    "    x_ic = np.random.uniform(x_l, x_r, N_ic)\n",
    "    x_train = np.concatenate((x_train,x_bc1,x_bc2,x_ic),0)\n",
    "    x_train = torch.FloatTensor(x_train)\n",
    "    x_train = x_train.unsqueeze(-1)\n",
    "    x_train = x_train.clone().detach().requires_grad_(True)\n",
    "\n",
    "    t_start = t_i + 0.001 \n",
    "    t_end = t_start + del_t*(N_t-1) \n",
    "    t_array = np.geomspace(t_start, t_end, N_t)\n",
    "    t_train = np.repeat(t_array, N_x)\n",
    "    t_bc = np.random.uniform(t_i, t_f, 2*N_bc)\n",
    "    t_ic = np.zeros(N_ic)\n",
    "    t_train = np.concatenate((t_train, t_bc, t_ic),0)\n",
    "    t_train = torch.FloatTensor(t_train)\n",
    "    t_train = t_train.unsqueeze(-1)\n",
    "    t_train = t_train.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    return x_train, t_train\n",
    "\n",
    "def xavier_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0.0)\n",
    "    \n",
    "class FVMANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FVMANN, self).__init__()\n",
    "        \n",
    "        # Fully conected model\n",
    "        modules = []\n",
    "        for i in range(len(hidden_size)):\n",
    "            if(i==0):\n",
    "                modules.append(nn.Linear(input_size, hidden_size[i]))\n",
    "            else:\n",
    "                modules.append(nn.Linear(hidden_size[i-1], hidden_size[i]))  \n",
    "            modules.append(nn.Tanh())\n",
    "                \n",
    "        modules.append(nn.Linear(hidden_size[-1], output_size))\n",
    "        modules.append(nn.Tanh())\n",
    "        self.fc = nn.Sequential(*modules)\n",
    "        \n",
    "        # initialise the weights\n",
    "#         if isinstance(self.fc, nn.Linear):\n",
    "#             constant_value = 0.1\n",
    "#             init.constant_(m.weight, constant_value)\n",
    "#             init.constant_(m.bias, constant_value)\n",
    "\n",
    "#         for layer in self.fc.modules():\n",
    "#             if isinstance(layer, nn.Linear):\n",
    "#                 layer.weight.data.normal_(mean=0, std=0.2)\n",
    "        \n",
    "    def forward(self, x_train, t_train):\n",
    "        op = self.fc(torch.cat((x_train, t_train),1))\n",
    "        op_t = torch.autograd.grad(op, t_train, grad_outputs=torch.ones_like(op), create_graph=True)[0]\n",
    "        op_x = torch.autograd.grad(op, x_train, grad_outputs=torch.ones_like(op), create_graph=True)[0]\n",
    "        op_x2 = torch.autograd.grad(op_x, x_train, grad_outputs=torch.ones_like(op_x), create_graph=True)[0]\n",
    "        return op, op_t, op_x2\n",
    "    \n",
    "def train_model(model, optimiser, epochs, T_r, T_l, k1, N_x, x_l, x_r, del_x, N_t, t_i, t_f, del_t, N_bc, N_ic, T_ini):\n",
    "    \n",
    "    loss_store = []\n",
    "    mse = nn.MSELoss(reduction='sum')\n",
    "    model.train()  \n",
    "    \n",
    "    w1 = 1\n",
    "    w2 = 6\n",
    "    w3 = 6\n",
    "    w4 = 1\n",
    "        \n",
    "    N_tot = N_t*N_x + 2*N_bc + N_ic\n",
    "    null = torch.zeros(N_tot)\n",
    "    null = null.unsqueeze(-1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        x_train, t_train = train_data(N_x, x_l, x_r, del_x, N_t, t_i, t_f, del_t, N_bc, N_ic)\n",
    "        T, dTdt, d2Tdx2 = model(x_train, t_train)\n",
    "\n",
    "        eq1 = w1*mse(dTdt, k1*d2Tdx2)/(N_tot)\n",
    "        ic1 = w2*mse( torch.mul(torch.where(t_train == t_i,1,0),(T - T_ini )), null )/N_ic\n",
    "        bc1 = w3*mse( torch.mul(torch.where(x_train == x_l,1,0),(T - T_l)), null )/N_bc\n",
    "        bc2 = w4*mse( torch.mul(torch.where(x_train == x_r,1,0),(T - T_r)), null )/N_bc\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss = eq1 + bc1 + bc2 + ic1\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        loss_store.append(loss.detach().numpy())\n",
    "\n",
    "        if epoch%200==0:   \n",
    "            print('epoch = ',epoch)\n",
    "            print('loss = ',loss.detach().numpy())\n",
    "            print('eq1_loss = ',eq1.detach().numpy())\n",
    "            print('ic1_loss = ',ic1.detach().numpy())\n",
    "            print('bc1_loss = ',bc1.detach().numpy())\n",
    "            print('bc2_loss = ',bc2.detach().numpy())\n",
    "\n",
    "    return loss_store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f47a7f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FVMANN(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=45, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=45, out_features=45, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=45, out_features=45, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=45, out_features=45, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=45, out_features=45, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=45, out_features=45, bias=True)\n",
      "    (11): Tanh()\n",
      "    (12): Linear(in_features=45, out_features=1, bias=True)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Total trainable parameters in the model: 10531\n",
      "epoch =  0\n",
      "loss =  6.4666986\n",
      "eq1_loss =  0.008139278\n",
      "ic1_loss =  0.0033525408\n",
      "bc1_loss =  6.4505796\n",
      "bc2_loss =  0.004627164\n",
      "epoch =  200\n",
      "loss =  4.719334\n",
      "eq1_loss =  0.02558443\n",
      "ic1_loss =  0.015604427\n",
      "bc1_loss =  4.6659007\n",
      "bc2_loss =  0.012244899\n",
      "epoch =  400\n",
      "loss =  3.5205822\n",
      "eq1_loss =  0.1402699\n",
      "ic1_loss =  0.04516758\n",
      "bc1_loss =  3.290415\n",
      "bc2_loss =  0.04472947\n",
      "epoch =  600\n",
      "loss =  2.8078299\n",
      "eq1_loss =  0.29156336\n",
      "ic1_loss =  0.08201079\n",
      "bc1_loss =  2.3679366\n",
      "bc2_loss =  0.06631927\n",
      "epoch =  800\n",
      "loss =  2.2099442\n",
      "eq1_loss =  0.40371066\n",
      "ic1_loss =  0.078542635\n",
      "bc1_loss =  1.6542691\n",
      "bc2_loss =  0.073421806\n",
      "epoch =  1000\n",
      "loss =  2.1187441\n",
      "eq1_loss =  0.44879666\n",
      "ic1_loss =  0.17694691\n",
      "bc1_loss =  1.4319305\n",
      "bc2_loss =  0.061070018\n",
      "epoch =  1200\n",
      "loss =  1.9243569\n",
      "eq1_loss =  0.43076876\n",
      "ic1_loss =  0.2503006\n",
      "bc1_loss =  1.1985922\n",
      "bc2_loss =  0.044695508\n",
      "epoch =  1400\n",
      "loss =  1.6397401\n",
      "eq1_loss =  0.37515065\n",
      "ic1_loss =  0.29629147\n",
      "bc1_loss =  0.92995036\n",
      "bc2_loss =  0.038347658\n",
      "epoch =  1600\n",
      "loss =  1.5503917\n",
      "eq1_loss =  0.31359744\n",
      "ic1_loss =  0.42851081\n",
      "bc1_loss =  0.7871605\n",
      "bc2_loss =  0.021122947\n",
      "epoch =  1800\n",
      "loss =  1.4417617\n",
      "eq1_loss =  0.2613658\n",
      "ic1_loss =  0.4468727\n",
      "bc1_loss =  0.7142847\n",
      "bc2_loss =  0.019238487\n",
      "epoch =  2000\n",
      "loss =  1.3398104\n",
      "eq1_loss =  0.2202704\n",
      "ic1_loss =  0.48353142\n",
      "bc1_loss =  0.6207803\n",
      "bc2_loss =  0.015228225\n",
      "epoch =  2200\n",
      "loss =  1.306855\n",
      "eq1_loss =  0.19264598\n",
      "ic1_loss =  0.5734274\n",
      "bc1_loss =  0.52351695\n",
      "bc2_loss =  0.017264722\n",
      "epoch =  2400\n",
      "loss =  1.3865961\n",
      "eq1_loss =  0.17499368\n",
      "ic1_loss =  0.6658559\n",
      "bc1_loss =  0.5269126\n",
      "bc2_loss =  0.018833874\n",
      "epoch =  2600\n",
      "loss =  1.3369718\n",
      "eq1_loss =  0.1647519\n",
      "ic1_loss =  0.6666324\n",
      "bc1_loss =  0.487545\n",
      "bc2_loss =  0.01804247\n",
      "epoch =  2800\n",
      "loss =  1.350385\n",
      "eq1_loss =  0.15728147\n",
      "ic1_loss =  0.6824328\n",
      "bc1_loss =  0.49092636\n",
      "bc2_loss =  0.019744419\n",
      "epoch =  3000\n",
      "loss =  1.3770249\n",
      "eq1_loss =  0.15441678\n",
      "ic1_loss =  0.7518919\n",
      "bc1_loss =  0.4482314\n",
      "bc2_loss =  0.02248478\n",
      "epoch =  3200\n",
      "loss =  1.253991\n",
      "eq1_loss =  0.15394212\n",
      "ic1_loss =  0.6370559\n",
      "bc1_loss =  0.44710746\n",
      "bc2_loss =  0.015885502\n",
      "epoch =  3400\n",
      "loss =  1.16153\n",
      "eq1_loss =  0.15266126\n",
      "ic1_loss =  0.53826565\n",
      "bc1_loss =  0.45120442\n",
      "bc2_loss =  0.019398747\n",
      "epoch =  3600\n",
      "loss =  1.2884042\n",
      "eq1_loss =  0.15014613\n",
      "ic1_loss =  0.6935411\n",
      "bc1_loss =  0.42745957\n",
      "bc2_loss =  0.017257474\n",
      "epoch =  3800\n",
      "loss =  1.4075992\n",
      "eq1_loss =  0.15338054\n",
      "ic1_loss =  0.7634735\n",
      "bc1_loss =  0.47294593\n",
      "bc2_loss =  0.017799225\n",
      "epoch =  4000\n",
      "loss =  1.3532956\n",
      "eq1_loss =  0.15178108\n",
      "ic1_loss =  0.73327917\n",
      "bc1_loss =  0.45323068\n",
      "bc2_loss =  0.015004598\n",
      "epoch =  4200\n",
      "loss =  1.1555643\n",
      "eq1_loss =  0.15077744\n",
      "ic1_loss =  0.55592257\n",
      "bc1_loss =  0.43390447\n",
      "bc2_loss =  0.014959881\n",
      "epoch =  4400\n",
      "loss =  1.2838974\n",
      "eq1_loss =  0.15017708\n",
      "ic1_loss =  0.6793411\n",
      "bc1_loss =  0.439643\n",
      "bc2_loss =  0.014736204\n",
      "epoch =  4600\n",
      "loss =  1.2436919\n",
      "eq1_loss =  0.15092525\n",
      "ic1_loss =  0.64815\n",
      "bc1_loss =  0.43075716\n",
      "bc2_loss =  0.01385951\n",
      "epoch =  4800\n",
      "loss =  1.2856766\n",
      "eq1_loss =  0.15004608\n",
      "ic1_loss =  0.69539917\n",
      "bc1_loss =  0.42921975\n",
      "bc2_loss =  0.0110116135\n",
      "epoch =  5000\n",
      "loss =  1.299536\n",
      "eq1_loss =  0.1512046\n",
      "ic1_loss =  0.7185679\n",
      "bc1_loss =  0.41975102\n",
      "bc2_loss =  0.010012366\n",
      "epoch =  5200\n",
      "loss =  1.1363156\n",
      "eq1_loss =  0.15250674\n",
      "ic1_loss =  0.54745096\n",
      "bc1_loss =  0.42980182\n",
      "bc2_loss =  0.006556151\n",
      "epoch =  5400\n",
      "loss =  1.0224861\n",
      "eq1_loss =  0.1582788\n",
      "ic1_loss =  0.4417037\n",
      "bc1_loss =  0.41489488\n",
      "bc2_loss =  0.0076087452\n",
      "epoch =  5600\n",
      "loss =  1.1279519\n",
      "eq1_loss =  0.1634836\n",
      "ic1_loss =  0.58301157\n",
      "bc1_loss =  0.37688282\n",
      "bc2_loss =  0.004573848\n",
      "epoch =  5800\n",
      "loss =  1.0126534\n",
      "eq1_loss =  0.17154239\n",
      "ic1_loss =  0.46905732\n",
      "bc1_loss =  0.36893478\n",
      "bc2_loss =  0.0031189153\n",
      "epoch =  6000\n",
      "loss =  1.127316\n",
      "eq1_loss =  0.18348631\n",
      "ic1_loss =  0.5519414\n",
      "bc1_loss =  0.38908017\n",
      "bc2_loss =  0.0028081406\n",
      "epoch =  6200\n",
      "loss =  0.81596756\n",
      "eq1_loss =  0.1887875\n",
      "ic1_loss =  0.24425086\n",
      "bc1_loss =  0.38071212\n",
      "bc2_loss =  0.002217055\n",
      "epoch =  6400\n",
      "loss =  0.8900782\n",
      "eq1_loss =  0.19468533\n",
      "ic1_loss =  0.32381848\n",
      "bc1_loss =  0.36974075\n",
      "bc2_loss =  0.0018337023\n",
      "epoch =  6600\n",
      "loss =  0.99464357\n",
      "eq1_loss =  0.19786024\n",
      "ic1_loss =  0.40094697\n",
      "bc1_loss =  0.39432535\n",
      "bc2_loss =  0.0015109624\n",
      "epoch =  6800\n",
      "loss =  0.9797865\n",
      "eq1_loss =  0.19140927\n",
      "ic1_loss =  0.3918344\n",
      "bc1_loss =  0.39393097\n",
      "bc2_loss =  0.002611824\n",
      "epoch =  7000\n",
      "loss =  0.9855397\n",
      "eq1_loss =  0.19042392\n",
      "ic1_loss =  0.38872784\n",
      "bc1_loss =  0.40417096\n",
      "bc2_loss =  0.002216922\n",
      "epoch =  7200\n",
      "loss =  0.9078454\n",
      "eq1_loss =  0.18081124\n",
      "ic1_loss =  0.34573486\n",
      "bc1_loss =  0.37902847\n",
      "bc2_loss =  0.0022707304\n",
      "epoch =  7400\n",
      "loss =  0.9134934\n",
      "eq1_loss =  0.1704092\n",
      "ic1_loss =  0.2967678\n",
      "bc1_loss =  0.44411248\n",
      "bc2_loss =  0.002203874\n",
      "epoch =  7600\n",
      "loss =  0.917502\n",
      "eq1_loss =  0.15568864\n",
      "ic1_loss =  0.32842577\n",
      "bc1_loss =  0.43004265\n",
      "bc2_loss =  0.0033449251\n",
      "epoch =  7800\n",
      "loss =  0.9501008\n",
      "eq1_loss =  0.13945663\n",
      "ic1_loss =  0.36787102\n",
      "bc1_loss =  0.44004887\n",
      "bc2_loss =  0.0027242205\n",
      "epoch =  8000\n",
      "loss =  0.6765575\n",
      "eq1_loss =  0.1264704\n",
      "ic1_loss =  0.19066243\n",
      "bc1_loss =  0.35620406\n",
      "bc2_loss =  0.0032205621\n",
      "epoch =  8200\n",
      "loss =  0.72364914\n",
      "eq1_loss =  0.116300926\n",
      "ic1_loss =  0.25274685\n",
      "bc1_loss =  0.35180405\n",
      "bc2_loss =  0.0027972988\n",
      "epoch =  8400\n",
      "loss =  0.7069895\n",
      "eq1_loss =  0.10811232\n",
      "ic1_loss =  0.23630455\n",
      "bc1_loss =  0.3593647\n",
      "bc2_loss =  0.0032079248\n",
      "epoch =  8600\n",
      "loss =  0.6527748\n",
      "eq1_loss =  0.107717626\n",
      "ic1_loss =  0.22123024\n",
      "bc1_loss =  0.32095596\n",
      "bc2_loss =  0.002870999\n",
      "epoch =  8800\n",
      "loss =  0.6312944\n",
      "eq1_loss =  0.10599937\n",
      "ic1_loss =  0.18535757\n",
      "bc1_loss =  0.33754528\n",
      "bc2_loss =  0.0023922084\n",
      "epoch =  9000\n",
      "loss =  0.62958753\n",
      "eq1_loss =  0.110737875\n",
      "ic1_loss =  0.21950702\n",
      "bc1_loss =  0.2974062\n",
      "bc2_loss =  0.0019364391\n",
      "epoch =  9200\n",
      "loss =  0.5849066\n",
      "eq1_loss =  0.11078695\n",
      "ic1_loss =  0.18081717\n",
      "bc1_loss =  0.29160124\n",
      "bc2_loss =  0.0017012246\n",
      "epoch =  9400\n",
      "loss =  0.6186053\n",
      "eq1_loss =  0.10894524\n",
      "ic1_loss =  0.19832385\n",
      "bc1_loss =  0.3098525\n",
      "bc2_loss =  0.0014836965\n",
      "epoch =  9600\n",
      "loss =  0.53071606\n",
      "eq1_loss =  0.11805624\n",
      "ic1_loss =  0.18055424\n",
      "bc1_loss =  0.23104481\n",
      "bc2_loss =  0.0010607116\n",
      "epoch =  9800\n",
      "loss =  0.6104245\n",
      "eq1_loss =  0.1165104\n",
      "ic1_loss =  0.2476082\n",
      "bc1_loss =  0.24540962\n",
      "bc2_loss =  0.0008962901\n",
      "epoch =  10000\n",
      "loss =  0.5321806\n",
      "eq1_loss =  0.11624495\n",
      "ic1_loss =  0.16789883\n",
      "bc1_loss =  0.24740772\n",
      "bc2_loss =  0.00062910304\n",
      "epoch =  10200\n",
      "loss =  0.5006201\n",
      "eq1_loss =  0.116867095\n",
      "ic1_loss =  0.16583611\n",
      "bc1_loss =  0.21752979\n",
      "bc2_loss =  0.00038709608\n",
      "epoch =  10400\n",
      "loss =  0.51776624\n",
      "eq1_loss =  0.11772959\n",
      "ic1_loss =  0.19841835\n",
      "bc1_loss =  0.20115422\n",
      "bc2_loss =  0.00046408107\n",
      "epoch =  10600\n",
      "loss =  0.5350684\n",
      "eq1_loss =  0.116239056\n",
      "ic1_loss =  0.1977116\n",
      "bc1_loss =  0.22076334\n",
      "bc2_loss =  0.00035437717\n",
      "epoch =  10800\n",
      "loss =  0.5423265\n",
      "eq1_loss =  0.117833436\n",
      "ic1_loss =  0.23162453\n",
      "bc1_loss =  0.19253746\n",
      "bc2_loss =  0.00033110956\n",
      "epoch =  11000\n",
      "loss =  0.51708114\n",
      "eq1_loss =  0.11189482\n",
      "ic1_loss =  0.18650635\n",
      "bc1_loss =  0.21843272\n",
      "bc2_loss =  0.00024728192\n",
      "epoch =  11200\n",
      "loss =  0.5253527\n",
      "eq1_loss =  0.109571576\n",
      "ic1_loss =  0.20880222\n",
      "bc1_loss =  0.2066831\n",
      "bc2_loss =  0.00029580994\n",
      "epoch =  11400\n",
      "loss =  0.5432614\n",
      "eq1_loss =  0.10466362\n",
      "ic1_loss =  0.24611315\n",
      "bc1_loss =  0.19209532\n",
      "bc2_loss =  0.00038927983\n",
      "epoch =  11600\n",
      "loss =  0.4310686\n",
      "eq1_loss =  0.09992596\n",
      "ic1_loss =  0.15434608\n",
      "bc1_loss =  0.17623273\n",
      "bc2_loss =  0.0005638278\n",
      "epoch =  11800\n",
      "loss =  0.5778647\n",
      "eq1_loss =  0.09094745\n",
      "ic1_loss =  0.27669752\n",
      "bc1_loss =  0.20953898\n",
      "bc2_loss =  0.0006807542\n",
      "epoch =  12000\n",
      "loss =  0.4727124\n",
      "eq1_loss =  0.08273953\n",
      "ic1_loss =  0.20584267\n",
      "bc1_loss =  0.18353012\n",
      "bc2_loss =  0.00060007937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  12200\n",
      "loss =  0.4759032\n",
      "eq1_loss =  0.07805272\n",
      "ic1_loss =  0.22751197\n",
      "bc1_loss =  0.16958193\n",
      "bc2_loss =  0.00075657427\n",
      "epoch =  12400\n",
      "loss =  0.39793903\n",
      "eq1_loss =  0.07040938\n",
      "ic1_loss =  0.14105172\n",
      "bc1_loss =  0.18550417\n",
      "bc2_loss =  0.00097372546\n",
      "epoch =  12600\n",
      "loss =  0.43783867\n",
      "eq1_loss =  0.06460269\n",
      "ic1_loss =  0.22688824\n",
      "bc1_loss =  0.14529322\n",
      "bc2_loss =  0.0010545288\n",
      "epoch =  12800\n",
      "loss =  0.3951307\n",
      "eq1_loss =  0.06359026\n",
      "ic1_loss =  0.15735996\n",
      "bc1_loss =  0.17304902\n",
      "bc2_loss =  0.0011314512\n",
      "epoch =  13000\n",
      "loss =  0.3877924\n",
      "eq1_loss =  0.06362683\n",
      "ic1_loss =  0.15442127\n",
      "bc1_loss =  0.16893992\n",
      "bc2_loss =  0.0008043964\n",
      "epoch =  13200\n",
      "loss =  0.35640156\n",
      "eq1_loss =  0.063970946\n",
      "ic1_loss =  0.13194962\n",
      "bc1_loss =  0.15975308\n",
      "bc2_loss =  0.0007279105\n",
      "epoch =  13400\n",
      "loss =  0.37917006\n",
      "eq1_loss =  0.06469583\n",
      "ic1_loss =  0.16178907\n",
      "bc1_loss =  0.15165049\n",
      "bc2_loss =  0.0010346655\n",
      "epoch =  13600\n",
      "loss =  0.4127892\n",
      "eq1_loss =  0.06629857\n",
      "ic1_loss =  0.1808711\n",
      "bc1_loss =  0.16493471\n",
      "bc2_loss =  0.0006848294\n",
      "epoch =  13800\n",
      "loss =  0.39916116\n",
      "eq1_loss =  0.06731189\n",
      "ic1_loss =  0.1814149\n",
      "bc1_loss =  0.14990705\n",
      "bc2_loss =  0.0005273025\n",
      "epoch =  14000\n",
      "loss =  0.3228197\n",
      "eq1_loss =  0.06809281\n",
      "ic1_loss =  0.11546449\n",
      "bc1_loss =  0.13882247\n",
      "bc2_loss =  0.00043993493\n",
      "epoch =  14200\n",
      "loss =  0.35188678\n",
      "eq1_loss =  0.06819237\n",
      "ic1_loss =  0.13999663\n",
      "bc1_loss =  0.14341143\n",
      "bc2_loss =  0.0002863609\n",
      "epoch =  14400\n",
      "loss =  0.33275008\n",
      "eq1_loss =  0.06695807\n",
      "ic1_loss =  0.109204024\n",
      "bc1_loss =  0.15643893\n",
      "bc2_loss =  0.00014907865\n",
      "epoch =  14600\n",
      "loss =  0.41138005\n",
      "eq1_loss =  0.0667201\n",
      "ic1_loss =  0.21401782\n",
      "bc1_loss =  0.13033286\n",
      "bc2_loss =  0.0003092786\n",
      "epoch =  14800\n",
      "loss =  0.302111\n",
      "eq1_loss =  0.06594481\n",
      "ic1_loss =  0.10512738\n",
      "bc1_loss =  0.13077956\n",
      "bc2_loss =  0.0002592291\n",
      "epoch =  15000\n",
      "loss =  0.46189553\n",
      "eq1_loss =  0.064613275\n",
      "ic1_loss =  0.23623644\n",
      "bc1_loss =  0.16090365\n",
      "bc2_loss =  0.00014216657\n",
      "epoch =  15200\n",
      "loss =  0.3253335\n",
      "eq1_loss =  0.06350796\n",
      "ic1_loss =  0.142037\n",
      "bc1_loss =  0.11946488\n",
      "bc2_loss =  0.0003236575\n",
      "epoch =  15400\n",
      "loss =  0.32896084\n",
      "eq1_loss =  0.062310334\n",
      "ic1_loss =  0.16306569\n",
      "bc1_loss =  0.10326267\n",
      "bc2_loss =  0.00032215693\n",
      "epoch =  15600\n",
      "loss =  0.37674898\n",
      "eq1_loss =  0.060827322\n",
      "ic1_loss =  0.18158123\n",
      "bc1_loss =  0.13423556\n",
      "bc2_loss =  0.000104867875\n",
      "epoch =  15800\n",
      "loss =  0.4077262\n",
      "eq1_loss =  0.0598598\n",
      "ic1_loss =  0.20578709\n",
      "bc1_loss =  0.14195998\n",
      "bc2_loss =  0.00011933528\n",
      "epoch =  16000\n",
      "loss =  0.31831336\n",
      "eq1_loss =  0.05787975\n",
      "ic1_loss =  0.14536914\n",
      "bc1_loss =  0.11485462\n",
      "bc2_loss =  0.00020987334\n",
      "epoch =  16200\n",
      "loss =  0.35057107\n",
      "eq1_loss =  0.05623015\n",
      "ic1_loss =  0.17512031\n",
      "bc1_loss =  0.11908855\n",
      "bc2_loss =  0.00013205894\n",
      "epoch =  16400\n",
      "loss =  0.38071722\n",
      "eq1_loss =  0.05631229\n",
      "ic1_loss =  0.21913412\n",
      "bc1_loss =  0.105123155\n",
      "bc2_loss =  0.00014764363\n",
      "epoch =  16600\n",
      "loss =  0.3096035\n",
      "eq1_loss =  0.055171635\n",
      "ic1_loss =  0.14429504\n",
      "bc1_loss =  0.109926164\n",
      "bc2_loss =  0.00021065434\n",
      "epoch =  16800\n",
      "loss =  0.29752973\n",
      "eq1_loss =  0.05237811\n",
      "ic1_loss =  0.11083511\n",
      "bc1_loss =  0.13411507\n",
      "bc2_loss =  0.00020142258\n",
      "epoch =  17000\n",
      "loss =  0.35239506\n",
      "eq1_loss =  0.05181876\n",
      "ic1_loss =  0.19086686\n",
      "bc1_loss =  0.10949667\n",
      "bc2_loss =  0.00021278005\n",
      "epoch =  17200\n",
      "loss =  0.31903797\n",
      "eq1_loss =  0.05126606\n",
      "ic1_loss =  0.15069047\n",
      "bc1_loss =  0.116856106\n",
      "bc2_loss =  0.00022531905\n",
      "epoch =  17400\n",
      "loss =  0.28269002\n",
      "eq1_loss =  0.05049727\n",
      "ic1_loss =  0.121873856\n",
      "bc1_loss =  0.10999917\n",
      "bc2_loss =  0.00031972476\n",
      "epoch =  17600\n",
      "loss =  0.31935447\n",
      "eq1_loss =  0.04877115\n",
      "ic1_loss =  0.17631885\n",
      "bc1_loss =  0.09396097\n",
      "bc2_loss =  0.00030352583\n",
      "epoch =  17800\n",
      "loss =  0.2620898\n",
      "eq1_loss =  0.047940377\n",
      "ic1_loss =  0.09669027\n",
      "bc1_loss =  0.117136024\n",
      "bc2_loss =  0.00032310712\n",
      "epoch =  18000\n",
      "loss =  0.29719228\n",
      "eq1_loss =  0.04684179\n",
      "ic1_loss =  0.15057346\n",
      "bc1_loss =  0.0994917\n",
      "bc2_loss =  0.00028532097\n",
      "epoch =  18200\n",
      "loss =  0.28235877\n",
      "eq1_loss =  0.046544455\n",
      "ic1_loss =  0.14672305\n",
      "bc1_loss =  0.08876631\n",
      "bc2_loss =  0.00032496426\n",
      "epoch =  18400\n",
      "loss =  0.2674941\n",
      "eq1_loss =  0.046128474\n",
      "ic1_loss =  0.13202393\n",
      "bc1_loss =  0.089065745\n",
      "bc2_loss =  0.00027596526\n",
      "epoch =  18600\n",
      "loss =  0.30454594\n",
      "eq1_loss =  0.042512484\n",
      "ic1_loss =  0.1636227\n",
      "bc1_loss =  0.09808813\n",
      "bc2_loss =  0.00032260345\n",
      "epoch =  18800\n",
      "loss =  0.33390504\n",
      "eq1_loss =  0.043158144\n",
      "ic1_loss =  0.20932485\n",
      "bc1_loss =  0.081170894\n",
      "bc2_loss =  0.00025115983\n",
      "epoch =  19000\n",
      "loss =  0.32131663\n",
      "eq1_loss =  0.043340273\n",
      "ic1_loss =  0.19596633\n",
      "bc1_loss =  0.08180577\n",
      "bc2_loss =  0.00020425055\n",
      "epoch =  19200\n",
      "loss =  0.4094488\n",
      "eq1_loss =  0.04141101\n",
      "ic1_loss =  0.26818997\n",
      "bc1_loss =  0.09960272\n",
      "bc2_loss =  0.00024511342\n",
      "epoch =  19400\n",
      "loss =  0.38246995\n",
      "eq1_loss =  0.041699182\n",
      "ic1_loss =  0.24537283\n",
      "bc1_loss =  0.09510943\n",
      "bc2_loss =  0.0002884792\n",
      "epoch =  19600\n",
      "loss =  0.24811476\n",
      "eq1_loss =  0.04080655\n",
      "ic1_loss =  0.12260778\n",
      "bc1_loss =  0.08447593\n",
      "bc2_loss =  0.00022449577\n",
      "epoch =  19800\n",
      "loss =  0.27399737\n",
      "eq1_loss =  0.039930116\n",
      "ic1_loss =  0.1327012\n",
      "bc1_loss =  0.101119556\n",
      "bc2_loss =  0.0002465114\n",
      "epoch =  20000\n",
      "loss =  0.2765678\n",
      "eq1_loss =  0.037711553\n",
      "ic1_loss =  0.15814844\n",
      "bc1_loss =  0.08046297\n",
      "bc2_loss =  0.00024483484\n",
      "epoch =  20200\n",
      "loss =  0.22105615\n",
      "eq1_loss =  0.037404854\n",
      "ic1_loss =  0.09791803\n",
      "bc1_loss =  0.08549429\n",
      "bc2_loss =  0.00023897186\n",
      "epoch =  20400\n",
      "loss =  0.31007886\n",
      "eq1_loss =  0.036864437\n",
      "ic1_loss =  0.19172187\n",
      "bc1_loss =  0.081236355\n",
      "bc2_loss =  0.00025620358\n",
      "epoch =  20600\n",
      "loss =  0.32269245\n",
      "eq1_loss =  0.0375438\n",
      "ic1_loss =  0.20225815\n",
      "bc1_loss =  0.08264681\n",
      "bc2_loss =  0.00024369918\n",
      "epoch =  20800\n",
      "loss =  0.1910631\n",
      "eq1_loss =  0.03744195\n",
      "ic1_loss =  0.0877524\n",
      "bc1_loss =  0.06546721\n",
      "bc2_loss =  0.00040153193\n",
      "epoch =  21000\n",
      "loss =  0.18702182\n",
      "eq1_loss =  0.035564277\n",
      "ic1_loss =  0.061666504\n",
      "bc1_loss =  0.08953087\n",
      "bc2_loss =  0.0002601694\n",
      "epoch =  21200\n",
      "loss =  0.26654047\n",
      "eq1_loss =  0.036269248\n",
      "ic1_loss =  0.14212233\n",
      "bc1_loss =  0.08785374\n",
      "bc2_loss =  0.000295166\n",
      "epoch =  21400\n",
      "loss =  0.2630929\n",
      "eq1_loss =  0.03525876\n",
      "ic1_loss =  0.14168258\n",
      "bc1_loss =  0.0859303\n",
      "bc2_loss =  0.00022127334\n",
      "epoch =  21600\n",
      "loss =  0.2711437\n",
      "eq1_loss =  0.03534595\n",
      "ic1_loss =  0.14890794\n",
      "bc1_loss =  0.08662068\n",
      "bc2_loss =  0.0002691297\n",
      "epoch =  21800\n",
      "loss =  0.24768925\n",
      "eq1_loss =  0.035110835\n",
      "ic1_loss =  0.13873775\n",
      "bc1_loss =  0.07351238\n",
      "bc2_loss =  0.00032827162\n",
      "epoch =  22000\n",
      "loss =  0.27800733\n",
      "eq1_loss =  0.035492532\n",
      "ic1_loss =  0.17522015\n",
      "bc1_loss =  0.06701281\n",
      "bc2_loss =  0.00028185797\n",
      "epoch =  22200\n",
      "loss =  0.1758293\n",
      "eq1_loss =  0.03450706\n",
      "ic1_loss =  0.07217261\n",
      "bc1_loss =  0.06887779\n",
      "bc2_loss =  0.0002718524\n",
      "epoch =  22400\n",
      "loss =  0.2977057\n",
      "eq1_loss =  0.034051776\n",
      "ic1_loss =  0.1671804\n",
      "bc1_loss =  0.09609222\n",
      "bc2_loss =  0.00038129292\n",
      "epoch =  22600\n",
      "loss =  0.24056475\n",
      "eq1_loss =  0.03323102\n",
      "ic1_loss =  0.116675444\n",
      "bc1_loss =  0.090393044\n",
      "bc2_loss =  0.00026523776\n",
      "epoch =  22800\n",
      "loss =  0.23271333\n",
      "eq1_loss =  0.032904945\n",
      "ic1_loss =  0.10166326\n",
      "bc1_loss =  0.09779842\n",
      "bc2_loss =  0.00034670834\n",
      "epoch =  23000\n",
      "loss =  0.2022866\n",
      "eq1_loss =  0.032813612\n",
      "ic1_loss =  0.08737067\n",
      "bc1_loss =  0.08165958\n",
      "bc2_loss =  0.0004427424\n",
      "epoch =  23200\n",
      "loss =  0.24596274\n",
      "eq1_loss =  0.032204024\n",
      "ic1_loss =  0.12936056\n",
      "bc1_loss =  0.084023416\n",
      "bc2_loss =  0.00037473542\n",
      "epoch =  23400\n",
      "loss =  0.2162\n",
      "eq1_loss =  0.031488564\n",
      "ic1_loss =  0.09490299\n",
      "bc1_loss =  0.08941697\n",
      "bc2_loss =  0.00039147583\n",
      "epoch =  23600\n",
      "loss =  0.26360416\n",
      "eq1_loss =  0.030961068\n",
      "ic1_loss =  0.14234486\n",
      "bc1_loss =  0.08990168\n",
      "bc2_loss =  0.0003965535\n",
      "epoch =  23800\n",
      "loss =  0.30975014\n",
      "eq1_loss =  0.030596066\n",
      "ic1_loss =  0.19310112\n",
      "bc1_loss =  0.085660964\n",
      "bc2_loss =  0.00039198573\n",
      "epoch =  24000\n",
      "loss =  0.271356\n",
      "eq1_loss =  0.030234676\n",
      "ic1_loss =  0.17299768\n",
      "bc1_loss =  0.06775261\n",
      "bc2_loss =  0.0003710199\n",
      "epoch =  24200\n",
      "loss =  0.22222203\n",
      "eq1_loss =  0.029232137\n",
      "ic1_loss =  0.10671524\n",
      "bc1_loss =  0.085874036\n",
      "bc2_loss =  0.0004006277\n",
      "epoch =  24400\n",
      "loss =  0.25225094\n",
      "eq1_loss =  0.027930854\n",
      "ic1_loss =  0.14321955\n",
      "bc1_loss =  0.08056106\n",
      "bc2_loss =  0.00053949276\n",
      "epoch =  24600\n",
      "loss =  0.2166094\n",
      "eq1_loss =  0.028767563\n",
      "ic1_loss =  0.10499349\n",
      "bc1_loss =  0.08238915\n",
      "bc2_loss =  0.00045919616\n",
      "epoch =  24800\n",
      "loss =  0.2000921\n",
      "eq1_loss =  0.028626436\n",
      "ic1_loss =  0.085418165\n",
      "bc1_loss =  0.08561275\n",
      "bc2_loss =  0.00043476617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  25000\n",
      "loss =  0.25040537\n",
      "eq1_loss =  0.027211862\n",
      "ic1_loss =  0.13278432\n",
      "bc1_loss =  0.09010574\n",
      "bc2_loss =  0.0003034575\n",
      "epoch =  25200\n",
      "loss =  0.16475064\n",
      "eq1_loss =  0.026941108\n",
      "ic1_loss =  0.07494194\n",
      "bc1_loss =  0.06253875\n",
      "bc2_loss =  0.0003288318\n",
      "epoch =  25400\n",
      "loss =  0.19795671\n",
      "eq1_loss =  0.026769139\n",
      "ic1_loss =  0.090927504\n",
      "bc1_loss =  0.07986197\n",
      "bc2_loss =  0.00039809995\n",
      "epoch =  25600\n",
      "loss =  0.23058105\n",
      "eq1_loss =  0.025392244\n",
      "ic1_loss =  0.13610213\n",
      "bc1_loss =  0.06870815\n",
      "bc2_loss =  0.0003785261\n",
      "epoch =  25800\n",
      "loss =  0.26130047\n",
      "eq1_loss =  0.02474439\n",
      "ic1_loss =  0.16091025\n",
      "bc1_loss =  0.075158894\n",
      "bc2_loss =  0.0004869443\n",
      "epoch =  26000\n",
      "loss =  0.22483808\n",
      "eq1_loss =  0.02516749\n",
      "ic1_loss =  0.10187923\n",
      "bc1_loss =  0.097395316\n",
      "bc2_loss =  0.00039604056\n",
      "epoch =  26200\n",
      "loss =  0.24065745\n",
      "eq1_loss =  0.024256054\n",
      "ic1_loss =  0.121483766\n",
      "bc1_loss =  0.094530776\n",
      "bc2_loss =  0.00038684547\n",
      "epoch =  26400\n",
      "loss =  0.2032077\n",
      "eq1_loss =  0.023611253\n",
      "ic1_loss =  0.12259344\n",
      "bc1_loss =  0.056678478\n",
      "bc2_loss =  0.00032453044\n",
      "epoch =  26600\n",
      "loss =  0.22905621\n",
      "eq1_loss =  0.023020256\n",
      "ic1_loss =  0.115156405\n",
      "bc1_loss =  0.09050077\n",
      "bc2_loss =  0.0003787898\n",
      "epoch =  26800\n",
      "loss =  0.19239287\n",
      "eq1_loss =  0.022078404\n",
      "ic1_loss =  0.09862727\n",
      "bc1_loss =  0.07123969\n",
      "bc2_loss =  0.00044751124\n",
      "epoch =  27000\n",
      "loss =  0.14497723\n",
      "eq1_loss =  0.02171136\n",
      "ic1_loss =  0.04531755\n",
      "bc1_loss =  0.07760887\n",
      "bc2_loss =  0.0003394411\n",
      "epoch =  27200\n",
      "loss =  0.2503941\n",
      "eq1_loss =  0.021461027\n",
      "ic1_loss =  0.13584858\n",
      "bc1_loss =  0.0927142\n",
      "bc2_loss =  0.00037030946\n",
      "epoch =  27400\n",
      "loss =  0.18444908\n",
      "eq1_loss =  0.020071404\n",
      "ic1_loss =  0.090991534\n",
      "bc1_loss =  0.07307474\n",
      "bc2_loss =  0.0003114065\n",
      "epoch =  27600\n",
      "loss =  0.2097433\n",
      "eq1_loss =  0.018988043\n",
      "ic1_loss =  0.113429576\n",
      "bc1_loss =  0.07702559\n",
      "bc2_loss =  0.00030009623\n",
      "epoch =  27800\n",
      "loss =  0.24853551\n",
      "eq1_loss =  0.020198798\n",
      "ic1_loss =  0.14573011\n",
      "bc1_loss =  0.08236174\n",
      "bc2_loss =  0.0002448651\n",
      "epoch =  28000\n",
      "loss =  0.24708797\n",
      "eq1_loss =  0.01958102\n",
      "ic1_loss =  0.15037476\n",
      "bc1_loss =  0.07684217\n",
      "bc2_loss =  0.00029002965\n",
      "epoch =  28200\n",
      "loss =  0.22489502\n",
      "eq1_loss =  0.019225946\n",
      "ic1_loss =  0.13217837\n",
      "bc1_loss =  0.07323745\n",
      "bc2_loss =  0.0002532557\n",
      "epoch =  28400\n",
      "loss =  0.18304047\n",
      "eq1_loss =  0.018801711\n",
      "ic1_loss =  0.08826446\n",
      "bc1_loss =  0.07566862\n",
      "bc2_loss =  0.00030568082\n",
      "epoch =  28600\n",
      "loss =  0.16704985\n",
      "eq1_loss =  0.017736908\n",
      "ic1_loss =  0.06936043\n",
      "bc1_loss =  0.079670995\n",
      "bc2_loss =  0.0002815183\n",
      "epoch =  28800\n",
      "loss =  0.16393147\n",
      "eq1_loss =  0.018498965\n",
      "ic1_loss =  0.06903086\n",
      "bc1_loss =  0.076152265\n",
      "bc2_loss =  0.00024938426\n",
      "epoch =  29000\n",
      "loss =  0.15270415\n",
      "eq1_loss =  0.017419871\n",
      "ic1_loss =  0.06294807\n",
      "bc1_loss =  0.072028704\n",
      "bc2_loss =  0.0003074984\n",
      "epoch =  29200\n",
      "loss =  0.25619698\n",
      "eq1_loss =  0.01757751\n",
      "ic1_loss =  0.1444239\n",
      "bc1_loss =  0.09391299\n",
      "bc2_loss =  0.00028255588\n",
      "epoch =  29400\n",
      "loss =  0.11323623\n",
      "eq1_loss =  0.01749109\n",
      "ic1_loss =  0.021580806\n",
      "bc1_loss =  0.07390922\n",
      "bc2_loss =  0.00025511652\n",
      "epoch =  29600\n",
      "loss =  0.14234309\n",
      "eq1_loss =  0.01744871\n",
      "ic1_loss =  0.041053094\n",
      "bc1_loss =  0.08360593\n",
      "bc2_loss =  0.00023535945\n",
      "epoch =  29800\n",
      "loss =  0.16797811\n",
      "eq1_loss =  0.017031316\n",
      "ic1_loss =  0.05673193\n",
      "bc1_loss =  0.093992755\n",
      "bc2_loss =  0.0002221112\n",
      "epoch =  30000\n",
      "loss =  0.17742884\n",
      "eq1_loss =  0.016321508\n",
      "ic1_loss =  0.09404189\n",
      "bc1_loss =  0.06680227\n",
      "bc2_loss =  0.0002631771\n",
      "epoch =  30200\n",
      "loss =  0.20010848\n",
      "eq1_loss =  0.01606411\n",
      "ic1_loss =  0.08919058\n",
      "bc1_loss =  0.09464331\n",
      "bc2_loss =  0.00021048862\n",
      "epoch =  30400\n",
      "loss =  0.20834719\n",
      "eq1_loss =  0.015925448\n",
      "ic1_loss =  0.114510134\n",
      "bc1_loss =  0.07766068\n",
      "bc2_loss =  0.00025091905\n",
      "epoch =  30600\n",
      "loss =  0.13884299\n",
      "eq1_loss =  0.01651639\n",
      "ic1_loss =  0.032630015\n",
      "bc1_loss =  0.08945483\n",
      "bc2_loss =  0.00024175292\n",
      "epoch =  30800\n",
      "loss =  0.13726\n",
      "eq1_loss =  0.015524318\n",
      "ic1_loss =  0.05530296\n",
      "bc1_loss =  0.06622147\n",
      "bc2_loss =  0.00021126108\n",
      "epoch =  31000\n",
      "loss =  0.15366876\n",
      "eq1_loss =  0.015594491\n",
      "ic1_loss =  0.07096617\n",
      "bc1_loss =  0.06682002\n",
      "bc2_loss =  0.00028809177\n",
      "epoch =  31200\n",
      "loss =  0.15396506\n",
      "eq1_loss =  0.015257678\n",
      "ic1_loss =  0.068128675\n",
      "bc1_loss =  0.07032834\n",
      "bc2_loss =  0.00025037042\n",
      "epoch =  31400\n",
      "loss =  0.1326847\n",
      "eq1_loss =  0.015792564\n",
      "ic1_loss =  0.07120304\n",
      "bc1_loss =  0.045476113\n",
      "bc2_loss =  0.00021298259\n",
      "epoch =  31600\n",
      "loss =  0.14163071\n",
      "eq1_loss =  0.015376606\n",
      "ic1_loss =  0.06958474\n",
      "bc1_loss =  0.056472164\n",
      "bc2_loss =  0.00019718659\n",
      "epoch =  31800\n",
      "loss =  0.10816822\n",
      "eq1_loss =  0.015402208\n",
      "ic1_loss =  0.03728614\n",
      "bc1_loss =  0.055292692\n",
      "bc2_loss =  0.00018717952\n",
      "epoch =  32000\n",
      "loss =  0.10040464\n",
      "eq1_loss =  0.015697965\n",
      "ic1_loss =  0.029713832\n",
      "bc1_loss =  0.05484405\n",
      "bc2_loss =  0.0001487939\n",
      "epoch =  32200\n",
      "loss =  0.20172562\n",
      "eq1_loss =  0.015171383\n",
      "ic1_loss =  0.11673739\n",
      "bc1_loss =  0.06963731\n",
      "bc2_loss =  0.0001795399\n",
      "epoch =  32400\n",
      "loss =  0.16534074\n",
      "eq1_loss =  0.014842683\n",
      "ic1_loss =  0.09548438\n",
      "bc1_loss =  0.054802876\n",
      "bc2_loss =  0.00021079503\n",
      "epoch =  32600\n",
      "loss =  0.10905684\n",
      "eq1_loss =  0.014750786\n",
      "ic1_loss =  0.025954768\n",
      "bc1_loss =  0.06816514\n",
      "bc2_loss =  0.00018614266\n",
      "epoch =  32800\n",
      "loss =  0.124240786\n",
      "eq1_loss =  0.014965005\n",
      "ic1_loss =  0.039174493\n",
      "bc1_loss =  0.069954306\n",
      "bc2_loss =  0.00014697638\n",
      "epoch =  33000\n",
      "loss =  0.11151259\n",
      "eq1_loss =  0.015110632\n",
      "ic1_loss =  0.04107611\n",
      "bc1_loss =  0.05515901\n",
      "bc2_loss =  0.00016683078\n",
      "epoch =  33200\n",
      "loss =  0.14324093\n",
      "eq1_loss =  0.014891199\n",
      "ic1_loss =  0.06807427\n",
      "bc1_loss =  0.060088206\n",
      "bc2_loss =  0.0001872452\n",
      "epoch =  33400\n",
      "loss =  0.13712142\n",
      "eq1_loss =  0.01457056\n",
      "ic1_loss =  0.053516284\n",
      "bc1_loss =  0.06890878\n",
      "bc2_loss =  0.0001257943\n",
      "epoch =  33600\n",
      "loss =  0.15449756\n",
      "eq1_loss =  0.014012656\n",
      "ic1_loss =  0.092197284\n",
      "bc1_loss =  0.048179764\n",
      "bc2_loss =  0.00010784945\n",
      "epoch =  33800\n",
      "loss =  0.12577865\n",
      "eq1_loss =  0.014297252\n",
      "ic1_loss =  0.0307629\n",
      "bc1_loss =  0.08056611\n",
      "bc2_loss =  0.00015238159\n",
      "epoch =  34000\n",
      "loss =  0.086685516\n",
      "eq1_loss =  0.014857444\n",
      "ic1_loss =  0.023232833\n",
      "bc1_loss =  0.048450977\n",
      "bc2_loss =  0.00014426626\n",
      "epoch =  34200\n",
      "loss =  0.10043301\n",
      "eq1_loss =  0.01406905\n",
      "ic1_loss =  0.029939609\n",
      "bc1_loss =  0.056277357\n",
      "bc2_loss =  0.0001469923\n",
      "epoch =  34400\n",
      "loss =  0.09348623\n",
      "eq1_loss =  0.014009552\n",
      "ic1_loss =  0.01495695\n",
      "bc1_loss =  0.06440027\n",
      "bc2_loss =  0.00011945437\n",
      "epoch =  34600\n",
      "loss =  0.13315634\n",
      "eq1_loss =  0.014220605\n",
      "ic1_loss =  0.04941031\n",
      "bc1_loss =  0.06942154\n",
      "bc2_loss =  0.000103888175\n",
      "epoch =  34800\n",
      "loss =  0.135844\n",
      "eq1_loss =  0.0139865875\n",
      "ic1_loss =  0.06353463\n",
      "bc1_loss =  0.05819499\n",
      "bc2_loss =  0.00012779557\n",
      "epoch =  35000\n",
      "loss =  0.11609699\n",
      "eq1_loss =  0.013826689\n",
      "ic1_loss =  0.032618184\n",
      "bc1_loss =  0.06955579\n",
      "bc2_loss =  9.632729e-05\n",
      "epoch =  35200\n",
      "loss =  0.15395686\n",
      "eq1_loss =  0.013515119\n",
      "ic1_loss =  0.07679584\n",
      "bc1_loss =  0.06357914\n",
      "bc2_loss =  6.675144e-05\n",
      "epoch =  35400\n",
      "loss =  0.087656245\n",
      "eq1_loss =  0.013622626\n",
      "ic1_loss =  0.02494005\n",
      "bc1_loss =  0.049004033\n",
      "bc2_loss =  8.953512e-05\n",
      "epoch =  35600\n",
      "loss =  0.12869827\n",
      "eq1_loss =  0.013526132\n",
      "ic1_loss =  0.06247039\n",
      "bc1_loss =  0.052586183\n",
      "bc2_loss =  0.00011556675\n",
      "epoch =  35800\n",
      "loss =  0.13948187\n",
      "eq1_loss =  0.013337621\n",
      "ic1_loss =  0.054146104\n",
      "bc1_loss =  0.07191366\n",
      "bc2_loss =  8.4486644e-05\n",
      "epoch =  36000\n",
      "loss =  0.09714232\n",
      "eq1_loss =  0.013151208\n",
      "ic1_loss =  0.04079153\n",
      "bc1_loss =  0.043118715\n",
      "bc2_loss =  8.086603e-05\n",
      "epoch =  36200\n",
      "loss =  0.14032505\n",
      "eq1_loss =  0.014065931\n",
      "ic1_loss =  0.042493638\n",
      "bc1_loss =  0.08365598\n",
      "bc2_loss =  0.000109509536\n",
      "epoch =  36400\n",
      "loss =  0.14099464\n",
      "eq1_loss =  0.013475486\n",
      "ic1_loss =  0.07767354\n",
      "bc1_loss =  0.049760208\n",
      "bc2_loss =  8.539522e-05\n",
      "epoch =  36600\n",
      "loss =  0.110007465\n",
      "eq1_loss =  0.012727791\n",
      "ic1_loss =  0.050826725\n",
      "bc1_loss =  0.046379946\n",
      "bc2_loss =  7.300437e-05\n",
      "epoch =  36800\n",
      "loss =  0.115947865\n",
      "eq1_loss =  0.012922083\n",
      "ic1_loss =  0.047109097\n",
      "bc1_loss =  0.055866923\n",
      "bc2_loss =  4.9759336e-05\n",
      "epoch =  37000\n",
      "loss =  0.09947325\n",
      "eq1_loss =  0.012823505\n",
      "ic1_loss =  0.028148498\n",
      "bc1_loss =  0.058410596\n",
      "bc2_loss =  9.064858e-05\n",
      "epoch =  37200\n",
      "loss =  0.113905475\n",
      "eq1_loss =  0.012548942\n",
      "ic1_loss =  0.0634548\n",
      "bc1_loss =  0.037818693\n",
      "bc2_loss =  8.304167e-05\n",
      "epoch =  37400\n",
      "loss =  0.13616787\n",
      "eq1_loss =  0.012717611\n",
      "ic1_loss =  0.05027909\n",
      "bc1_loss =  0.073114395\n",
      "bc2_loss =  5.6773177e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  37600\n",
      "loss =  0.10391457\n",
      "eq1_loss =  0.012313427\n",
      "ic1_loss =  0.03392063\n",
      "bc1_loss =  0.057631582\n",
      "bc2_loss =  4.8930076e-05\n",
      "epoch =  37800\n",
      "loss =  0.14541823\n",
      "eq1_loss =  0.012151354\n",
      "ic1_loss =  0.0734401\n",
      "bc1_loss =  0.059750672\n",
      "bc2_loss =  7.61052e-05\n",
      "epoch =  38000\n",
      "loss =  0.10580603\n",
      "eq1_loss =  0.012116948\n",
      "ic1_loss =  0.023403788\n",
      "bc1_loss =  0.07023633\n",
      "bc2_loss =  4.8966012e-05\n",
      "epoch =  38200\n",
      "loss =  0.10680693\n",
      "eq1_loss =  0.012324966\n",
      "ic1_loss =  0.0459786\n",
      "bc1_loss =  0.048464336\n",
      "bc2_loss =  3.9025887e-05\n",
      "epoch =  38400\n",
      "loss =  0.12776937\n",
      "eq1_loss =  0.01196726\n",
      "ic1_loss =  0.06654826\n",
      "bc1_loss =  0.04917553\n",
      "bc2_loss =  7.8320576e-05\n",
      "epoch =  38600\n",
      "loss =  0.07406546\n",
      "eq1_loss =  0.011685378\n",
      "ic1_loss =  0.02797236\n",
      "bc1_loss =  0.034350682\n",
      "bc2_loss =  5.704361e-05\n",
      "epoch =  38800\n",
      "loss =  0.07423111\n",
      "eq1_loss =  0.011329705\n",
      "ic1_loss =  0.022860577\n",
      "bc1_loss =  0.040000726\n",
      "bc2_loss =  4.0101964e-05\n",
      "epoch =  39000\n",
      "loss =  0.15080523\n",
      "eq1_loss =  0.011788533\n",
      "ic1_loss =  0.054533042\n",
      "bc1_loss =  0.08444296\n",
      "bc2_loss =  4.0711722e-05\n",
      "epoch =  39200\n",
      "loss =  0.07977405\n",
      "eq1_loss =  0.010950985\n",
      "ic1_loss =  0.021464687\n",
      "bc1_loss =  0.047315005\n",
      "bc2_loss =  4.337307e-05\n",
      "epoch =  39400\n",
      "loss =  0.13042094\n",
      "eq1_loss =  0.01124968\n",
      "ic1_loss =  0.05316124\n",
      "bc1_loss =  0.065961674\n",
      "bc2_loss =  4.834433e-05\n",
      "epoch =  39600\n",
      "loss =  0.09303333\n",
      "eq1_loss =  0.011008101\n",
      "ic1_loss =  0.047627077\n",
      "bc1_loss =  0.03434361\n",
      "bc2_loss =  5.453296e-05\n",
      "epoch =  39800\n",
      "loss =  0.08557428\n",
      "eq1_loss =  0.01062091\n",
      "ic1_loss =  0.04048664\n",
      "bc1_loss =  0.03444395\n",
      "bc2_loss =  2.2775142e-05\n"
     ]
    }
   ],
   "source": [
    "N_x = 35\n",
    "N_t = 35\n",
    "N_bc = 100\n",
    "N_ic = 100\n",
    "x_l = 0\n",
    "x_r = 0.7\n",
    "t_i = 0\n",
    "t_f = 0.8\n",
    "del_t = (t_f - (t_i + 0.001))/(N_t - 1)\n",
    "del_x = (x_r - x_l - 0.002)/(N_x - 1)\n",
    "T_l = 1.0\n",
    "T_r = 0.0\n",
    "T_ini = 0\n",
    "\n",
    "# Neural network params\n",
    "input_size = 2\n",
    "hidden_size = [45, 45, 45, 45, 45, 45]\n",
    "output_size = 1\n",
    "\n",
    "# material params\n",
    "k1 = 0.05\n",
    "\n",
    "# Training data and initial data\n",
    "model = FVMANN(input_size, hidden_size, output_size)\n",
    "model.apply(xavier_init)\n",
    "print(model)\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters in the model:\", total_trainable_params)\n",
    "\n",
    "# Setup Loss function and Optimiser\n",
    "learning_rate = 6e-6\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "epochs = 40000\n",
    "\n",
    "# Training model\n",
    "loss_store = train_model(model, optimiser, epochs, T_r, T_l, k1, N_x, x_l, x_r, del_x, N_t, t_i, t_f, del_t, N_bc, N_ic, T_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a0639ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x163dfdde040>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x = np.linspace(1, len(loss_store), len(loss_store))\n",
    "plt.plot(loss_store[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0ab96f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x163d48cde50>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_test = 2000\n",
    "\n",
    "t_pred = 0.5\n",
    "x_test = torch.linspace(x_r,x_l,N_test)\n",
    "t_test = torch.ones(N_test)*t_pred\n",
    "x_test = x_test.unsqueeze(-1)\n",
    "t_test = t_test.unsqueeze(-1)\n",
    "x_test = x_test.clone().detach().requires_grad_(True)\n",
    "t_test = t_test.clone().detach().requires_grad_(True)\n",
    "\n",
    "y_pred,_,_  = model(x_test, t_test )\n",
    "y_pred = y_pred.detach().numpy()\n",
    "x_test = x_test.detach().numpy()\n",
    "plt.plot(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb4ef4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00704656],\n",
       "       [-0.00702681],\n",
       "       [-0.00700656],\n",
       "       ...,\n",
       "       [ 0.85293835],\n",
       "       [ 0.8569879 ],\n",
       "       [ 0.8610435 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
