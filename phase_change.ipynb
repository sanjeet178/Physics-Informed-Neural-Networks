{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88668b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:- 0.10816795 , epoch:- 0\n",
      "[-0.11605412 -0.11607751 -0.1159729  ... -0.1158939  -0.11591733\n",
      " -0.1158939 ]\n",
      "loss:- 0.059308853 , epoch:- 100\n",
      "[-0.06824972 -0.06825901 -0.06821778 ... -0.06818705 -0.06819614\n",
      " -0.06818705]\n",
      "loss:- 0.04388252 , epoch:- 200\n",
      "[-0.02443825 -0.02443747 -0.0244422  ... -0.02444755 -0.0244458\n",
      " -0.02444755]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "\n",
    "# Define the number of outputs and the learning rate\n",
    "n_input_1 = 2\n",
    "n_input_2 = 1\n",
    "n_nodes_hl1 = 30\n",
    "n_nodes_hl2 = 30\n",
    "n_nodes_hl3 = 30\n",
    "n_nodes_hl4 = 30\n",
    "n_nodes_hl5 = 30\n",
    "n_nodes_hl6 = 30\n",
    "n_nodes_hl7 = 30\n",
    "n_nodes_hl8 = 30\n",
    "n_output = 1\n",
    "learn_rate = 0.00002\n",
    "\n",
    "# Boundary Conditions\n",
    "left_temp = 1\n",
    "right_temp = 0\n",
    "x_l = 0\n",
    "C1 = 2.0\n",
    "C2 = 2.0\n",
    "s_ini = 0.1\n",
    "T = 0\n",
    "ini_temp = 0\n",
    "\n",
    "# training data\n",
    "t_pred = 0.6\n",
    "N = 8000\n",
    "N1 = 400 # Number of datapoints to describe B.C's\n",
    "a = 0\n",
    "b = 1\n",
    "diff = (b-a)/N\n",
    "x = []\n",
    "t = []\n",
    "x1 = []\n",
    "t1 = []\n",
    "for i in range(N):\n",
    "    x1.append(a+i*diff) \n",
    "    t1.append(t_pred)\n",
    "    x.append(random.uniform(0, 1))\n",
    "    t.append(random.uniform(0, 1))\n",
    "    if(i==N-1):\n",
    "        for j in range(N1):\n",
    "            x.append(0)\n",
    "            t.append(random.uniform(0, 1))\n",
    "            x.append(random.uniform(0, 1))\n",
    "            t.append(0)\n",
    "            \n",
    "x1 = np.array(x1)\n",
    "x1 = x1.reshape((N,1))\n",
    "t1 = np.array(t1)\n",
    "t1 = t1.reshape((N,1))\n",
    "N = N + 2*N1            \n",
    "x = np.array(x)\n",
    "x = x.reshape((N,1))\n",
    "t = np.array(t)\n",
    "t = t.reshape((N,1))\n",
    "\n",
    "# Placeholders\n",
    "x_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "t_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "s_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "Ts_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 15000\n",
    "\n",
    "# Define standard deviation for initialising weights and biases from normal distribution.\n",
    "hl_sigma = 0.1\n",
    "\n",
    "def NN1(x2, t2):\n",
    "    data = tf.concat([x2, t2], 1)\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    hidden_1_layer = {'weights': tf.Variable(tf.random.normal([n_input_1, n_nodes_hl1],stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl1], stddev=hl_sigma))}\n",
    "    hidden_2_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl2], stddev=hl_sigma))}\n",
    "    hidden_3_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl2, n_nodes_hl3], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl3], stddev=hl_sigma))}\n",
    "    hidden_4_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl3, n_nodes_hl4], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl4], stddev=hl_sigma))}\n",
    "    hidden_5_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl4, n_nodes_hl5], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl5], stddev=hl_sigma))}\n",
    "    hidden_6_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl5, n_nodes_hl6], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl6], stddev=hl_sigma))}\n",
    "    hidden_7_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl6, n_nodes_hl7], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl7], stddev=hl_sigma))}\n",
    "    hidden_8_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl7, n_nodes_hl8], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl8], stddev=hl_sigma))}\n",
    "    output_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl8, n_output], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_output], stddev=hl_sigma))}\n",
    "           \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.tanh(l1)   \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.tanh(l2)\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.tanh(l3)\n",
    "    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.tanh(l4)\n",
    "    l5 = tf.add(tf.matmul(l4, hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    l5 = tf.nn.tanh(l5)\n",
    "    l6 = tf.add(tf.matmul(l5, hidden_6_layer['weights']), hidden_6_layer['biases'])\n",
    "    l6 = tf.nn.tanh(l6)\n",
    "    l7 = tf.add(tf.matmul(l6, hidden_7_layer['weights']), hidden_7_layer['biases'])\n",
    "    l7 = tf.nn.tanh(l7)\n",
    "    l8 = tf.add(tf.matmul(l7, hidden_8_layer['weights']), hidden_8_layer['biases'])\n",
    "    l8 = tf.nn.tanh(l8)\n",
    "    output = tf.add(tf.matmul(l8, output_layer['weights']), output_layer['biases'], name='output')\n",
    "    return output\n",
    "\n",
    "def NN2(t2):\n",
    "    \n",
    "    data = tf.cast(t2, tf.float32)\n",
    "    hidden_1_layer = {'weights': tf.Variable(tf.random.normal([n_input_2, n_nodes_hl1],stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl1], stddev=hl_sigma))}\n",
    "    hidden_2_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl2], stddev=hl_sigma))}\n",
    "    hidden_3_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl2, n_nodes_hl3], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl3], stddev=hl_sigma))}\n",
    "    hidden_4_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl3, n_nodes_hl4], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl4], stddev=hl_sigma))}\n",
    "    hidden_5_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl4, n_nodes_hl5], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl5], stddev=hl_sigma))}\n",
    "    hidden_6_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl5, n_nodes_hl6], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl6], stddev=hl_sigma))}\n",
    "    hidden_7_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl6, n_nodes_hl7], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl7], stddev=hl_sigma))}\n",
    "    hidden_8_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl7, n_nodes_hl8], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl8], stddev=hl_sigma))}\n",
    "    output_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl8, n_output], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_output], stddev=hl_sigma))}\n",
    "           \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.tanh(l1)   \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.tanh(l2)\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.tanh(l3)\n",
    "    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.tanh(l4)\n",
    "    l5 = tf.add(tf.matmul(l4, hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    l5 = tf.nn.tanh(l5)\n",
    "    l6 = tf.add(tf.matmul(l5, hidden_6_layer['weights']), hidden_6_layer['biases'])\n",
    "    l6 = tf.nn.tanh(l6)\n",
    "    l7 = tf.add(tf.matmul(l6, hidden_7_layer['weights']), hidden_7_layer['biases'])\n",
    "    l7 = tf.nn.tanh(l7)\n",
    "    l8 = tf.add(tf.matmul(l7, hidden_8_layer['weights']), hidden_8_layer['biases'])\n",
    "    l8 = tf.nn.tanh(l8)\n",
    "    output = tf.add(tf.matmul(l8, output_layer['weights']), output_layer['biases'], name='output')\n",
    "    return output\n",
    "\n",
    "def train_neural_network_batch():\n",
    "    u = NN1(x_ph,t_ph)  \n",
    "    dudx = tf.gradients(u, x_ph)\n",
    "    dudx2 = tf.gradients(tf.gradients(u, x_ph), x_ph)\n",
    "    dudt = tf.gradients(u, t_ph)\n",
    "    \n",
    "    s = NN2(t_ph)\n",
    "    Ts = NN1(s, t_ph) \n",
    "    dTsdx = tf.gradients(Ts, s)\n",
    "    dsdt = tf.gradients(s, t_ph)\n",
    "    \n",
    "        \n",
    "    cost = tf.reduce_mean( tf.square((dudt-tf.constant(C1)*dudx2)*tf.cast(tf.less_equal(x_ph,s), tf.float32)) \n",
    "                          + tf.square(tf.cast(tf.equal(x_ph,x_l), tf.float32)*(u-left_temp)) \n",
    "                          + 15*tf.square(Ts-right_temp) \n",
    "                          + tf.square(tf.cast(tf.equal(t_ph,T), tf.float32)*(u-ini_temp)) \n",
    "                          + 15*tf.square(dsdt+tf.constant(C2)*dTsdx) \n",
    "                          + 15*tf.square(tf.cast(tf.equal(t_ph,T), tf.float32)*(s - s_ini)) )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            _, l = sess.run([optimizer,cost], feed_dict={x_ph:x, t_ph:t})\n",
    "            \n",
    "            if(epoch % 100 == 0):\n",
    "                print('loss:-',l,', epoch:-',epoch)\n",
    "                print( sess.run(tf.squeeze(s),{t_ph:t}) )\n",
    "                if(l<=0.00005):\n",
    "                    break\n",
    "\n",
    "        # Validation\n",
    "        return sess.run(tf.squeeze(s),{t_ph:t1}), sess.run(tf.squeeze(u),{x_ph:x1, t_ph:t1}), x1\n",
    "    \n",
    "# Run the code                              \n",
    "s_pred, y_pred ,x_pred = train_neural_network_batch()\n",
    "y_pred = y_pred.reshape(N-2*N1,1)\n",
    "\n",
    "# Plot\n",
    "cnt = 0\n",
    "for i in range(len(x_pred)):\n",
    "    cnt = cnt+1\n",
    "    if x_pred[i]>s_pred[i]:\n",
    "        break\n",
    "    \n",
    "plt.plot(x_pred[0:cnt], y_pred[0:cnt], label ='NN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22d355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a9209230d0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi6klEQVR4nO3deXhV5b328e8vM2GGhABJgDAKAjKEAAEFxQFHFFFA0YoDg0Cttfb0beupr22PbdWqqMxaihMiqFAHUFDGABLmeQgQCGOYZ0LI8/6RnL4pAglkJyt75/5cV65r770We98PITcra3iWOecQERH/F+R1ABER8Q0VuohIgFChi4gECBW6iEiAUKGLiASIEK8+OCoqytWrV8+rjxcR8UtLly494JyLvtgyzwq9Xr16pKamevXxIiJ+yczSL7VMu1xERAKECl1EJECo0EVEAoQKXUQkQKjQRUQChApdRCRAqNBFRAKE3xX69gMn+dv0DZzP0bS/IiL5+V2hf7tuLyNmp/HMxOVkZed4HUdEpNTw7ErRqzXghgYA/M/XGzh6+hyj+rWlfLjfDUNExOf8bgsdckv9lV4tSUk7yEPjFnPoZJbXkUREPOeXhQ7wQGI8o/q1ZcOeYzwwKoXdR057HUlExFN+W+gAtzSLYcLjSew/dpZeI1PYsv+E15FERDzj14UO0L5+dT4Z2JGs844HRqWwYucRryOJiHjC7wsdoFntSkwZ3JGKEaE8NHYR8zZneh1JRKTEFVjoZvaeme03szWXWG5mNtzMtpjZKjNr4/uYBatbvTyTB3WkTrVIHh+/hC9X7fYihoiIZwqzhT4e6H6Z5bcDjfK+BgAjix7r6tSoFMEnAzvSOr4qwz5ezvuLLjkPvIhIwCmw0J1zc4FDl1mlBzDB5VoEVDGzWr4KeKUqlwtlwhNJdLumBi98sYY3Z27GOV1VKiKBzxf70GOBnfmeZ+S99hNmNsDMUs0sNTOz+PZzR4QGM6pfW+5vE8frMzfx4rS15GiqABEJcCV6iaVzbgwwBiAxMbFYGzYkOIhXerWkWvlQxs7bxuFT53j1gesICwmI48AiIj/hi0LfBcTnex6X95rngoKM393ZjOoVwvnLNxs4cvoco/q1ITJMUwWISODxxebqNODRvLNdOgBHnXN7fPC+PjOoSwP+dn9L5m/O5OFxizlySlMFiEjgKcxpix8DC4EmZpZhZk+Y2SAzG5S3ytfAVmALMBZ4utjSFsGD7eIZ2a8ta3cf44FRC9lzVFMFiEhgMa/OAElMTHSpqakl/rkL0w7y1ITUf58N0yC6QolnEBG5Wma21DmXeLFlZe4IYccG1Zk4oANns8/zwKiFrMo44nUkERGfKHOFDtA8tjKfDkomMiyYvmMWsWDLAa8jiYgUWZksdICEqPJMGZxMXNVI+v9jCV+vLlXHcUVErliZLXSAmEoRTBrYkZZxlRny0TI+WrzD60giIletTBc6QOXIUN5/oj03NqnBbz9fzdvfa6oAEfFPZb7QAcqFBTP6kbb0bB3Lq99u4qUv12mqABHxO7pkMk9ocBCvPnAdVcuH8e78bRw5dY6/9WpJaLD+zxMR/6BCzycoyPj9nU2pVj6MV2Zs5MipLEY83JZyYcFeRxMRKZA2Py9gZgy5sSEv92zBnE2Z9HtXUwWIiH9QoV9C36Q6jHi4DaszjtJ79CL2Hj3jdSQRkctSoV9G9+a1GN+/HRmHT3H/yBS2HTjpdSQRkUtSoRcguWEUEwd05My58/QamcLqjKNeRxIRuSgVeiG0iKvMp4M6EhEaTJ8xC5m/WVMFiEjpo0IvpPrRFfjs6WTiq0XSf/yPTF1RKu7hISLybyr0KxBTKYJPBnakTZ2qPDNxBePmbfU6kojIv6nQr1DlcqH88/Ekbm9ekz99tZ6Xv1mvqQJEpFRQoV+FiNBg3n6oDf061GH0nK089+lKzp3P8TqWiJRxulL0KgUHGX/s0ZyYihG89t0mDp7IYsTDbSgfrr9SEfGGttCLwMwY1q0Rf+nZgnmbM3lo7CIOnjjrdSwRKaNU6D7QJ6kOox9JZMPe4/QatZCdh055HUlEyiAVuo/c0iyGD59sz6GTWfQcmcK63ce8jiQiZYwK3YcS61Xj00EdCQkyeo9eSEqaLkASkZKjQvexxjEVmTI4mZqVI3jsvSV8tUr3KhWRkqFCLwa1q5Tj00G59yod+vEyJizc7nUkESkDVOjFpEpkGB882Z5u18Tw31PX8uqMjboASUSKlQq9GEWEBjOqXxv6tIvn7R+28F9TVpGtC5BEpJgUqtDNrLuZbTSzLWb2m4ssr2tms8xslZnNNrM430f1TyHBQbzcswU/v6khk1IzGPj+Uk5nnfc6logEoAIL3cyCgXeA24FmQF8za3bBaq8CE5xzLYGXgJd9HdSfmRm/vLUJf7y3Od9v3M/D4xZx+KRuaycivlWYLfQkYItzbqtzLguYCPS4YJ1mwPd5j3+4yHIBHulQlxEPtWHNrmP0GpVCxmFdgCQivlOYQo8FduZ7npH3Wn4rgZ55j+8DKppZ9QvfyMwGmFmqmaVmZmZeTV6/d3uLWkx4Ion9x8/Sc0QKa3frDkgi4hu+Oij6K6CLmS0HugC7gJ/sKHbOjXHOJTrnEqOjo3300f6nQ/3qTB6UTHCQ0Xv0IuZtLpv/uYmIbxWm0HcB8fmex+W99m/Oud3OuZ7OudbA7/JeO+KrkIGoSc2KfPZ0MnFVy9H/H0uYsjTD60gi4ucKU+hLgEZmlmBmYUAfYFr+Fcwsysz+973+D/Ceb2MGplqVyzFpUEeSEqrx3Kcrefv7zTpXXUSuWoGF7pzLBoYCM4D1wCTn3Foze8nM7slbrSuw0cw2ATHAn4spb8CpFBHK+P5J3NuqNq9+u4nffr5G56qLyFUxr7YIExMTXWpqqiefXRrl5Dhe+XYjI2en0e2aGrz1UGsiw3SzDBH5T2a21DmXeLFlulK0lAgKMv6r+zX8sce1/LBxP33HLOKAbpYhIldAhV7KPNKxHqP6tWXjvuP0HJHCtgMnvY4kIn5ChV4K3XptTT56qgMnzmbTc8QClu047HUkEfEDKvRSqk2dqkwZnEylcqE8NHYR367d63UkESnlVOilWEJUeaYMTqZJTEUGfbCU9zWvuohchgq9lIuqEM7HAzpwY5MavDB1LX/5ZgM5OTpXXUR+SoXuByLDQhj9SFv6JtVh1Jw0np20grPZmoJXRP6TTnT2EyHBQfzPfc2Jq1qOV2ZsZM/RM4x5pC1VIsO8jiYipYS20P2ImTHkxoa82acVK3YcoeeIFNIP6rRGEcmlQvdDPVrF8sGT7Tl0Kov7RqSwNP2Q15FEpBRQofuppIRqfDY4mUoRIfQdu5gvV+32OpKIeEyF7sfqR1fgs6c70TK2MkM/Ws7I2WmarVGkDFOh+7lq5cP44Mn23H1dbf46fQO//Xw15zRbo0iZpLNcAkBEaDBv9m5FnWrleOeHNDIOn+adh9tQKSLU62giUoK0hR4ggoKM52+7hr/e34KFaQd5YORCdh057XUsESlBKvQA07tdHcb3T2L3kdPc984CVmfoJtQiZYUKPQB1bhTF5MHJhAYH8eDohcxct8/rSCJSAlToAapJzYp8/nQyDWtUYMD7qYxfsM3rSCJSzFToAaxGpQg+GdiBm66J4cV/reMPU3W/UpFApkIPcP87sdcTnRP458J0Hv9nKsfOnPM6logUAxV6GRAcZLxwVzNe7tmClC0H6DkihR0HT3kdS0R8TIVehvRNqsOEJ5LIPH6WHu/M58dtmgNGJJCo0MuY5AZRfDGkE1Ujw3h43CI+Td3pdSQR8REVehmUEFWez5/uRFJCNZ6fvIqXv1mvuyCJBAAVehlVOTKU8f2TeLh9HUbP2crAD5Zy8my217FEpAhU6GVYaHAQf7q3OX+4uxmz1u+j16iF7NZ0ASJ+q1CFbmbdzWyjmW0xs99cZHkdM/vBzJab2Sozu8P3UaU4mBn9OyXw7mPt2HnoFD3eWcCKnUe8jiUiV6HAQjezYOAd4HagGdDXzJpdsNrvgUnOudZAH2CEr4NK8bqxSQ0+ezqZiNAgeo9eyL9W6oYZIv6mMFvoScAW59xW51wWMBHoccE6DqiU97gyoDbwQ41jKvLF051oGVeZYR8v5/XvNulgqYgfKUyhxwL5z23LyHstvxeBfmaWAXwNDLvYG5nZADNLNbPUzMzMq4grxa16hXA+eLI997eJ481Zmxny0TIdLBXxE746KNoXGO+ciwPuAN43s5+8t3NujHMu0TmXGB0d7aOPFl8LDwnm1Qda8vs7mzJj7V7uH5nCzkO6slSktCtMoe8C4vM9j8t7Lb8ngEkAzrmFQAQQ5YuA4g0z48nr6/OPvLnV73l7PilpB7yOJSKXUZhCXwI0MrMEMwsj96DntAvW2QF0AzCzpuQWuvapBIAujaOZOrQz1SuE88i7PzJh4XbdiFqklCqw0J1z2cBQYAawntyzWdaa2Utmdk/eas8BT5nZSuBj4DGnn/qAkXtlaTJdG0fz31PX8tvPV5OVrWl4RUob86p3ExMTXWpqqiefLVfnfI7jtW83MmJ2Gol1qzKyX1uiK4Z7HUukTDGzpc65xIst05WiUmjBQcavu1/DW31bs2b3Ue55e77uWSpSiqjQ5YrdfV1tJg9KxoBeo1KYuuLCY+Qi4gUVulyV5rGVmTasMy3jKvPMxBX8dfoGzusiJBFPqdDlqkVVCOfDJzvQN6kOI2en8fj4JRw5leV1LJEyS4UuRRIWEsTLPVvw5/uak5J2gLvfns/a3dqvLuIFFbr4xMPt6/LJwI6cy3bcPzKFz5dneB1JpMxRoYvPtKlTlX8N68x1cVV49pOVvDhtLefO63x1kZKiQhefiq6YO7nXE50TGJ+ynYfHLmb/8TNexxIpE1To4nOhwUG8cFcz3uzTitW7jnLX8PksTT/sdSyRgKdCl2LTo1Usnz2dTLmwYPqMWcj7i9I1D4xIMVKhS7FqWqsS04Z0pnPDKF74Yg3PT17FmXPnvY4lEpBU6FLsKkeG8u7P2vFMt0ZMXppBr1GaX12kOKjQpUQEBRnP3tKYd3+WSPrBU9w5fB4z1+3zOpZIQFGhS4nq1jSGr4ZdT3y1SJ6ckMrL36wnW6c2iviECl1KXJ3qkUwZnMxD7eswes5WHhq7mH3HdGqjSFGp0MUTEaHB/M99LXijd+6pjXcOn0fKFt3iTqQoVOjiqXtbxzJtaCeqRIbR793FvDVrMzmatVHkqqjQxXONYioydUgn7r6uNq99t4n+45dw6KRmbRS5Uip0KRXKh4fwRu9W/One5ixMO8idw+fp6lKRK6RCl1LDzOjXoS5TBicTEmz0Hr2Qd+dv09WlIoWkQpdSp0VcZb4cej1dm9Tgj1+u46kJqRzWLhiRAqnQpVSqHBnK2Efb8sJdzZizKZM7hs9j8daDXscSKdVU6FJqmRlPdE7gs8GdCAsJou/YRbw5c7PuXSpyCSp0KfVaxFXmy2Gdufu62rw+cxMPj1ukC5FELkKFLn6hYkQob/RuxSu9WrJy51Fuf3Me32/QXDAi+anQxW+YGQ8kxvOvYZ2pUTGcx8en8qcv15GVrblgRECFLn6oYY0KfDGkE492rMu4+dvoNSqF9IMnvY4l4rlCFbqZdTezjWa2xcx+c5Hlr5vZiryvTWZ2xOdJRfKJCA3mpR7NGdWvLdsPnOTO4fP5Yvkur2OJeKrAQjezYOAd4HagGdDXzJrlX8c596xzrpVzrhXwFvBZMWQV+YnuzWvy9TPXc03NivzikxX8/OPlHD19zutYIp4ozBZ6ErDFObfVOZcFTAR6XGb9vsDHvggnUhhxVSOZOKADz93SmK9W7+H2N+aySOesSxlUmEKPBXbme56R99pPmFldIAH4/hLLB5hZqpmlZmZmXmlWkUsKCQ5iWLdGTBmcTHhoMH3HLuIv32zQAVMpU3x9ULQPMNk5d9G7ADvnxjjnEp1zidHR0T7+aBFoFV+FL4d1pk+7eEbNSeO+EQvYsv+417FESkRhCn0XEJ/veVzeaxfTB+1uEY+VDw/h5Z4tGf1IW3YfOc2dw+fz/sLtmuRLAl5hCn0J0MjMEswsjNzSnnbhSmZ2DVAVWOjbiCJX57ZrazLjFzfQoX51Xpi6lsfHLyHz+FmvY4kUmwIL3TmXDQwFZgDrgUnOubVm9pKZ3ZNv1T7ARKfNIClFalSKYHz/drx4dzMWpB2k+xtzmblOV5hKYDKv+jcxMdGlpqZ68tlSNm3ad5xnJq5g/Z5jPJgYx+/vakaliFCvY4lcETNb6pxLvNgyXSkqZUbjmIp8MSSZp7s2YPLSDLq/Ppf5m3VjagkcKnQpU8JDgvl192uYMjiZiNBg+r27mBe+WMOprGyvo4kUmQpdyqTWdary1c+v5/FOCXywOJ3b35zHku2HvI4lUiQqdCmzyoUF8993N2PiUx3IcY4HRy/kz1+t48y5i15GIVLqqdClzGtfvzrTn7mBh5LqMHbeNu4cPo+VO494HUvkiqnQRci9GOnP97VgwuNJnMo6T8+RKfxt+gZtrYtfUaGL5HND42im/+IG7msdy4jZadw5fB5L07VvXfyDCl3kApXLhfLqA9fxz8eTOHMuh16jFvLitLWcPKszYaR0U6GLXEKXxtHMePYGHu1Ql/Ep27ntjbnM26xZQqX0UqGLXEaF8BD+b4/mfDqoI2EhQTzy7o/8evJK3URDSiUVukghtKtXja9/fj2DuzZgyrJd3PL3OcxYu9frWCL/QYUuUkgRocH8V/drmDqkE9UrhDPw/aUM+XAZ+4+d8TqaCKBCF7lizWMrM21oJ351a2O+W7+Pbn+fwweL0snJ0USj4i0VushVCA0OYuhNjZj+zPW0iK3M779Yw/2jUli/55jX0aQMU6GLFEH96Ap8+GR7Xu99HekHT3HXW/N5+Zv1muxLPKFCFykiM+O+1nF8/1wXHmgbx+g5W7n19bn8sGG/19GkjFGhi/hIlcgw/nJ/SyYN7EhEaDD9xy9hyIfL2KeDplJCVOgiPpaUkHuK4/O3NWHm+n3c/Noc/rFgG9nnc7yOJgFOhS5SDMJCghhyY0O+ffYGWtetyv/91zruems+i7ce9DqaBDAVukgxqlu9PP/s345R/dpy/Ew2vccs4hcTl+vcdSkWKnSRYmZmdG9ek5m/7MKwmxry9eq93PTaHMbN28o57YYRH1Khi5SQcmHBPHdrE7599gaSEqrxp6/Wc8eb80hJ042qxTdU6CIlrF5Ued57rB3jHk3kTPZ5Hhq7mCEfLWPP0dNeRxM/F+J1AJGy6uZmMXRuFMWoOWmMnJ3G9+v3M7hrA566vj7lwoK9jid+SFvoIh6KCA3mFzc3ZuYvu9C1STR//24T3V6bzdQVu3BOc8PIlVGhi5QC8dUiGdmvLRMHdKBq+TCembiCniNTWLbjsNfRxI8UqtDNrLuZbTSzLWb2m0us86CZrTOztWb2kW9jipQNHepX519DO/NKr5ZkHD5NzxEpPDNxObuPaP+6FMwK+rXOzIKBTcAtQAawBOjrnFuXb51GwCTgJufcYTOr4Zy77EQWiYmJLjU1taj5RQLWybPZjJydxth5WwEYeEN9BnZpQPlwHfoqy8xsqXMu8WLLCrOFngRscc5tdc5lAROBHhes8xTwjnPuMEBBZS4iBSsfHsKvbmvCrOe6cOu1NRn+/RZufHU2k5dmaO51uajCFHossDPf84y81/JrDDQ2swVmtsjMul/sjcxsgJmlmllqZqZutitSGHFVI3mrb2umDO5IrSrl+NWnK7nzrfnM2ZSpA6fyH3x1UDQEaAR0BfoCY82syoUrOefGOOcSnXOJ0dHRPvpokbKhbd1qfD44mTf7tOLE2XP87L0feXjcYlZnHPU6mpQShSn0XUB8vudxea/llwFMc86dc85tI3efeyPfRBSR/xUUZPRoFcvMX3bhD3c3Y8Pe49z99nyGfrSM9IMnvY4nHitMoS8BGplZgpmFAX2AaRes8wW5W+eYWRS5u2C2+i6miOQXHhJM/04JzHm+K8Nuasis9fvp9toc/jB1DQdOnPU6nnikwEJ3zmUDQ4EZwHpgknNurZm9ZGb35K02AzhoZuuAH4DnnXOaJ1SkmFWMCOW5W5sw5/muPNgung8W76DL337gzZmbOXlWt8Erawo8bbG46LRFEd9LyzzBqzM28s2avURVCOPprg15qH0dIkI1lUCguNxpiyp0kQC0bMdhXp2xkZS0g9SsFMHQmxryYGI8YSG6ONzfqdBFyqiULQd47btNLE0/TFzVcvy8WyN6to4lJFjF7q+KemGRiPip5IZRTB7UkfH921E1MoxfT17FLa/PZeqKXZzXxUkBR4UuEuDMjK5NajBtaCdGP9KW8JAgnpm4gtvfnMv0NXt01WkAUaGLlBFmxm3X1uTrn1/PW31bk53jGPTBMu4YPo8vV+3WFnsA0D50kTIq+3wO01bu5u0ftrA18yQNa1Rg6I0NuatlLe1jL8V0UFRELul8juPr1Xt46/vNbNp3gnrVIxlyY0PubR1LqIq91FGhi0iBcnIc367by/BZW1i35xhxVcsx5MaG3N8mTqc7liIqdBEpNOccs9bv563vN7My4yi1K0cwsEsDHkyM171OSwEVuohcMeccczcf4K1Zm0lNP0zVyFB+llyPn3WsR9XyYV7HK7NU6CJSJEu2H2LU7DRmbdhPudBgereL58nrE4irGul1tDJHhS4iPrFx73HGzN3K1BW7cMDdLWsxsEsDmtaq5HW0MkOFLiI+tfvIad6dv42Pf9zBqazzdG0SzaAuDWifUA0z8zpeQFOhi0ixOHIqiw8WpfOPBds5eDKL6+Kr8GTnBLo3r6lTHouJCl1EitWZc+eZvDSDcfO2sv3gKWpVjuDRjvXomxRPlUgdQPUlFbqIlIicHMcPG/fz3oJtLNhykHKhwdzfNpbHkhNoWKOC1/ECggpdRErchr3HeG/+Nr5YsZus7By6Nonmic4JdG4Ypf3sRaBCFxHPHDhxlo8W72DCwnQOnDhLoxoV6N8pgXtb1yYyLMTreH5HhS4injubfZ6vVu3h3fnbWLv7GBUjQri/TRz9OtTV7pgroEIXkVLDOUdq+mE+WJTO16v3cO68I7lBdfp1qMstzWJ0dkwBVOgiUiodOHGWT5bs5KPFO9h15DQ1KobTN6kOfZPqULNyhNfxSiUVuoiUaudzHLM37uf9RenM2ZRJkBm3NI2hX4e6dGpYXQdR87lcoeuIhIh4LjjI6NY0hm5NY9hx8BQf/pjOpCU7mb52L/WjytO7XTw928QRXTHc66ilmrbQRaRUOnPuPF+v3sOHi3ewNP0wIUHGTdfUoE9SPDc0ii6zd1XSLhcR8Wtb9h9nUmoGU5ZmcPBkFjGVwnmgbTwPJsZTp3rZmvFRhS4iASErO4fvN+zjkyU7mbMpkxwHHetXp09SPLddW5OI0MC/AUeRC93MugNvAsHAOOfcXy5Y/hjwCrAr76W3nXPjLveeKnQRKYo9R08zZWkGk1Iz2HHoFJUiQrinVW16tomjdXyVgD2QWqRCN7NgYBNwC5ABLAH6OufW5VvnMSDROTe0sKFU6CLiCzk5jkVbD/JJ6k5mrN3LmXM5JESV577WsdzXOpb4aoG1S6aoZ7kkAVucc1vz3mwi0ANYd9k/JSJSAoKCjOSGUSQ3jOL4mXN8s2Yvny/bxd+/28Tfv9tEUr1q3Ncmljta1KJyuVCv4xarwmyh9wK6O+eezHv+CNA+/9Z43hb6y0AmuVvzzzrndl7kvQYAAwDq1KnTNj093UfDEBH5T7uOnOaL5bv4bFkGaZknCQsJ4pamMfRsE8sNjaP99orUou5yKUyhVwdOOOfOmtlAoLdz7qbLva92uYhISXDOsXrXUT5btotpK3dz6GQW1cqHcXvzmtzVsjZJCdUIDvKf/e1F3eWyC4jP9zyO/3/wEwDn3MF8T8cBf7vSkCIixcHMaBlXhZZxVfjdnU2ZszGTqSt389myXXy4eAc1KoZzZ8ta3NWyNm3q+PfB1MIU+hKgkZklkFvkfYCH8q9gZrWcc3vynt4DrPdpShERHwgNDuLmZjHc3CyGU1nZzFq/ny9X7ebDxTv4x4LtxFYpx10ta3H3dbW5tnYlvyv3wp62eAfwBrmnLb7nnPuzmb0EpDrnppnZy+QWeTZwCBjsnNtwuffULhcRKS2OnTnHd2v38eWq3czbfIDsHEdCVPl/l3vjmIpeR/w3XVgkIlJIh09mMX3tXr5ctZuFaQfJcdAgujzdm9ek+7W1aB7r7Za7Cl1E5CrsP36G6Wv2Mn3NXhZvO8T5HEdslXLcem0M3a+tSWK9kj+gqkIXESmiQyezmLl+H9+u3cvczQfIys6hevkwbr02hluvrUlyg+qEhxT/1AMqdBERHzpxNpvZG/czfc1eftiwn5NZ56kYHsJNTWtw27U1uaFxNBXCi2d2chW6iEgxOXPuPClpB5i+Zi/frdvH4VPnCAsOon39atzcNIZuTWsQV9V30w+o0EVESkD2+RxS0w8za/0+Zq3fz9YDJwG4pmZFujWtQbemMbSKq0JQEfa7q9BFRDywNfMEs9bvZ+b6faSmH+Z8jiOqQhgv3NWMHq1ir+o9dQs6EREP1I+uQP3oCjx1Q32OnMpizqZMZq7fT81KxXMDbBW6iEgJqBIZRo9WsVe9ZV4Y/jndmIiI/IQKXUQkQKjQRUQChApdRCRAqNBFRAKECl1EJECo0EVEAoQKXUQkQHh26b+ZZQLpV/nHo4ADPozjDzTmskFjLhuKMua6zrnoiy3wrNCLwsxSLzWXQaDSmMsGjblsKK4xa5eLiEiAUKGLiAQIfy30MV4H8IDGXDZozGVDsYzZL/ehi4jIT/nrFrqIiFxAhS4iEiBKdaGbWXcz22hmW8zsNxdZHm5mn+QtX2xm9TyI6VOFGPMvzWydma0ys1lmVteLnL5U0JjzrXe/mTkz8/tT3AozZjN7MO97vdbMPirpjL5WiH/bdczsBzNbnvfv+w4vcvqKmb1nZvvNbM0llpuZDc/7+1hlZm2K/KHOuVL5BQQDaUB9IAxYCTS7YJ2ngVF5j/sAn3iduwTGfCMQmfd4cFkYc956FYG5wCIg0evcJfB9bgQsB6rmPa/hde4SGPMYYHDe42bAdq9zF3HMNwBtgDWXWH4H8A1gQAdgcVE/szRvoScBW5xzW51zWcBEoMcF6/QA/pn3eDLQzcyu/nba3itwzM65H5xzp/KeLgLiSjijrxXm+wzwR+CvwJmSDFdMCjPmp4B3nHOHAZxz+0s4o68VZswOqJT3uDKwuwTz+Zxzbi5w6DKr9AAmuFyLgCpmVqson1maCz0W2JnveUbeaxddxzmXDRwFqpdIuuJRmDHn9wS5/8P7swLHnPeraLxz7quSDFaMCvN9bgw0NrMFZrbIzLqXWLriUZgxvwj0M7MM4GtgWMlE88yV/rwXSDeJ9lNm1g9IBLp4naU4mVkQ8HfgMY+jlLQQcne7dCX3t7C5ZtbCOXfEy1DFrC8w3jn3mpl1BN43s+bOuRyvg/mL0ryFvguIz/c8Lu+1i65jZiHk/pp2sETSFY/CjBkzuxn4HXCPc+5sCWUrLgWNuSLQHJhtZtvJ3dc4zc8PjBbm+5wBTHPOnXPObQM2kVvw/qowY34CmATgnFsIRJA7iVWgKtTP+5UozYW+BGhkZglmFkbuQc9pF6wzDfhZ3uNewPcu72iDnypwzGbWGhhNbpn7+35VKGDMzrmjzrko51w951w9co8b3OOcS/Umrk8U5t/2F+RunWNmUeTugtlaghl9rTBj3gF0AzCzpuQWemaJpixZ04BH88526QAcdc7tKdI7en0kuICjxHeQu2WSBvwu77WXyP2Bhtxv+KfAFuBHoL7XmUtgzDOBfcCKvK9pXmcu7jFfsO5s/Pwsl0J+n43cXU3rgNVAH68zl8CYmwELyD0DZgVwq9eZizjej4E9wDlyf+N6AhgEDMr3PX4n7+9jtS/+XevSfxGRAFGad7mIiMgVUKGLiAQIFbqISIBQoYuIBAgVuohIgFChi4gECBW6iEiA+H/LBtDeW6hpTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_pred, y_pred, label ='NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e95e47",
   "metadata": {},
   "source": [
    "# Trial-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "\n",
    "# Define the number of outputs and the learning rate\n",
    "n_input_1 = 3\n",
    "n_nodes_hl1 = 30\n",
    "n_nodes_hl2 = 30\n",
    "n_nodes_hl3 = 30\n",
    "n_nodes_hl4 = 30\n",
    "n_nodes_hl5 = 30\n",
    "n_nodes_hl6 = 30\n",
    "n_nodes_hl7 = 30\n",
    "n_nodes_hl8 = 30\n",
    "n_output = 1\n",
    "learn_rate = 0.0002\n",
    "\n",
    "# Boundary Conditions\n",
    "left_temp = 1\n",
    "right_temp = 0\n",
    "x_0 = 0\n",
    "x_l = 0.2\n",
    "x_r = 1 \n",
    "C1 = 0.2\n",
    "C2 = 2.0\n",
    "T_ini = 0\n",
    "ini_temp = 0\n",
    "\n",
    "# training data\n",
    "t_pred = 0.4\n",
    "x_lim_loc = 0.9\n",
    "N = 3000\n",
    "N_bc = 400 # Number of datapoints to describe B.C's\n",
    "N_xlim = 80\n",
    "diff1 = (x_l-0)/N\n",
    "diff2 = (x_r - x_l)/N_xlim\n",
    "\n",
    "x = []\n",
    "t = []\n",
    "x_lim = []\n",
    "\n",
    "x1 = []\n",
    "t1 = []\n",
    "x_lim1 = []\n",
    "\n",
    "for i in range(N):\n",
    "    x1.append(x_l+i*diff1) \n",
    "    t1.append(t_pred)\n",
    "    x_lim1.append(x_lim_loc)\n",
    "    x.append(random.uniform(0, 1))\n",
    "    t_feed.append(random.uniform(0, 1))\n",
    "    if(i==N-1):\n",
    "        for j in range(N_bc):\n",
    "            x.append(0)\n",
    "            t_feed.append(random.uniform(0, 1))\n",
    "            x.append(random.uniform(0, 1))\n",
    "            t_feed.append(0)\n",
    "            t_feed.append(random.uniform(0, 1))\n",
    "            \n",
    "for i in range(N_bc):\n",
    "    x_lim.append(x_l+i*diff2) \n",
    "\n",
    "N1 = N\n",
    "\n",
    "x1 = np.array(x1)\n",
    "x1 = x1.reshape((N1,1))\n",
    "t1 = np.array(t1)\n",
    "t1 = t1.reshape((N1,1))\n",
    "x_lim1 = np.array(x_lim1)\n",
    "x_lim1 = x_lim1.reshape((N1,1))\n",
    "    \n",
    "N = len(x)\n",
    "x = np.array(x)\n",
    "x = x.reshape((N,1))\n",
    "\n",
    "N = len(t_feed)\n",
    "t_feed = np.array(t_feed)\n",
    "t_feed = t_feed.reshape((N,1))\n",
    "\n",
    "# Placeholders\n",
    "x_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "t_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "c_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 100\n",
    "\n",
    "# Define standard deviation for initialising weights and biases from normal distribution.\n",
    "hl_sigma = 0.15\n",
    "\n",
    "def NN1(x2, t2, xlim):\n",
    "    data = tf.concat([x2, t2, xlim], 1)\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    hidden_1_layer = {'weights': tf.Variable(tf.random.normal([n_input_1, n_nodes_hl1],stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl1], stddev=hl_sigma))}\n",
    "    hidden_2_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl2], stddev=hl_sigma))}\n",
    "    hidden_3_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl2, n_nodes_hl3], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl3], stddev=hl_sigma))}\n",
    "    hidden_4_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl3, n_nodes_hl4], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl4], stddev=hl_sigma))}\n",
    "    hidden_5_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl4, n_nodes_hl5], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl5], stddev=hl_sigma))}\n",
    "    hidden_6_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl5, n_nodes_hl6], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl6], stddev=hl_sigma))}\n",
    "    hidden_7_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl6, n_nodes_hl7], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl7], stddev=hl_sigma))}\n",
    "    hidden_8_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl7, n_nodes_hl8], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl8], stddev=hl_sigma))}\n",
    "    output_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl8, n_output], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_output], stddev=hl_sigma))}\n",
    "           \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.tanh(l1)   \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.tanh(l2)\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.tanh(l3)\n",
    "    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.tanh(l4)\n",
    "    l5 = tf.add(tf.matmul(l4, hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    l5 = tf.nn.tanh(l5)\n",
    "    l6 = tf.add(tf.matmul(l5, hidden_6_layer['weights']), hidden_6_layer['biases'])\n",
    "    l6 = tf.nn.tanh(l6)\n",
    "    l7 = tf.add(tf.matmul(l6, hidden_7_layer['weights']), hidden_7_layer['biases'])\n",
    "    l7 = tf.nn.tanh(l7)\n",
    "    l8 = tf.add(tf.matmul(l7, hidden_8_layer['weights']), hidden_8_layer['biases'])\n",
    "    l8 = tf.nn.tanh(l8)\n",
    "    output = tf.add(tf.matmul(l8, output_layer['weights']), output_layer['biases'], name='output')\n",
    "    return output\n",
    "\n",
    "def train_neural_network_batch():\n",
    "    u = NN1(x_ph,t_ph,x_lim_ph)  \n",
    "    dudx = tf.gradients(u, x_ph)\n",
    "    dudx2 = tf.gradients(tf.gradients(u, x_ph), x_ph)\n",
    "    dudt = tf.gradients(u, t_ph)\n",
    "        \n",
    "    cost = tf.reduce_mean( tf.square((dudt-tf.constant(C1)*dudx2)*tf.cast(tf.less_equal(x_ph,x_lim_ph), tf.float32)) \n",
    "                          + 10*tf.square(tf.cast(tf.equal(x_ph,0), tf.float32)*(u-left_temp)) \n",
    "                          + 10*tf.square(tf.cast(tf.equal(x_ph,x_lim_ph), tf.float32)*(u-right_temp)) \n",
    "                          + tf.square(tf.cast(tf.equal(t_ph,T_ini), tf.float32)*(u-ini_temp)) )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    " \n",
    "            for i in x_lim:\n",
    "                \n",
    "                x_temp = []\n",
    "                for j in range(N_bc):\n",
    "                    x_temp.append(i)\n",
    "                \n",
    "                x_temp = np.array(x_temp)\n",
    "                x_temp = x_temp.reshape((N_bc,1))\n",
    "                x_feed = np.concatenate((x, x_temp), axis=0)\n",
    "                \n",
    "                x_lim_feed = []\n",
    "                for j in range(N):\n",
    "                    x_lim_feed.append(i)\n",
    "                    \n",
    "                x_lim_feed = np.array(x_lim_feed)\n",
    "                x_lim_feed = x_lim_feed.reshape((N,1))\n",
    "                    \n",
    "                _, l = sess.run([optimizer,cost], feed_dict={x_ph:x_feed, t_ph:t_feed, x_lim_ph:x_lim_feed})\n",
    "            \n",
    "                print('loss:-',l,', epoch:-',epoch)\n",
    "                \n",
    "                if(l<=0.00005):\n",
    "                    break\n",
    "\n",
    "        # Validation\n",
    "        return sess.run(tf.squeeze(u),{x_ph:x1, t_ph:t1, x_lim_ph:x_lim1}), x1\n",
    "    \n",
    "# Run the code                              \n",
    "y_pred, x_pred = train_neural_network_batch()\n",
    "y_pred = y_pred.reshape(N1,1)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(x1)):\n",
    "    cnt = cnt+1\n",
    "    if x1[i]>x_lim_loc:\n",
    "        break\n",
    "        \n",
    "plt.plot(x1[0:cnt], y_pred[0:cnt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb756a",
   "metadata": {},
   "source": [
    "# Trial-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6739fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanjeet\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "loss:- 0.8022792 , epoch:- 0\n",
      "loss:- 0.11773837 , epoch:- 100\n",
      "loss:- 0.04468594 , epoch:- 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_864/3017783854.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;31m# Run the code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m \u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbia\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_neural_network_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_864/3017783854.py\u001b[0m in \u001b[0;36mtrain_neural_network_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx_ph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_ph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_ph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    969\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    970\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1192\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1372\u001b[0m                            run_metadata)\n\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1362\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1453\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1454\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import special\n",
    "\n",
    "# Define the number of outputs and the learning rate\n",
    "n_input_1 = 3\n",
    "n_nodes_hl1 = 30\n",
    "n_nodes_hl2 = 30\n",
    "n_nodes_hl3 = 30\n",
    "n_nodes_hl4 = 30\n",
    "n_nodes_hl5 = 30\n",
    "n_nodes_hl6 = 30\n",
    "n_nodes_hl7 = 30\n",
    "n_nodes_hl8 = 30\n",
    "n_output = 1\n",
    "learn_rate = 0.0002\n",
    "\n",
    "# Boundary Conditions\n",
    "left_temp = 1\n",
    "right_temp = 0\n",
    "x_l = 0\n",
    "x_r = 1 \n",
    "T_ini = 0\n",
    "ini_temp = 0\n",
    "\n",
    "# training data\n",
    "t_pred = 0.2\n",
    "c_pred = 0.8\n",
    "N1 = 6000\n",
    "N_bc = 400 # Number of datapoints to describe B.C's\n",
    "diff = (x_r-x_l)/N1\n",
    "\n",
    "x = []\n",
    "t = []\n",
    "c = []\n",
    "\n",
    "for i in range(N1):\n",
    "    x.append(random.uniform(0, 1))\n",
    "    c.append(random.uniform(0, 1))\n",
    "    t.append(random.uniform(0, 1))\n",
    "    if(i==N1-1):\n",
    "        for j in range(N_bc):\n",
    "            x.append(x_l)\n",
    "            t.append(random.uniform(0, 1))\n",
    "            c.append(random.uniform(0, 1))\n",
    "            x.append(x_r)\n",
    "            t.append(random.uniform(0, 1))\n",
    "            c.append(random.uniform(0, 1))\n",
    "            x.append(random.uniform(0, 1))\n",
    "            t.append(T_ini)\n",
    "            c.append(random.uniform(0, 1))\n",
    "    \n",
    "N = len(x)\n",
    "\n",
    "x = np.array(x)\n",
    "x = x.reshape((N,1))\n",
    "t = np.array(t)\n",
    "t = t.reshape((N,1))\n",
    "c = np.array(c)\n",
    "c = c.reshape((N,1))\n",
    "\n",
    "# Placeholders\n",
    "x_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "t_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "c_ph = tf.placeholder('float', [None, 1],name='input')\n",
    "\n",
    "# number of epochs\n",
    "n_epochs = 10000\n",
    "\n",
    "# Define standard deviation for initialising weights and biases from normal distribution.\n",
    "hl_sigma = 0.15\n",
    "\n",
    "def NN1(x2, t2, c2):\n",
    "    data = tf.concat([x2, t2, c2], 1)\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    hidden_1_layer = {'weights': tf.Variable(tf.random.normal([n_input_1, n_nodes_hl1],stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl1], stddev=hl_sigma))}\n",
    "    hidden_2_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl1, n_nodes_hl2], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl2], stddev=hl_sigma))}\n",
    "    hidden_3_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl2, n_nodes_hl3], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl3], stddev=hl_sigma))}\n",
    "    hidden_4_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl3, n_nodes_hl4], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl4], stddev=hl_sigma))}\n",
    "    hidden_5_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl4, n_nodes_hl5], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl5], stddev=hl_sigma))}\n",
    "    hidden_6_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl5, n_nodes_hl6], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl6], stddev=hl_sigma))}\n",
    "    hidden_7_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl6, n_nodes_hl7], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl7], stddev=hl_sigma))}\n",
    "    hidden_8_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl7, n_nodes_hl8], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_nodes_hl8], stddev=hl_sigma))}\n",
    "    output_layer = {'weights': tf.Variable(tf.random.normal([n_nodes_hl8, n_output], stddev=hl_sigma)),\n",
    "                      'biases': tf.Variable(tf.random.normal([n_output], stddev=hl_sigma))}\n",
    "           \n",
    "    l1 = tf.add(tf.matmul(data, hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.tanh(l1)   \n",
    "    l2 = tf.add(tf.matmul(l1, hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.tanh(l2)\n",
    "    l3 = tf.add(tf.matmul(l2, hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.tanh(l3)\n",
    "    l4 = tf.add(tf.matmul(l3, hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.tanh(l4)\n",
    "    l5 = tf.add(tf.matmul(l4, hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    l5 = tf.nn.tanh(l5)\n",
    "    l6 = tf.add(tf.matmul(l5, hidden_6_layer['weights']), hidden_6_layer['biases'])\n",
    "    l6 = tf.nn.tanh(l6)\n",
    "    l7 = tf.add(tf.matmul(l6, hidden_7_layer['weights']), hidden_7_layer['biases'])\n",
    "    l7 = tf.nn.tanh(l7)\n",
    "    l8 = tf.add(tf.matmul(l7, hidden_8_layer['weights']), hidden_8_layer['biases'])\n",
    "    l8 = tf.nn.tanh(l8)\n",
    "    output = tf.add(tf.matmul(l8, output_layer['weights']), output_layer['biases'], name='output')\n",
    "\n",
    "    wts = []\n",
    "    wts.append(hidden_1_layer['weights'])\n",
    "    wts.append(hidden_2_layer['weights'])\n",
    "    wts.append(hidden_3_layer['weights'])\n",
    "    wts.append(hidden_4_layer['weights'])\n",
    "    wts.append(hidden_5_layer['weights'])\n",
    "    wts.append(hidden_6_layer['weights'])\n",
    "    wts.append(hidden_7_layer['weights'])\n",
    "    wts.append(hidden_8_layer['weights'])\n",
    "    wts.append(output_layer['weights'])\n",
    "    \n",
    "    bia = []\n",
    "    bia.append(hidden_1_layer['biases'])\n",
    "    bia.append(hidden_2_layer['biases'])\n",
    "    bia.append(hidden_3_layer['biases'])\n",
    "    bia.append(hidden_4_layer['biases'])\n",
    "    bia.append(hidden_5_layer['biases'])\n",
    "    bia.append(hidden_6_layer['biases'])\n",
    "    bia.append(hidden_7_layer['biases'])\n",
    "    bia.append(hidden_8_layer['biases'])\n",
    "    bia.append(output_layer['biases'])\n",
    "    \n",
    "    return wts, bia, output\n",
    "\n",
    "def train_neural_network_batch():\n",
    "    wts,bia,u = NN1(x_ph,t_ph,c_ph)  \n",
    "    dudx = tf.gradients(u, x_ph)\n",
    "    dudx2 = tf.gradients(tf.gradients(u, x_ph), x_ph)\n",
    "    dudt = tf.gradients(u, t_ph)\n",
    "        \n",
    "    cost = tf.reduce_mean( tf.square(dudt-c_ph*dudx2) \n",
    "                          + 10*tf.square(tf.cast(tf.equal(x_ph,x_l), tf.float32)*(u-left_temp)) \n",
    "                          + 10*tf.square(tf.cast(tf.equal(x_ph,x_r), tf.float32)*(u-right_temp)) \n",
    "                          + tf.square(tf.cast(tf.equal(t_ph,T_ini), tf.float32)*(u-ini_temp)) )\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learn_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "                    \n",
    "                _, l = sess.run([optimizer,cost], feed_dict={x_ph:x, t_ph:t, c_ph:c})\n",
    "                \n",
    "                if(epoch % 100 == 0):\n",
    "                    print('loss:-',l,', epoch:-',epoch)\n",
    "                if(l<=0.00005):\n",
    "                    break\n",
    "\n",
    "        # Validation\n",
    "        return sess.run(wts,{x_ph:x, t_ph:t, c_ph:c}), sess.run(bia,{x_ph:x, t_ph:t, c_ph:c})\n",
    "    \n",
    "# Run the code                              \n",
    "wts, bia = train_neural_network_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0256f1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = []\n",
    "t1 = []\n",
    "c1 = []\n",
    "\n",
    "t_pred = 0.001\n",
    "c_pred = 1\n",
    "\n",
    "for i in range(N1):\n",
    "    x1.append(x_l+i*diff) \n",
    "    t1.append(t_pred)\n",
    "    c1.append(c_pred)\n",
    "    \n",
    "x1 = np.array(x1)\n",
    "x1 = x1.reshape((N1,1))\n",
    "t1 = np.array(t1)\n",
    "t1 = t1.reshape((N1,1))\n",
    "c1 = np.array(c1)\n",
    "c1 = c1.reshape((N1,1))\n",
    "\n",
    "# Neural Network Solution\n",
    "l = np.concatenate([x1, t1, c1], 1)\n",
    "for i in range(len(wts)):\n",
    "    l = np.matmul(l,wts[i]) + bia[i]\n",
    "    if(i<len(wts)-1):\n",
    "        l = np.tanh(l)\n",
    "    \n",
    "# Analytical Solution\n",
    "y1 = []\n",
    "i = 1\n",
    "y1 = -2*(-1)**(i+1)/(i*np.pi)*np.sin(i*np.pi*x1)*np.exp(-i**2*np.pi**2*c_pred*t_pred)\n",
    "for i in range(2, 49, 1):\n",
    "    y1 += -2*(-1)**(i+1)/(i*np.pi)*np.sin(i*np.pi*x1)*np.exp(-i**2*np.pi**2*c_pred*t_pred)   \n",
    "y1 += x1\n",
    "y1 = np.flip(y1)\n",
    "    \n",
    "plt.plot(x1, l, label ='NN')\n",
    "plt.plot(x1, y1, label ='analytical')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f211ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cylinder_wake.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cylinder_wake.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6688/2905274353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[0mN_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cylinder_wake.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[0mU_star\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'U_star'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# N x 2 x T\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \"\"\"\n\u001b[0;32m    223\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'variable_names'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[0mMR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanjeet\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\io\\matlab\\mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'.mat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             raise IOError(\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cylinder_wake.mat'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Computational Domain\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "nu = 0.01\n",
    "\n",
    "class NavierStokes():\n",
    "    def __init__(self, X, Y, T, u, v):\n",
    "\n",
    "        self.x = torch.tensor(X, dtype=torch.float32, requires_grad=True)\n",
    "        self.y = torch.tensor(Y, dtype=torch.float32, requires_grad=True)\n",
    "        self.t = torch.tensor(T, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        self.u = torch.tensor(u, dtype=torch.float32)\n",
    "        self.v = torch.tensor(v, dtype=torch.float32)\n",
    "\n",
    "        #null vector to test against f and g:\n",
    "        self.null = torch.zeros((self.x.shape[0], 1))\n",
    "\n",
    "        # initialize network:\n",
    "        self.network()\n",
    "\n",
    "        self.optimizer = torch.optim.LBFGS(self.net.parameters(), lr=1, max_iter=200000, max_eval=50000,\n",
    "                                           history_size=50, tolerance_grad=1e-05, tolerance_change=0.5 * np.finfo(float).eps,\n",
    "                                           line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        #loss\n",
    "        self.ls = 0\n",
    "\n",
    "        #iteration number\n",
    "        self.iter = 0\n",
    "\n",
    "    def network(self):\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 20), nn.Tanh(),\n",
    "            nn.Linear(20, 2))\n",
    "\n",
    "    def function(self, x, y, t):\n",
    "\n",
    "        res = self.net(torch.hstack((x, y, t)))\n",
    "        psi, p = res[:, 0:1], res[:, 1:2]\n",
    "\n",
    "        u = torch.autograd.grad(psi, y, grad_outputs=torch.ones_like(psi), create_graph=True)[0] #retain_graph=True,\n",
    "        v = -1.*torch.autograd.grad(psi, x, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
    "\n",
    "        u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "        u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "        u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
    "        u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "        v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "        v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "        v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "        v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "        p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
    "        p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
    "\n",
    "        f = u_t + u * u_x + v * u_y + p_x - nu * (u_xx + u_yy)\n",
    "        g = v_t + u * v_x + v * v_y + p_y - nu * (v_xx + v_yy)\n",
    "\n",
    "        return u, v, p, f, g\n",
    "\n",
    "    def closure(self):\n",
    "        # reset gradients to zero:\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # u, v, p, g and f predictions:\n",
    "        u_prediction, v_prediction, p_prediction, f_prediction, g_prediction = self.function(self.x, self.y, self.t)\n",
    "\n",
    "        # calculate losses\n",
    "        u_loss = self.mse(u_prediction, self.u)\n",
    "        v_loss = self.mse(v_prediction, self.v)\n",
    "        f_loss = self.mse(f_prediction, self.null)\n",
    "        g_loss = self.mse(g_prediction, self.null)\n",
    "        self.ls = u_loss + v_loss + f_loss +g_loss\n",
    "\n",
    "        # derivative with respect to net's weights:\n",
    "        self.ls.backward()\n",
    "\n",
    "        self.iter += 1\n",
    "        if not self.iter % 1:\n",
    "            print('Iteration: {:}, Loss: {:0.6f}'.format(self.iter, self.ls))\n",
    "\n",
    "        return self.ls\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # training loop\n",
    "        self.net.train()\n",
    "        self.optimizer.step(self.closure)\n",
    "\n",
    "N_train = 5000\n",
    "\n",
    "data = scipy.io.loadmat('cylinder_wake.mat')\n",
    "\n",
    "U_star = data['U_star']  # N x 2 x T\n",
    "P_star = data['p_star']  # N x T\n",
    "t_star = data['t']  # T x 1\n",
    "X_star = data['X_star']  # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "x_test = X_star[:, 0:1]\n",
    "y_test = X_star[:, 1:2]\n",
    "p_test = P_star[:, 0:1]\n",
    "u_test = U_star[:, 0:1, 0]\n",
    "t_test = np.ones((x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "# Rearrange Data\n",
    "XX = np.tile(X_star[:, 0:1], (1, T))  # N x T\n",
    "YY = np.tile(X_star[:, 1:2], (1, T))  # N x T\n",
    "TT = np.tile(t_star, (1, N)).T  # N x T\n",
    "\n",
    "UU = U_star[:, 0, :]  # N x T\n",
    "VV = U_star[:, 1, :]  # N x T\n",
    "PP = P_star  # N x T\n",
    "\n",
    "x = XX.flatten()[:, None]  # NT x 1\n",
    "y = YY.flatten()[:, None]  # NT x 1\n",
    "t = TT.flatten()[:, None]  # NT x 1\n",
    "\n",
    "u = UU.flatten()[:, None]  # NT x 1\n",
    "v = VV.flatten()[:, None]  # NT x 1\n",
    "p = PP.flatten()[:, None]  # NT x 1\n",
    "\n",
    "# Training Data\n",
    "idx = np.random.choice(N * T, N_train, replace=False)\n",
    "x_train = x[idx, :]\n",
    "y_train = y[idx, :]\n",
    "t_train = t[idx, :]\n",
    "u_train = u[idx, :]\n",
    "v_train = v[idx, :]\n",
    "\n",
    "'''\n",
    "pinn = NavierStokes(x_train, y_train, t_train, u_train, v_train)\n",
    "\n",
    "pinn.train()\n",
    "\n",
    "torch.save(pinn.net.state_dict(), 'model.pt')\n",
    "'''\n",
    "\n",
    "pinn = NavierStokes(x_train, y_train, t_train, u_train, v_train)\n",
    "pinn.net.load_state_dict(torch.load('model.pt'))\n",
    "pinn.net.eval()\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32, requires_grad=True)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, requires_grad=True)\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "u_out, v_out, p_out, f_out, g_out = pinn.function(x_test, y_test, t_test)\n",
    "\n",
    "u_plot = p_out.data.cpu().numpy()\n",
    "u_plot = np.reshape(u_plot, (50, 100))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.contourf(u_plot, levels=30, cmap='jet')\n",
    "plt.colorbar()\n",
    "#plt.show()\n",
    "\n",
    "def animate(i):\n",
    "    ax.clear()\n",
    "    u_out, v_out, p_out, f_out, g_out = pinn.function(x_test, y_test, i*t_test)\n",
    "    u_plot = p_out.data.cpu().numpy()\n",
    "    u_plot = np.reshape(u_plot, (50, 100))\n",
    "    cax = ax.contourf(u_plot, levels=20, cmap='jet')\n",
    "    plt.xlabel(r'$x$')\n",
    "    plt.xlabel(r'$y$')\n",
    "    plt.title(r'$p(x,\\; y, \\; t)$')\n",
    "\n",
    "# Call animate method\n",
    "ani = animation.FuncAnimation(fig, animate, 20, interval=1, blit=False)\n",
    "#ani.save('p_field_lbfgs.gif')\n",
    "#plt.close()\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c320b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
