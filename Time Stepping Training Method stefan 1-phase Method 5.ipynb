{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ac27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8819113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_torch(arr):\n",
    "    \n",
    "    arr = torch.FloatTensor(arr)\n",
    "    arr = arr.unsqueeze(-1)\n",
    "    arr = arr.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def x_train_data(N_x, x_l, x_r, N_bc, s, t_test, del_t):\n",
    "    \n",
    "    x_train = np.linspace(x_l,x_r,N_x)   \n",
    "\n",
    "    for i in range(N_x):\n",
    "        if x_train[i]>s:\n",
    "            break\n",
    "\n",
    "    x_train = np_to_torch(x_train)\n",
    "    N_xl = torch.sum( torch.where(x_train == x_l,1,0) ).detach().numpy().item()\n",
    "    \n",
    "    return x_train, N_xl, i\n",
    "\n",
    "def initial_temp(N_x, N_bc, T_l, T_r, N_x_test, N_s, N_s_test):\n",
    "    \n",
    "    T_prev_1 = np.concatenate((np.linspace(T_l,T_r,N_s), np.ones(N_x - N_s)*T_r),0)\n",
    "    T_prev = np_to_torch(T_prev_1)\n",
    "    T_test_prev = np.concatenate((np.linspace(T_l,T_r,N_s_test), np.ones(N_x_test - N_s)*T_r),0)\n",
    "    T_test_prev = np.reshape(T_test_prev,(N_x_test, 1))\n",
    "    \n",
    "    return T_prev, T_test_prev\n",
    "\n",
    "def initial_interface(N, s):\n",
    "\n",
    "    s_interface = torch.full((N, 1), s)\n",
    "    s_interface = s_interface.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    return s_interface, s_interface\n",
    "            \n",
    "def xavier_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "    \n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, layer_size):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        # Fully conected model\n",
    "        modules = []\n",
    "        for i in range(len(layer_size) - 2):\n",
    "            modules.append(nn.Linear(layer_size[i], layer_size[i+1]))  \n",
    "            modules.append(nn.Tanh())\n",
    "        modules.append(nn.Linear(layer_size[-2], layer_size[-1])) \n",
    "#         modules.append(nn.ReLU())\n",
    "\n",
    "        self.fc = nn.Sequential(*modules)\n",
    "        for layer in self.fc.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                 layer.weight.data.normal_(mean=0, std=0.2)\n",
    "#         self.fc.apply(xavier_init)\n",
    "        \n",
    "    def forward(self, x_train, k2, del_t, s_ini, t_test, dTsds_prev):\n",
    "        op = self.fc( x_train )\n",
    "        op_x = torch.autograd.grad(op, x_train, grad_outputs=torch.ones_like(op), create_graph=True)[0]\n",
    "        op_x2 = torch.autograd.grad(op_x, x_train, grad_outputs=torch.ones_like(op_x), create_graph=True)[0]\n",
    "        \n",
    "        op_s = self.fc( s_ini )\n",
    "        op_s_x = torch.autograd.grad(op_s, s_ini, grad_outputs=torch.ones_like(op_s), create_graph=True)[0]\n",
    "        \n",
    "        c_prev = 1\n",
    "        c_new = 1 - c_prev\n",
    "            \n",
    "        s_new = s_ini - del_t*k2*(c_new*op_s_x + c_prev*dTsds_prev)\n",
    "        op_s_new = self.fc( s_new )\n",
    "        op_s_new_x = torch.autograd.grad(op_s_new, s_new, grad_outputs=torch.ones_like(op_s_new), create_graph=True)[0]\n",
    "        op_s_new_x2 = torch.autograd.grad(op_s_new_x, s_new, grad_outputs=torch.ones_like(op_s_new), create_graph=True)[0]\n",
    "\n",
    "        return op, op_x2, op_s_new, s_new, op_s_x, op_s_new_x2\n",
    "    \n",
    "def get_loss(x_train, k1, k2, N_tot, T_l, T_r, N_xl, x_l, x_r, T_prev, del_t, t_test, s_ini, dTsds_prev):\n",
    "    \n",
    "    mse = nn.MSELoss(reduction='sum')\n",
    "    w1 = 1\n",
    "    w2 = 1\n",
    "    w3 = 1\n",
    "        \n",
    "    T, d2Tdx2, Ts, s_new, _, d2Tdx2_s_new  = model(x_train, k2, del_t, s_ini, t_test, dTsds_prev)\n",
    "    N1 = torch.sum(torch.where(x_train <= s_new,1,0)).detach().numpy().item()\n",
    "    eq1 = w1*( torch.sum( torch.square( torch.mul(torch.where(x_train <= s_new,1,0),T - T_prev - del_t*k1*d2Tdx2 ) ) ) )/(N1)\n",
    "    bc1 = w2*torch.sum( torch.square( torch.mul(torch.where(x_train == x_l,1,0),(T - T_l)) ) )/(N_xl)\n",
    "    bc2 = w3*torch.sum( torch.square( T_r - Ts ) )\n",
    "\n",
    "    loss = eq1 + bc1 + bc2   \n",
    "    \n",
    "    return loss, eq1, bc1, bc2\n",
    "\n",
    "def print_loss(epoch, loss, eq1, bc1, bc2):\n",
    "    print('epoch = ',epoch)\n",
    "    print('loss = ',loss.detach().numpy())\n",
    "    print('eq1_loss = ',eq1.detach().numpy())\n",
    "    print('bc1_loss = ',bc1.detach().numpy())\n",
    "    print('bc2_loss = ',bc2.detach().numpy())\n",
    "\n",
    "def interface_identifier(y_pred, T_r, N, x_test, s):\n",
    "    \n",
    "    for i in range(N):\n",
    "        if x_test[i]>s:\n",
    "            break\n",
    "            \n",
    "    for j in range(i,N):\n",
    "        y_pred[j] = T_r\n",
    "\n",
    "    return y_pred, s\n",
    "\n",
    "def lamb_analytical(k1, k2):\n",
    "    x = []\n",
    "    er = []\n",
    "    cnt = 0\n",
    "    for i in np.arange(0.1, 5, 0.001):\n",
    "        x.append(i)\n",
    "        er.append(math.erf(x[-1]))\n",
    "        cnt = cnt+1\n",
    "\n",
    "    x = np.array(x)\n",
    "    er = np.array(er)\n",
    "    y =[]\n",
    "    y = np.exp(-x*x)/(er*math.sqrt(math.pi))-x*k1/k2\n",
    "\n",
    "    for i in range(1,cnt):\n",
    "        if(y[i]*y[i-1]<0):\n",
    "            lam = x[i]\n",
    "            break\n",
    "    \n",
    "    return lam\n",
    "\n",
    "def analytical(N_x_test, x_test, t_test, T_r, k1, k2, T_l):\n",
    "\n",
    "    x_test = x_test.detach().numpy()\n",
    "    y_an = np.zeros((N_x_test, 1))\n",
    "    lam = lamb_analytical(k1, k2)\n",
    "    s = np.sqrt(k1*t_test)*2*lam\n",
    "    \n",
    "    for j in range(N_x_test):\n",
    "        if(x_test[j]<s):\n",
    "            y_an[j] = T_l - T_l*math.erf( x_test[j]/( 2*np.sqrt(k1*t_test) ) )/ math.erf(lam) \n",
    "        else:\n",
    "            y_an[j] = T_r\n",
    "            \n",
    "    y_an = np.reshape(y_an, (N_x_test, 1))\n",
    "    \n",
    "    return y_an, s\n",
    "    \n",
    "def train_model(model, optimiser1, epochs, T_r, T_l, k1, k2, N_x, x_l, x_r, N_t, N_bc, accuracy_cap, N_x_test, del_t, s_initial):\n",
    "    \n",
    "    loss_store = []\n",
    "    T_store_pred = []\n",
    "    s_store_pred = []\n",
    "    T_store_an = []\n",
    "    s_store_an = []\n",
    "    t_store = []\n",
    "    mse = nn.MSELoss(reduction='sum')\n",
    "    model.train()  \n",
    "    \n",
    "#     N_tot = N_x + N_bc\n",
    "    N_tot = N_x\n",
    "    print(\"N_tot = \", N_tot)\n",
    "    \n",
    "    t_test = 0\n",
    "    \n",
    "    t_store.append(0)\n",
    "    s_store_an.append(0)\n",
    "    for i in range(N_t):\n",
    "        \n",
    "        t_test = t_test + del_t\n",
    "        t_store.append(t_test)\n",
    "        print(\"t = \", t_test)\n",
    "        print(\" \")\n",
    "        \n",
    "        if(i==0):\n",
    "            x_train, N_xl, N_s = x_train_data(N_x, x_l, x_r, N_bc, s_initial, t_test, del_t)\n",
    "            print(\"Ns = \", N_s)\n",
    "            T_prev, _ = initial_temp(N_x, N_bc, T_l, T_r, N_x_test, N_s, N_s)\n",
    "            s_prev, _ = initial_interface(1, s_initial)\n",
    "            T_store_pred.append(T_prev.detach().numpy())\n",
    "            s_store_pred.append(s_prev.detach().numpy())\n",
    "            slope = (T_r - T_l)/s_initial\n",
    "            print(\"slope = \", slope)\n",
    "            dTsds_prev =torch.FloatTensor( np.ones((1, 1))*slope )\n",
    "        print(\"slope at interface = \", dTsds_prev)\n",
    "#         print(T_prev)\n",
    "    \n",
    "        if i>2:\n",
    "                epochs = 2001\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            #Backpropogation and optimisation\n",
    "            loss, eq1, bc1, bc2 = get_loss(x_train, k1, k2, N_tot, T_l, T_r, N_xl, x_l, x_r, T_prev, del_t, t_test, s_prev, dTsds_prev)\n",
    "            optimiser1.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser1.step()  \n",
    "            loss_store.append(loss.detach().numpy())\n",
    "            \n",
    "            if epoch%2000==0:\n",
    "                print_loss(epoch, loss, eq1, bc1, bc2)\n",
    "                print(\"\")\n",
    "\n",
    "#             if loss<0.0004 :\n",
    "#                 print(\"loss limit attained, epoch = \", epoch)\n",
    "#                 print_loss(epoch, loss, eq1, bc1, bc2)\n",
    "#                 print(\"\")\n",
    "#                 break\n",
    "                    \n",
    "        # Store the results after each time step\n",
    "        T_prev,_,_,s_prev,dTsds_prev,_ = model(x_train, k2, del_t, s_prev, t_test, dTsds_prev) \n",
    "        dTsds_prev = dTsds_prev.clone().detach().requires_grad_(False)\n",
    "        T_prev = T_prev.detach().numpy()\n",
    "        T_prev, _ = interface_identifier(T_prev, T_r, N_tot, x_train.detach().numpy(), s_prev[0][0].detach().numpy())\n",
    "        s_prev = s_prev.detach().numpy()\n",
    "        print(\"interface_PINN = \", s_prev[0][0])\n",
    "        T_an, s_an = analytical(N_x, x_train, t_test, T_r, k1, k2, T_l)\n",
    "        print(\"interface_Analytical = \", s_an)\n",
    "        \n",
    "        T_store_pred.append(T_prev)\n",
    "        \n",
    "        T_store_an.append(T_an)\n",
    "        s_store_pred.append(s_prev)\n",
    "        s_store_an.append(s_an)\n",
    "        \n",
    "        T_prev = torch.FloatTensor(T_store_pred[-1]).clone().detach().requires_grad_(False)\n",
    "        s_prev = torch.FloatTensor(s_store_pred[-1]).clone().detach().requires_grad_(True)\n",
    "        \n",
    "        print(\"broke inner loop\")\n",
    "        print(\"\")\n",
    "\n",
    "    return loss_store, T_store_pred, T_store_an, x_train, s_store_pred, s_store_an, t_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa5eeff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=3, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Total trainable parameters in the model: 34\n",
      "N_tot =  3001\n",
      "t =  0.001\n",
      " \n",
      "Ns =  17\n",
      "slope =  -333.3333333333333\n",
      "slope at interface =  tensor([[-333.3333]])\n",
      "epoch =  0\n",
      "loss =  0.3584315\n",
      "eq1_loss =  0.056948382\n",
      "bc1_loss =  0.2992662\n",
      "bc2_loss =  0.0022169133\n",
      "\n",
      "epoch =  2000\n",
      "loss =  0.16273375\n",
      "eq1_loss =  0.034219723\n",
      "bc1_loss =  0.08528278\n",
      "bc2_loss =  0.043231253\n",
      "\n",
      "epoch =  4000\n",
      "loss =  0.1627082\n",
      "eq1_loss =  0.03428219\n",
      "bc1_loss =  0.085038565\n",
      "bc2_loss =  0.043387443\n",
      "\n",
      "epoch =  6000\n",
      "loss =  0.16267836\n",
      "eq1_loss =  0.034278706\n",
      "bc1_loss =  0.08502117\n",
      "bc2_loss =  0.043378484\n",
      "\n",
      "epoch =  8000\n",
      "loss =  0.16261129\n",
      "eq1_loss =  0.034269255\n",
      "bc1_loss =  0.0849877\n",
      "bc2_loss =  0.04335433\n",
      "\n",
      "epoch =  10000\n",
      "loss =  0.16214205\n",
      "eq1_loss =  0.034199372\n",
      "bc1_loss =  0.08476591\n",
      "bc2_loss =  0.043176766\n",
      "\n",
      "epoch =  12000\n",
      "loss =  0.15231407\n",
      "eq1_loss =  0.03278261\n",
      "bc1_loss =  0.07994332\n",
      "bc2_loss =  0.039588142\n",
      "\n",
      "epoch =  14000\n",
      "loss =  0.11291733\n",
      "eq1_loss =  0.027135042\n",
      "bc1_loss =  0.06001338\n",
      "bc2_loss =  0.025768906\n",
      "\n",
      "epoch =  16000\n",
      "loss =  0.05948549\n",
      "eq1_loss =  0.019349197\n",
      "bc1_loss =  0.031465154\n",
      "bc2_loss =  0.008671139\n",
      "\n",
      "epoch =  18000\n",
      "loss =  0.021814896\n",
      "eq1_loss =  0.01326288\n",
      "bc1_loss =  0.008464868\n",
      "bc2_loss =  8.714689e-05\n",
      "\n",
      "epoch =  20000\n",
      "loss =  0.013916025\n",
      "eq1_loss =  0.011046581\n",
      "bc1_loss =  0.0016390372\n",
      "bc2_loss =  0.0012304068\n",
      "\n",
      "epoch =  22000\n",
      "loss =  0.011924636\n",
      "eq1_loss =  0.009724339\n",
      "bc1_loss =  0.0009644651\n",
      "bc2_loss =  0.001235832\n",
      "\n",
      "epoch =  24000\n",
      "loss =  0.008897452\n",
      "eq1_loss =  0.007692394\n",
      "bc1_loss =  0.0004493895\n",
      "bc2_loss =  0.00075566844\n",
      "\n",
      "epoch =  26000\n",
      "loss =  0.005561862\n",
      "eq1_loss =  0.0054261554\n",
      "bc1_loss =  2.9200592e-05\n",
      "bc2_loss =  0.00010650625\n",
      "\n",
      "epoch =  28000\n",
      "loss =  0.0050025643\n",
      "eq1_loss =  0.0049981778\n",
      "bc1_loss =  4.258577e-06\n",
      "bc2_loss =  1.2815362e-07\n",
      "\n",
      "epoch =  30000\n",
      "loss =  0.004982079\n",
      "eq1_loss =  0.0049753776\n",
      "bc1_loss =  4.9296123e-06\n",
      "bc2_loss =  1.771803e-06\n",
      "\n",
      "epoch =  32000\n",
      "loss =  0.0049620233\n",
      "eq1_loss =  0.0049549113\n",
      "bc1_loss =  3.8508715e-06\n",
      "bc2_loss =  3.2608498e-06\n",
      "\n",
      "epoch =  34000\n",
      "loss =  0.0049434276\n",
      "eq1_loss =  0.004936021\n",
      "bc1_loss =  2.5941506e-06\n",
      "bc2_loss =  4.812796e-06\n",
      "\n",
      "epoch =  36000\n",
      "loss =  0.004925895\n",
      "eq1_loss =  0.0049164286\n",
      "bc1_loss =  2.1012966e-06\n",
      "bc2_loss =  7.3653546e-06\n",
      "\n",
      "epoch =  38000\n",
      "loss =  0.0049088276\n",
      "eq1_loss =  0.00489745\n",
      "bc1_loss =  1.468657e-06\n",
      "bc2_loss =  9.9089e-06\n",
      "\n",
      "epoch =  40000\n",
      "loss =  0.0048914147\n",
      "eq1_loss =  0.0048778257\n",
      "bc1_loss =  9.759215e-07\n",
      "bc2_loss =  1.2613033e-05\n",
      "\n",
      "epoch =  42000\n",
      "loss =  0.0048742737\n",
      "eq1_loss =  0.004850873\n",
      "bc1_loss =  2.5891609e-06\n",
      "bc2_loss =  2.081203e-05\n",
      "\n",
      "epoch =  44000\n",
      "loss =  0.0048512467\n",
      "eq1_loss =  0.004832742\n",
      "bc1_loss =  4.2808256e-07\n",
      "bc2_loss =  1.8077111e-05\n",
      "\n",
      "epoch =  46000\n",
      "loss =  0.0048260344\n",
      "eq1_loss =  0.004805119\n",
      "bc1_loss =  3.0332217e-07\n",
      "bc2_loss =  2.0612379e-05\n",
      "\n",
      "epoch =  48000\n",
      "loss =  0.0047950423\n",
      "eq1_loss =  0.0047716475\n",
      "bc1_loss =  2.3830218e-07\n",
      "bc2_loss =  2.3156512e-05\n",
      "\n",
      "epoch =  50000\n",
      "loss =  0.004755291\n",
      "eq1_loss =  0.0047286637\n",
      "bc1_loss =  2.5379273e-07\n",
      "bc2_loss =  2.6373731e-05\n",
      "\n",
      "interface_PINN =  0.0031666667\n",
      "interface_Analytical =  0.002940918223956595\n",
      "broke inner loop\n",
      "\n",
      "t =  0.002\n",
      " \n",
      "slope at interface =  tensor([[-157.9756]])\n",
      "epoch =  0\n",
      "loss =  0.029765012\n",
      "eq1_loss =  0.020305729\n",
      "bc1_loss =  2.5109745e-07\n",
      "bc2_loss =  0.009459032\n",
      "\n",
      "epoch =  2000\n",
      "loss =  0.0012209543\n",
      "eq1_loss =  0.00090444426\n",
      "bc1_loss =  0.00016589204\n",
      "bc2_loss =  0.00015061809\n",
      "\n",
      "epoch =  4000\n",
      "loss =  0.00047757194\n",
      "eq1_loss =  0.0004515191\n",
      "bc1_loss =  1.6476584e-05\n",
      "bc2_loss =  9.576264e-06\n",
      "\n",
      "epoch =  6000\n",
      "loss =  0.0004292126\n",
      "eq1_loss =  0.00042789342\n",
      "bc1_loss =  1.087024e-06\n",
      "bc2_loss =  2.3217359e-07\n",
      "\n",
      "epoch =  8000\n",
      "loss =  0.0004246797\n",
      "eq1_loss =  0.0004234967\n",
      "bc1_loss =  5.805315e-07\n",
      "bc2_loss =  6.0244247e-07\n",
      "\n",
      "epoch =  10000\n",
      "loss =  0.000420882\n",
      "eq1_loss =  0.0004193043\n",
      "bc1_loss =  2.3783686e-07\n",
      "bc2_loss =  1.3398576e-06\n",
      "\n",
      "epoch =  12000\n",
      "loss =  0.0004182766\n",
      "eq1_loss =  0.00041627564\n",
      "bc1_loss =  8.3637644e-08\n",
      "bc2_loss =  1.9173262e-06\n",
      "\n",
      "epoch =  14000\n",
      "loss =  0.0004156264\n",
      "eq1_loss =  0.00041337224\n",
      "bc1_loss =  4.7903313e-08\n",
      "bc2_loss =  2.206258e-06\n",
      "\n",
      "epoch =  16000\n",
      "loss =  0.00041268033\n",
      "eq1_loss =  0.00041046125\n",
      "bc1_loss =  1.990475e-08\n",
      "bc2_loss =  2.199181e-06\n",
      "\n",
      "epoch =  18000\n",
      "loss =  0.00040956002\n",
      "eq1_loss =  0.0004071721\n",
      "bc1_loss =  2.3997874e-08\n",
      "bc2_loss =  2.3639118e-06\n",
      "\n",
      "epoch =  20000\n",
      "loss =  0.00040619203\n",
      "eq1_loss =  0.00040366157\n",
      "bc1_loss =  2.7102388e-08\n",
      "bc2_loss =  2.5033737e-06\n",
      "\n",
      "epoch =  22000\n",
      "loss =  0.00040235397\n",
      "eq1_loss =  0.00039975913\n",
      "bc1_loss =  2.2346796e-08\n",
      "bc2_loss =  2.5724996e-06\n",
      "\n",
      "epoch =  24000\n",
      "loss =  0.00039767748\n",
      "eq1_loss =  0.00039498412\n",
      "bc1_loss =  1.8500842e-08\n",
      "bc2_loss =  2.6748337e-06\n",
      "\n",
      "epoch =  26000\n",
      "loss =  0.0003917209\n",
      "eq1_loss =  0.00038883628\n",
      "bc1_loss =  1.6330887e-08\n",
      "bc2_loss =  2.8683025e-06\n",
      "\n",
      "epoch =  28000\n",
      "loss =  0.0003838094\n",
      "eq1_loss =  0.0003807936\n",
      "bc1_loss =  1.49886e-08\n",
      "bc2_loss =  3.000828e-06\n",
      "\n",
      "epoch =  30000\n",
      "loss =  0.00037270386\n",
      "eq1_loss =  0.00036962106\n",
      "bc1_loss =  1.5518609e-08\n",
      "bc2_loss =  3.0672734e-06\n",
      "\n",
      "epoch =  32000\n",
      "loss =  0.00035610172\n",
      "eq1_loss =  0.0003531212\n",
      "bc1_loss =  9.789858e-09\n",
      "bc2_loss =  2.970754e-06\n",
      "\n",
      "epoch =  34000\n",
      "loss =  0.000330867\n",
      "eq1_loss =  0.00032852442\n",
      "bc1_loss =  4.997233e-09\n",
      "bc2_loss =  2.3375926e-06\n",
      "\n",
      "epoch =  36000\n",
      "loss =  0.0002920006\n",
      "eq1_loss =  0.00028961047\n",
      "bc1_loss =  5.985626e-09\n",
      "bc2_loss =  2.3841162e-06\n",
      "\n",
      "epoch =  38000\n",
      "loss =  0.00024168911\n",
      "eq1_loss =  0.00023958317\n",
      "bc1_loss =  3.493915e-08\n",
      "bc2_loss =  2.070993e-06\n",
      "\n",
      "epoch =  40000\n",
      "loss =  0.00020578186\n",
      "eq1_loss =  0.0002050065\n",
      "bc1_loss =  3.775682e-08\n",
      "bc2_loss =  7.3761186e-07\n",
      "\n",
      "epoch =  42000\n",
      "loss =  0.00019521885\n",
      "eq1_loss =  0.00019474029\n",
      "bc1_loss =  1.0813497e-07\n",
      "bc2_loss =  3.70422e-07\n",
      "\n",
      "epoch =  44000\n",
      "loss =  0.00019083761\n",
      "eq1_loss =  0.00019041913\n",
      "bc1_loss =  9.55488e-08\n",
      "bc2_loss =  3.2293156e-07\n",
      "\n",
      "epoch =  46000\n",
      "loss =  0.00018728893\n",
      "eq1_loss =  0.00018692204\n",
      "bc1_loss =  1.080174e-07\n",
      "bc2_loss =  2.5886243e-07\n",
      "\n",
      "epoch =  48000\n",
      "loss =  0.00018413519\n",
      "eq1_loss =  0.00018379846\n",
      "bc1_loss =  9.1214105e-08\n",
      "bc2_loss =  2.4551372e-07\n",
      "\n",
      "epoch =  50000\n",
      "loss =  0.00018127481\n",
      "eq1_loss =  0.0001809745\n",
      "bc1_loss =  1.1889591e-07\n",
      "bc2_loss =  1.8142045e-07\n",
      "\n",
      "interface_PINN =  0.0039565447\n",
      "interface_Analytical =  0.004159086438149612\n",
      "broke inner loop\n",
      "\n",
      "t =  0.003\n",
      " \n",
      "slope at interface =  tensor([[-118.9166]])\n",
      "epoch =  0\n",
      "loss =  0.007636321\n",
      "eq1_loss =  0.003142803\n",
      "bc1_loss =  7.94509e-08\n",
      "bc2_loss =  0.004493438\n",
      "\n",
      "epoch =  2000\n",
      "loss =  0.00013285178\n",
      "eq1_loss =  0.00013189572\n",
      "bc1_loss =  7.1606655e-07\n",
      "bc2_loss =  2.3999277e-07\n",
      "\n",
      "epoch =  4000\n",
      "loss =  0.00011026065\n",
      "eq1_loss =  0.00010966721\n",
      "bc1_loss =  4.904131e-07\n",
      "bc2_loss =  1.0302239e-07\n",
      "\n",
      "epoch =  6000\n",
      "loss =  8.7437584e-05\n",
      "eq1_loss =  8.720131e-05\n",
      "bc1_loss =  2.1859256e-07\n",
      "bc2_loss =  1.7683139e-08\n",
      "\n",
      "epoch =  8000\n",
      "loss =  7.6027e-05\n",
      "eq1_loss =  7.5862066e-05\n",
      "bc1_loss =  1.6263881e-07\n",
      "bc2_loss =  2.2908218e-09\n",
      "\n",
      "epoch =  10000\n",
      "loss =  7.257052e-05\n",
      "eq1_loss =  7.250578e-05\n",
      "bc1_loss =  5.1220216e-08\n",
      "bc2_loss =  1.3509194e-08\n",
      "\n",
      "epoch =  12000\n",
      "loss =  7.149738e-05\n",
      "eq1_loss =  7.144049e-05\n",
      "bc1_loss =  3.4362202e-08\n",
      "bc2_loss =  2.2525356e-08\n",
      "\n",
      "epoch =  14000\n",
      "loss =  7.1088165e-05\n",
      "eq1_loss =  7.103013e-05\n",
      "bc1_loss =  1.2041145e-08\n",
      "bc2_loss =  4.5992024e-08\n",
      "\n",
      "epoch =  16000\n",
      "loss =  7.089267e-05\n",
      "eq1_loss =  7.0818955e-05\n",
      "bc1_loss =  2.2172486e-09\n",
      "bc2_loss =  7.1495506e-08\n",
      "\n",
      "epoch =  18000\n",
      "loss =  7.0712864e-05\n",
      "eq1_loss =  7.066004e-05\n",
      "bc1_loss =  1.968671e-08\n",
      "bc2_loss =  3.3135862e-08\n",
      "\n",
      "epoch =  20000\n",
      "loss =  7.058861e-05\n",
      "eq1_loss =  7.053658e-05\n",
      "bc1_loss =  1.9023346e-08\n",
      "bc2_loss =  3.300579e-08\n",
      "\n",
      "epoch =  22000\n",
      "loss =  7.047469e-05\n",
      "eq1_loss =  7.042278e-05\n",
      "bc1_loss =  1.652953e-08\n",
      "bc2_loss =  3.5386222e-08\n",
      "\n",
      "epoch =  24000\n",
      "loss =  7.036536e-05\n",
      "eq1_loss =  7.031445e-05\n",
      "bc1_loss =  1.7383229e-08\n",
      "bc2_loss =  3.3527613e-08\n",
      "\n",
      "epoch =  26000\n",
      "loss =  7.03689e-05\n",
      "eq1_loss =  7.023697e-05\n",
      "bc1_loss =  4.1208956e-09\n",
      "bc2_loss =  1.2781244e-07\n",
      "\n",
      "epoch =  28000\n",
      "loss =  7.015394e-05\n",
      "eq1_loss =  7.010427e-05\n",
      "bc1_loss =  1.691491e-08\n",
      "bc2_loss =  3.2746414e-08\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  30000\n",
      "loss =  7.005036e-05\n",
      "eq1_loss =  7.000122e-05\n",
      "bc1_loss =  1.6498891e-08\n",
      "bc2_loss =  3.2638642e-08\n",
      "\n",
      "epoch =  32000\n",
      "loss =  6.994762e-05\n",
      "eq1_loss =  6.989904e-05\n",
      "bc1_loss =  1.6346124e-08\n",
      "bc2_loss =  3.223073e-08\n",
      "\n",
      "epoch =  34000\n",
      "loss =  6.984613e-05\n",
      "eq1_loss =  6.97979e-05\n",
      "bc1_loss =  1.559295e-08\n",
      "bc2_loss =  3.2638642e-08\n",
      "\n",
      "epoch =  36000\n",
      "loss =  6.9745e-05\n",
      "eq1_loss =  6.9696944e-05\n",
      "bc1_loss =  1.4026714e-08\n",
      "bc2_loss =  3.4031533e-08\n",
      "\n",
      "epoch =  38000\n",
      "loss =  6.965448e-05\n",
      "eq1_loss =  6.959786e-05\n",
      "bc1_loss =  4.673982e-09\n",
      "bc2_loss =  5.1951247e-08\n",
      "\n",
      "epoch =  40000\n",
      "loss =  6.954474e-05\n",
      "eq1_loss =  6.94986e-05\n",
      "bc1_loss =  1.7320417e-08\n",
      "bc2_loss =  2.881643e-08\n",
      "\n",
      "epoch =  42000\n",
      "loss =  6.9445094e-05\n",
      "eq1_loss =  6.939901e-05\n",
      "bc1_loss =  1.5061662e-08\n",
      "bc2_loss =  3.1022385e-08\n",
      "\n",
      "epoch =  44000\n",
      "loss =  6.934596e-05\n",
      "eq1_loss =  6.930087e-05\n",
      "bc1_loss =  1.7273383e-08\n",
      "bc2_loss =  2.7813499e-08\n",
      "\n",
      "epoch =  46000\n",
      "loss =  6.924774e-05\n",
      "eq1_loss =  6.9203015e-05\n",
      "bc1_loss =  1.6452987e-08\n",
      "bc2_loss =  2.8272641e-08\n",
      "\n",
      "epoch =  48000\n",
      "loss =  6.914971e-05\n",
      "eq1_loss =  6.91054e-05\n",
      "bc1_loss =  1.64377e-08\n",
      "bc2_loss =  2.7873174e-08\n",
      "\n",
      "epoch =  50000\n",
      "loss =  6.905217e-05\n",
      "eq1_loss =  6.900829e-05\n",
      "bc1_loss =  1.590712e-08\n",
      "bc2_loss =  2.7972774e-08\n",
      "\n",
      "interface_PINN =  0.0045511276\n",
      "interface_Analytical =  0.005093819784798048\n",
      "broke inner loop\n",
      "\n",
      "t =  0.004\n",
      " \n",
      "slope at interface =  tensor([[-103.0547]])\n",
      "epoch =  0\n",
      "loss =  0.004219302\n",
      "eq1_loss =  0.0016013569\n",
      "bc1_loss =  1.6133445e-08\n",
      "bc2_loss =  0.002617929\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.2545372e-05\n",
      "eq1_loss =  5.2493542e-05\n",
      "bc1_loss =  3.987033e-08\n",
      "bc2_loss =  1.1962786e-08\n",
      "\n",
      "interface_PINN =  0.0050664013\n",
      "interface_Analytical =  0.00588183644791319\n",
      "broke inner loop\n",
      "\n",
      "t =  0.005\n",
      " \n",
      "slope at interface =  tensor([[-92.4344]])\n",
      "epoch =  0\n",
      "loss =  0.0026488604\n",
      "eq1_loss =  0.0008963078\n",
      "bc1_loss =  3.9894136e-08\n",
      "bc2_loss =  0.0017525128\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.3629796e-05\n",
      "eq1_loss =  4.3437223e-05\n",
      "bc1_loss =  1.1349181e-07\n",
      "bc2_loss =  7.9081715e-08\n",
      "\n",
      "interface_PINN =  0.0055285734\n",
      "interface_Analytical =  0.006576093065034897\n",
      "broke inner loop\n",
      "\n",
      "t =  0.006\n",
      " \n",
      "slope at interface =  tensor([[-84.5897]])\n",
      "epoch =  0\n",
      "loss =  0.0018253438\n",
      "eq1_loss =  0.00056764134\n",
      "bc1_loss =  1.13652504e-07\n",
      "bc2_loss =  0.0012575889\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.7625472e-05\n",
      "eq1_loss =  3.7238762e-05\n",
      "bc1_loss =  2.1859256e-07\n",
      "bc2_loss =  1.6811669e-07\n",
      "\n",
      "interface_PINN =  0.005951522\n",
      "interface_Analytical =  0.0072037490239458\n",
      "broke inner loop\n",
      "\n",
      "t =  0.007\n",
      " \n",
      "slope at interface =  tensor([[-78.4739]])\n",
      "epoch =  0\n",
      "loss =  0.0013560163\n",
      "eq1_loss =  0.00040717312\n",
      "bc1_loss =  2.187598e-07\n",
      "bc2_loss =  0.0009486244\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.5073634e-05\n",
      "eq1_loss =  3.4576642e-05\n",
      "bc1_loss =  2.892425e-07\n",
      "bc2_loss =  2.0775065e-07\n",
      "\n",
      "interface_PINN =  0.0063438914\n",
      "interface_Analytical =  0.007780938246766908\n",
      "broke inner loop\n",
      "\n",
      "t =  0.008\n",
      " \n",
      "slope at interface =  tensor([[-73.5614]])\n",
      "epoch =  0\n",
      "loss =  0.0010522772\n",
      "eq1_loss =  0.00031050708\n",
      "bc1_loss =  2.8930663e-07\n",
      "bc2_loss =  0.00074148073\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.287814e-05\n",
      "eq1_loss =  3.2331518e-05\n",
      "bc1_loss =  3.1867785e-07\n",
      "bc2_loss =  2.2794246e-07\n",
      "\n",
      "interface_PINN =  0.0067116986\n",
      "interface_Analytical =  0.008318172876299225\n",
      "broke inner loop\n",
      "\n",
      "t =  0.009000000000000001\n",
      " \n",
      "slope at interface =  tensor([[-69.5115]])\n",
      "epoch =  0\n",
      "loss =  0.0008438847\n",
      "eq1_loss =  0.00024668395\n",
      "bc1_loss =  3.1874515e-07\n",
      "bc2_loss =  0.000596882\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.0279321e-05\n",
      "eq1_loss =  2.9728246e-05\n",
      "bc1_loss =  3.205649e-07\n",
      "bc2_loss =  2.305108e-07\n",
      "\n",
      "interface_PINN =  0.007059256\n",
      "interface_Analytical =  0.008822754671869784\n",
      "broke inner loop\n",
      "\n",
      "t =  0.010000000000000002\n",
      " \n",
      "slope at interface =  tensor([[-66.0927]])\n",
      "epoch =  0\n",
      "loss =  0.00069405267\n",
      "eq1_loss =  0.00020237881\n",
      "bc1_loss =  3.205649e-07\n",
      "bc2_loss =  0.0004913533\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.7702272e-05\n",
      "eq1_loss =  2.7178956e-05\n",
      "bc1_loss =  3.055585e-07\n",
      "bc2_loss =  2.1775733e-07\n",
      "\n",
      "interface_PINN =  0.0073897196\n",
      "interface_Analytical =  0.009300000000000006\n",
      "broke inner loop\n",
      "\n",
      "t =  0.011000000000000003\n",
      " \n",
      "slope at interface =  tensor([[-63.1536]])\n",
      "epoch =  0\n",
      "loss =  0.00057514245\n",
      "eq1_loss =  0.00016319336\n",
      "bc1_loss =  3.0542674e-07\n",
      "bc2_loss =  0.00041164368\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.4852094e-05\n",
      "eq1_loss =  2.4312938e-05\n",
      "bc1_loss =  3.015521e-07\n",
      "bc2_loss =  2.3760437e-07\n",
      "\n",
      "interface_PINN =  0.007705488\n",
      "interface_Analytical =  0.009753922287982417\n",
      "broke inner loop\n",
      "\n",
      "t =  0.012000000000000004\n",
      " \n",
      "slope at interface =  tensor([[-60.5680]])\n",
      "epoch =  0\n",
      "loss =  0.00048752717\n",
      "eq1_loss =  0.00013630616\n",
      "bc1_loss =  3.0148664e-07\n",
      "bc2_loss =  0.00035091952\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.2133168e-05\n",
      "eq1_loss =  2.1607782e-05\n",
      "bc1_loss =  2.878977e-07\n",
      "bc2_loss =  2.3748817e-07\n",
      "\n",
      "interface_PINN =  0.008008327\n",
      "interface_Analytical =  0.010187639569596098\n",
      "broke inner loop\n",
      "\n",
      "t =  0.013000000000000005\n",
      " \n",
      "slope at interface =  tensor([[-58.2775]])\n",
      "epoch =  0\n",
      "loss =  0.0004185697\n",
      "eq1_loss =  0.00011593564\n",
      "bc1_loss =  2.8783376e-07\n",
      "bc2_loss =  0.00030234622\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.978615e-05\n",
      "eq1_loss =  1.9285158e-05\n",
      "bc1_loss =  2.700807e-07\n",
      "bc2_loss =  2.3091162e-07\n",
      "\n",
      "interface_PINN =  0.008299715\n",
      "interface_Analytical =  0.010603631453421993\n",
      "broke inner loop\n",
      "\n",
      "t =  0.014000000000000005\n",
      " \n",
      "slope at interface =  tensor([[-56.2331]])\n",
      "epoch =  0\n",
      "loss =  0.00036342154\n",
      "eq1_loss =  9.99691e-05\n",
      "bc1_loss =  2.7014266e-07\n",
      "bc2_loss =  0.0002631823\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.7691085e-05\n",
      "eq1_loss =  1.7220838e-05\n",
      "bc1_loss =  2.5020222e-07\n",
      "bc2_loss =  2.2004407e-07\n",
      "\n",
      "interface_PINN =  0.00858088\n",
      "interface_Analytical =  0.011003908396565296\n",
      "broke inner loop\n",
      "\n",
      "t =  0.015000000000000006\n",
      " \n",
      "slope at interface =  tensor([[-54.3935]])\n",
      "epoch =  0\n",
      "loss =  0.00031860475\n",
      "eq1_loss =  8.720699e-05\n",
      "bc1_loss =  2.5026185e-07\n",
      "bc2_loss =  0.0002311475\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.5805013e-05\n",
      "eq1_loss =  1.5368296e-05\n",
      "bc1_loss =  2.3005316e-07\n",
      "bc2_loss =  2.0666536e-07\n",
      "\n",
      "interface_PINN =  0.008852848\n",
      "interface_Analytical =  0.011390127303941788\n",
      "broke inner loop\n",
      "\n",
      "t =  0.016000000000000007\n",
      " \n",
      "slope at interface =  tensor([[-52.7270]])\n",
      "epoch =  0\n",
      "loss =  0.00028169065\n",
      "eq1_loss =  7.686191e-05\n",
      "bc1_loss =  2.2993882e-07\n",
      "bc2_loss =  0.0002045988\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.4132355e-05\n",
      "eq1_loss =  1.3730641e-05\n",
      "bc1_loss =  2.1025758e-07\n",
      "bc2_loss =  1.9145673e-07\n",
      "\n",
      "interface_PINN =  0.009116483\n",
      "interface_Analytical =  0.011763672895826381\n",
      "broke inner loop\n",
      "\n",
      "t =  0.017000000000000008\n",
      " \n",
      "slope at interface =  tensor([[-51.2082]])\n",
      "epoch =  0\n",
      "loss =  0.000250956\n",
      "eq1_loss =  6.840495e-05\n",
      "bc1_loss =  2.0998436e-07\n",
      "bc2_loss =  0.00018234107\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.2694061e-05\n",
      "eq1_loss =  1.2327881e-05\n",
      "bc1_loss =  1.9130029e-07\n",
      "bc2_loss =  1.7487969e-07\n",
      "\n",
      "interface_PINN =  0.009372524\n",
      "interface_Analytical =  0.012125716473676938\n",
      "broke inner loop\n",
      "\n",
      "t =  0.01800000000000001\n",
      " \n",
      "slope at interface =  tensor([[-49.8169]])\n",
      "epoch =  0\n",
      "loss =  0.0002251651\n",
      "eq1_loss =  6.1474246e-05\n",
      "bc1_loss =  1.915089e-07\n",
      "bc2_loss =  0.00016349935\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.1517144e-05\n",
      "eq1_loss =  1.11855425e-05\n",
      "bc1_loss =  1.7373497e-07\n",
      "bc2_loss =  1.5786681e-07\n",
      "\n",
      "interface_PINN =  0.009621608\n",
      "interface_Analytical =  0.012477259314448838\n",
      "broke inner loop\n",
      "\n",
      "t =  0.01900000000000001\n",
      " \n",
      "slope at interface =  tensor([[-48.5359]])\n",
      "epoch =  0\n",
      "loss =  0.00020126798\n",
      "eq1_loss =  5.3710788e-05\n",
      "bc1_loss =  1.7383437e-07\n",
      "bc2_loss =  0.00014738335\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.0394644e-05\n",
      "eq1_loss =  1.006835e-05\n",
      "bc1_loss =  1.6456751e-07\n",
      "bc2_loss =  1.6172666e-07\n",
      "\n",
      "interface_PINN =  0.009864287\n",
      "interface_Analytical =  0.012819165339443918\n",
      "broke inner loop\n",
      "\n",
      "t =  0.02000000000000001\n",
      " \n",
      "slope at interface =  tensor([[-47.3418]])\n",
      "epoch =  0\n",
      "loss =  0.00018337596\n",
      "eq1_loss =  4.9217193e-05\n",
      "bc1_loss =  1.6471262e-07\n",
      "bc2_loss =  0.00013399405\n",
      "\n",
      "epoch =  2000\n",
      "loss =  9.410085e-06\n",
      "eq1_loss =  9.117361e-06\n",
      "bc1_loss =  1.5005597e-07\n",
      "bc2_loss =  1.4266834e-07\n",
      "\n",
      "interface_PINN =  0.010100996\n",
      "interface_Analytical =  0.013152186130069797\n",
      "broke inner loop\n",
      "\n",
      "t =  0.02100000000000001\n",
      " \n",
      "slope at interface =  tensor([[-46.2353]])\n",
      "epoch =  0\n",
      "loss =  0.00016572507\n",
      "eq1_loss =  4.377838e-05\n",
      "bc1_loss =  1.4991747e-07\n",
      "bc2_loss =  0.00012179677\n",
      "\n",
      "epoch =  2000\n",
      "loss =  8.534276e-06\n",
      "eq1_loss =  8.250648e-06\n",
      "bc1_loss =  1.414552e-07\n",
      "bc2_loss =  1.4217348e-07\n",
      "\n",
      "interface_PINN =  0.010332173\n",
      "interface_Analytical =  0.01347698037395619\n",
      "broke inner loop\n",
      "\n",
      "t =  0.022000000000000013\n",
      " \n",
      "slope at interface =  tensor([[-45.2015]])\n",
      "epoch =  0\n",
      "loss =  0.00015236491\n",
      "eq1_loss =  4.060616e-05\n",
      "bc1_loss =  1.4114153e-07\n",
      "bc2_loss =  0.000111617606\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2000\n",
      "loss =  7.809044e-06\n",
      "eq1_loss =  7.5564176e-06\n",
      "bc1_loss =  1.2849524e-07\n",
      "bc2_loss =  1.2413153e-07\n",
      "\n",
      "interface_PINN =  0.0105581805\n",
      "interface_Analytical =  0.013794129185997947\n",
      "broke inner loop\n",
      "\n",
      "t =  0.023000000000000013\n",
      " \n",
      "slope at interface =  tensor([[-44.2374]])\n",
      "epoch =  0\n",
      "loss =  0.00013886212\n",
      "eq1_loss =  3.6478796e-05\n",
      "bc1_loss =  1.2862347e-07\n",
      "bc2_loss =  0.0001022547\n",
      "\n",
      "epoch =  2000\n",
      "loss =  7.1310587e-06\n",
      "eq1_loss =  6.8860536e-06\n",
      "bc1_loss =  1.2116743e-07\n",
      "bc2_loss =  1.2383771e-07\n",
      "\n",
      "interface_PINN =  0.010779368\n",
      "interface_Analytical =  0.014104148325935897\n",
      "broke inner loop\n",
      "\n",
      "t =  0.024000000000000014\n",
      " \n",
      "slope at interface =  tensor([[-43.3309]])\n",
      "epoch =  0\n",
      "loss =  0.00012768638\n",
      "eq1_loss =  3.3156903e-05\n",
      "bc1_loss =  1.2120893e-07\n",
      "bc2_loss =  9.4408264e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.4949268e-06\n",
      "eq1_loss =  6.262223e-06\n",
      "bc1_loss =  1.14095e-07\n",
      "bc2_loss =  1.18608355e-07\n",
      "\n",
      "interface_PINN =  0.010996022\n",
      "interface_Analytical =  0.014407498047891605\n",
      "broke inner loop\n",
      "\n",
      "t =  0.025000000000000015\n",
      " \n",
      "slope at interface =  tensor([[-42.4757]])\n",
      "epoch =  0\n",
      "loss =  0.00011864143\n",
      "eq1_loss =  3.12284e-05\n",
      "bc1_loss =  1.1417555e-07\n",
      "bc2_loss =  8.729885e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.0183684e-06\n",
      "eq1_loss =  5.811058e-06\n",
      "bc1_loss =  1.04135e-07\n",
      "bc2_loss =  1.03175495e-07\n",
      "\n",
      "interface_PINN =  0.0112084\n",
      "interface_Analytical =  0.014704591119782978\n",
      "broke inner loop\n",
      "\n",
      "t =  0.026000000000000016\n",
      " \n",
      "slope at interface =  tensor([[-41.6737]])\n",
      "epoch =  0\n",
      "loss =  0.00010930015\n",
      "eq1_loss =  2.8472448e-05\n",
      "bc1_loss =  1.0421195e-07\n",
      "bc2_loss =  8.072349e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.540668e-06\n",
      "eq1_loss =  5.341134e-06\n",
      "bc1_loss =  9.788437e-08\n",
      "bc2_loss =  1.0164953e-07\n",
      "\n",
      "interface_PINN =  0.011416769\n",
      "interface_Analytical =  0.014995799411835315\n",
      "broke inner loop\n",
      "\n",
      "t =  0.027000000000000017\n",
      " \n",
      "slope at interface =  tensor([[-40.9150]])\n",
      "epoch =  0\n",
      "loss =  0.00010144124\n",
      "eq1_loss =  2.617697e-05\n",
      "bc1_loss =  9.792167e-08\n",
      "bc2_loss =  7.5166354e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.0839953e-06\n",
      "eq1_loss =  4.8944466e-06\n",
      "bc1_loss =  9.22974e-08\n",
      "bc2_loss =  9.725136e-08\n",
      "\n",
      "interface_PINN =  0.011621344\n",
      "interface_Analytical =  0.015281459354394148\n",
      "broke inner loop\n",
      "\n",
      "t =  0.028000000000000018\n",
      " \n",
      "slope at interface =  tensor([[-40.1943]])\n",
      "epoch =  0\n",
      "loss =  9.4371295e-05\n",
      "eq1_loss =  2.419146e-05\n",
      "bc1_loss =  9.22974e-08\n",
      "bc2_loss =  7.008754e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.6886826e-06\n",
      "eq1_loss =  4.508935e-06\n",
      "bc1_loss =  8.7015195e-08\n",
      "bc2_loss =  9.2732506e-08\n",
      "\n",
      "interface_PINN =  0.011822316\n",
      "interface_Analytical =  0.01556187649353382\n",
      "broke inner loop\n",
      "\n",
      "t =  0.02900000000000002\n",
      " \n",
      "slope at interface =  tensor([[-39.5103]])\n",
      "epoch =  0\n",
      "loss =  8.8026216e-05\n",
      "eq1_loss =  2.2442593e-05\n",
      "bc1_loss =  8.698004e-08\n",
      "bc2_loss =  6.549664e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.3428136e-06\n",
      "eq1_loss =  4.1726403e-06\n",
      "bc1_loss =  8.192275e-08\n",
      "bc2_loss =  8.825032e-08\n",
      "\n",
      "interface_PINN =  0.012019867\n",
      "interface_Analytical =  0.01583732932031157\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03000000000000002\n",
      " \n",
      "slope at interface =  tensor([[-38.8600]])\n",
      "epoch =  0\n",
      "loss =  8.230368e-05\n",
      "eq1_loss =  2.0891055e-05\n",
      "bc1_loss =  8.188863e-08\n",
      "bc2_loss =  6.133074e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.03454e-06\n",
      "eq1_loss =  3.873209e-06\n",
      "bc1_loss =  7.7348105e-08\n",
      "bc2_loss =  8.3982755e-08\n",
      "\n",
      "interface_PINN =  0.012214167\n",
      "interface_Analytical =  0.016108072510390575\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03100000000000002\n",
      " \n",
      "slope at interface =  tensor([[-38.2411]])\n",
      "epoch =  0\n",
      "loss =  7.713833e-05\n",
      "eq1_loss =  1.9505409e-05\n",
      "bc1_loss =  7.7348105e-08\n",
      "bc2_loss =  5.755557e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.7570708e-06\n",
      "eq1_loss =  3.6041808e-06\n",
      "bc1_loss =  7.300147e-08\n",
      "bc2_loss =  7.988832e-08\n",
      "\n",
      "interface_PINN =  0.012405372\n",
      "interface_Analytical =  0.016374339681342897\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03200000000000002\n",
      " \n",
      "slope at interface =  tensor([[-37.6509]])\n",
      "epoch =  0\n",
      "loss =  7.2447496e-05\n",
      "eq1_loss =  1.8263188e-05\n",
      "bc1_loss =  7.2872695e-08\n",
      "bc2_loss =  5.4111435e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.5034304e-06\n",
      "eq1_loss =  3.3586643e-06\n",
      "bc1_loss =  6.896825e-08\n",
      "bc2_loss =  7.5797715e-08\n",
      "\n",
      "interface_PINN =  0.012593627\n",
      "interface_Analytical =  0.016636345752598453\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03300000000000002\n",
      " \n",
      "slope at interface =  tensor([[-37.0874]])\n",
      "epoch =  0\n",
      "loss =  6.817675e-05\n",
      "eq1_loss =  1.7143868e-05\n",
      "bc1_loss =  6.887436e-08\n",
      "bc2_loss =  5.0964005e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.2710516e-06\n",
      "eq1_loss =  3.1342543e-06\n",
      "bc1_loss =  6.511044e-08\n",
      "bc2_loss =  7.1686884e-08\n",
      "\n",
      "interface_PINN =  0.012779064\n",
      "interface_Analytical =  0.01689428897586402\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03400000000000002\n",
      " \n",
      "slope at interface =  tensor([[-36.5487]])\n",
      "epoch =  0\n",
      "loss =  6.427952e-05\n",
      "eq1_loss =  1.6132522e-05\n",
      "bc1_loss =  6.517129e-08\n",
      "bc2_loss =  4.808183e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.057017e-06\n",
      "eq1_loss =  2.9275682e-06\n",
      "bc1_loss =  6.154097e-08\n",
      "bc2_loss =  6.790793e-08\n",
      "\n",
      "interface_PINN =  0.012961808\n",
      "interface_Analytical =  0.017148352690564788\n",
      "broke inner loop\n",
      "\n",
      "t =  0.035000000000000024\n",
      " \n",
      "slope at interface =  tensor([[-36.0332]])\n",
      "epoch =  0\n",
      "loss =  6.0706116e-05\n",
      "eq1_loss =  1.5215808e-05\n",
      "bc1_loss =  6.145228e-08\n",
      "bc2_loss =  4.5428857e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.8601048e-06\n",
      "eq1_loss =  2.7382164e-06\n",
      "bc1_loss =  5.7928574e-08\n",
      "bc2_loss =  6.3959675e-08\n",
      "\n",
      "interface_PINN =  0.013141974\n",
      "interface_Analytical =  0.017398706848498847\n",
      "broke inner loop\n",
      "\n",
      "t =  0.036000000000000025\n",
      " \n",
      "slope at interface =  tensor([[-35.5393]])\n",
      "epoch =  0\n",
      "loss =  5.7434794e-05\n",
      "eq1_loss =  1.4384056e-05\n",
      "bc1_loss =  5.8215846e-08\n",
      "bc2_loss =  4.2992524e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.680609e-06\n",
      "eq1_loss =  2.5654576e-06\n",
      "bc1_loss =  5.4787566e-08\n",
      "bc2_loss =  6.0363746e-08\n",
      "\n",
      "interface_PINN =  0.01331967\n",
      "interface_Analytical =  0.017645509343739575\n",
      "broke inner loop\n",
      "\n",
      "t =  0.037000000000000026\n",
      " \n",
      "slope at interface =  tensor([[-35.0654]])\n",
      "epoch =  0\n",
      "loss =  5.4424254e-05\n",
      "eq1_loss =  1.3630391e-05\n",
      "bc1_loss =  5.4955112e-08\n",
      "bc2_loss =  4.073891e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.517806e-06\n",
      "eq1_loss =  2.4089532e-06\n",
      "bc1_loss =  5.192408e-08\n",
      "bc2_loss =  5.6928716e-08\n",
      "\n",
      "interface_PINN =  0.013494997\n",
      "interface_Analytical =  0.01788890717735437\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03800000000000003\n",
      " \n",
      "slope at interface =  tensor([[-34.6104]])\n",
      "epoch =  0\n",
      "loss =  5.165228e-05\n",
      "eq1_loss =  1.2947011e-05\n",
      "bc1_loss =  5.192408e-08\n",
      "bc2_loss =  3.8653347e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.3724162e-06\n",
      "eq1_loss =  2.2698223e-06\n",
      "bc1_loss =  4.9137444e-08\n",
      "bc2_loss =  5.3456407e-08\n",
      "\n",
      "interface_PINN =  0.013668049\n",
      "interface_Analytical =  0.01812903748134469\n",
      "broke inner loop\n",
      "\n",
      "t =  0.03900000000000003\n",
      " \n",
      "slope at interface =  tensor([[-34.1730]])\n",
      "epoch =  0\n",
      "loss =  4.910215e-05\n",
      "eq1_loss =  1.2328664e-05\n",
      "bc1_loss =  4.9111023e-08\n",
      "bc2_loss =  3.6724374e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.2453728e-06\n",
      "eq1_loss =  2.148824e-06\n",
      "bc1_loss =  4.640198e-08\n",
      "bc2_loss =  5.0146728e-08\n",
      "\n",
      "interface_PINN =  0.013838914\n",
      "interface_Analytical =  0.01836602842206231\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04000000000000003\n",
      " \n",
      "slope at interface =  tensor([[-33.7521]])\n",
      "epoch =  0\n",
      "loss =  4.6746125e-05\n",
      "eq1_loss =  1.1771188e-05\n",
      "bc1_loss =  4.6376304e-08\n",
      "bc2_loss =  3.4928562e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.1369679e-06\n",
      "eq1_loss =  2.0463851e-06\n",
      "bc1_loss =  4.379473e-08\n",
      "bc2_loss =  4.6787964e-08\n",
      "\n",
      "interface_PINN =  0.0140076745\n",
      "interface_Analytical =  0.01860000000000002\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04100000000000003\n",
      " \n",
      "slope at interface =  tensor([[-33.3468]])\n",
      "epoch =  0\n",
      "loss =  4.4201945e-05\n",
      "eq1_loss =  1.0897867e-05\n",
      "bc1_loss =  4.3869605e-08\n",
      "bc2_loss =  3.326021e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.0065677e-06\n",
      "eq1_loss =  1.9147453e-06\n",
      "bc1_loss =  4.2605453e-08\n",
      "bc2_loss =  4.921675e-08\n",
      "\n",
      "interface_PINN =  0.014174408\n",
      "interface_Analytical =  0.018831064760124448\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04200000000000003\n",
      " \n",
      "slope at interface =  tensor([[-32.9540]])\n",
      "epoch =  0\n",
      "loss =  4.2318617e-05\n",
      "eq1_loss =  1.0437254e-05\n",
      "bc1_loss =  4.2507086e-08\n",
      "bc2_loss =  3.1838856e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.8938847e-06\n",
      "eq1_loss =  1.8074808e-06\n",
      "bc1_loss =  4.0539604e-08\n",
      "bc2_loss =  4.5864287e-08\n",
      "\n",
      "interface_PINN =  0.014339178\n",
      "interface_Analytical =  0.019059328424684874\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04300000000000003\n",
      " \n",
      "slope at interface =  tensor([[-32.5734]])\n",
      "epoch =  0\n",
      "loss =  4.0439205e-05\n",
      "eq1_loss =  1.0030279e-05\n",
      "bc1_loss =  4.0587622e-08\n",
      "bc2_loss =  3.0368337e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.7934972e-06\n",
      "eq1_loss =  1.7122742e-06\n",
      "bc1_loss =  3.864217e-08\n",
      "bc2_loss =  4.258085e-08\n",
      "\n",
      "interface_PINN =  0.014502045\n",
      "interface_Analytical =  0.0192848904585948\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04400000000000003\n",
      " \n",
      "slope at interface =  tensor([[-32.2073]])\n",
      "epoch =  0\n",
      "loss =  3.8688384e-05\n",
      "eq1_loss =  9.658867e-06\n",
      "bc1_loss =  3.8548492e-08\n",
      "bc2_loss =  2.8990966e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2000\n",
      "loss =  1.7151904e-06\n",
      "eq1_loss =  1.6393045e-06\n",
      "bc1_loss =  3.6584712e-08\n",
      "bc2_loss =  3.93011e-08\n",
      "\n",
      "interface_PINN =  0.014663082\n",
      "interface_Analytical =  0.01950784457596484\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04500000000000003\n",
      " \n",
      "slope at interface =  tensor([[-31.8544]])\n",
      "epoch =  0\n",
      "loss =  3.674898e-05\n",
      "eq1_loss =  9.0053545e-06\n",
      "bc1_loss =  3.6607517e-08\n",
      "bc2_loss =  2.770702e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.6191634e-06\n",
      "eq1_loss =  1.5426128e-06\n",
      "bc1_loss =  3.540865e-08\n",
      "bc2_loss =  4.1141877e-08\n",
      "\n",
      "interface_PINN =  0.014822354\n",
      "interface_Analytical =  0.019728279195104698\n",
      "broke inner loop\n",
      "\n",
      "t =  0.046000000000000034\n",
      " \n",
      "slope at interface =  tensor([[-31.5120]])\n",
      "epoch =  0\n",
      "loss =  3.5344234e-05\n",
      "eq1_loss =  8.680986e-06\n",
      "bc1_loss =  3.5453528e-08\n",
      "bc2_loss =  2.6627793e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.5365166e-06\n",
      "eq1_loss =  1.4646625e-06\n",
      "bc1_loss =  3.3702463e-08\n",
      "bc2_loss =  3.815163e-08\n",
      "\n",
      "interface_PINN =  0.014979914\n",
      "interface_Analytical =  0.019946277848260332\n",
      "broke inner loop\n",
      "\n",
      "t =  0.047000000000000035\n",
      " \n",
      "slope at interface =  tensor([[-31.1793]])\n",
      "epoch =  0\n",
      "loss =  3.3929577e-05\n",
      "eq1_loss =  8.404687e-06\n",
      "bc1_loss =  3.379006e-08\n",
      "bc2_loss =  2.54911e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.4695671e-06\n",
      "eq1_loss =  1.4023062e-06\n",
      "bc1_loss =  3.218794e-08\n",
      "bc2_loss =  3.5072972e-08\n",
      "\n",
      "interface_PINN =  0.01513581\n",
      "interface_Analytical =  0.020161919551471303\n",
      "broke inner loop\n",
      "\n",
      "t =  0.048000000000000036\n",
      " \n",
      "slope at interface =  tensor([[-30.8582]])\n",
      "epoch =  0\n",
      "loss =  3.2329677e-05\n",
      "eq1_loss =  7.884184e-06\n",
      "bc1_loss =  3.214518e-08\n",
      "bc2_loss =  2.4413348e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.3927981e-06\n",
      "eq1_loss =  1.3252067e-06\n",
      "bc1_loss =  3.121164e-08\n",
      "bc2_loss =  3.6379788e-08\n",
      "\n",
      "interface_PINN =  0.015290101\n",
      "interface_Analytical =  0.0203752791391922\n",
      "broke inner loop\n",
      "\n",
      "t =  0.04900000000000004\n",
      " \n",
      "slope at interface =  tensor([[-30.5468]])\n",
      "epoch =  0\n",
      "loss =  3.117416e-05\n",
      "eq1_loss =  7.627735e-06\n",
      "bc1_loss =  3.1148492e-08\n",
      "bc2_loss =  2.3515275e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.3286682e-06\n",
      "eq1_loss =  1.2651903e-06\n",
      "bc1_loss =  2.9775382e-08\n",
      "bc2_loss =  3.3702463e-08\n",
      "\n",
      "interface_PINN =  0.015442835\n",
      "interface_Analytical =  0.020586427567696172\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05000000000000004\n",
      " \n",
      "slope at interface =  tensor([[-30.2437]])\n",
      "epoch =  0\n",
      "loss =  3.0017425e-05\n",
      "eq1_loss =  7.422212e-06\n",
      "bc1_loss =  2.9754816e-08\n",
      "bc2_loss =  2.2565458e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.2786265e-06\n",
      "eq1_loss =  1.2198117e-06\n",
      "bc1_loss =  2.82526e-08\n",
      "bc2_loss =  3.056218e-08\n",
      "\n",
      "interface_PINN =  0.015594053\n",
      "interface_Analytical =  0.020795432190748066\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05100000000000004\n",
      " \n",
      "slope at interface =  tensor([[-29.9506]])\n",
      "epoch =  0\n",
      "loss =  2.8664903e-05\n",
      "eq1_loss =  6.9740295e-06\n",
      "bc1_loss =  2.847344e-08\n",
      "bc2_loss =  2.16624e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.2136721e-06\n",
      "eq1_loss =  1.1540504e-06\n",
      "bc1_loss =  2.7476549e-08\n",
      "bc2_loss =  3.214518e-08\n",
      "\n",
      "interface_PINN =  0.015743807\n",
      "interface_Analytical =  0.02100235701058338\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05200000000000004\n",
      " \n",
      "slope at interface =  tensor([[-29.6659]])\n",
      "epoch =  0\n",
      "loss =  2.7736256e-05\n",
      "eq1_loss =  6.788228e-06\n",
      "bc1_loss =  2.7634858e-08\n",
      "bc2_loss =  2.0920394e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.1613804e-06\n",
      "eq1_loss =  1.1057714e-06\n",
      "bc1_loss =  2.6284397e-08\n",
      "bc2_loss =  2.9324557e-08\n",
      "\n",
      "interface_PINN =  0.015892137\n",
      "interface_Analytical =  0.021207262906843986\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05300000000000004\n",
      " \n",
      "slope at interface =  tensor([[-29.3882]])\n",
      "epoch =  0\n",
      "loss =  2.6557074e-05\n",
      "eq1_loss =  6.4261176e-06\n",
      "bc1_loss =  2.6323065e-08\n",
      "bc2_loss =  2.0104633e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.1059668e-06\n",
      "eq1_loss =  1.050508e-06\n",
      "bc1_loss =  2.5497972e-08\n",
      "bc2_loss =  2.9960802e-08\n",
      "\n",
      "interface_PINN =  0.016039077\n",
      "interface_Analytical =  0.02141020784579171\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05400000000000004\n",
      " \n",
      "slope at interface =  tensor([[-29.1187]])\n",
      "epoch =  0\n",
      "loss =  2.5697726e-05\n",
      "eq1_loss =  6.251673e-06\n",
      "bc1_loss =  2.555511e-08\n",
      "bc2_loss =  1.9420499e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.0629876e-06\n",
      "eq1_loss =  1.0105371e-06\n",
      "bc1_loss =  2.4517735e-08\n",
      "bc2_loss =  2.7932913e-08\n",
      "\n",
      "interface_PINN =  0.01618467\n",
      "interface_Analytical =  0.02161124707183741\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05500000000000004\n",
      " \n",
      "slope at interface =  tensor([[-28.8559]])\n",
      "epoch =  0\n",
      "loss =  2.4674424e-05\n",
      "eq1_loss =  5.947114e-06\n",
      "bc1_loss =  2.4499073e-08\n",
      "bc2_loss =  1.870281e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  1.0137069e-06\n",
      "eq1_loss =  9.621502e-07\n",
      "bc1_loss =  2.3703311e-08\n",
      "bc2_loss =  2.7853275e-08\n",
      "\n",
      "interface_PINN =  0.016328951\n",
      "interface_Analytical =  0.02181043328317897\n",
      "broke inner loop\n",
      "\n",
      "t =  0.05600000000000004\n",
      " \n",
      "slope at interface =  tensor([[-28.6006]])\n",
      "epoch =  0\n",
      "loss =  2.3889543e-05\n",
      "eq1_loss =  5.7875304e-06\n",
      "bc1_loss =  2.38872e-08\n",
      "bc2_loss =  1.8078124e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  9.784251e-07\n",
      "eq1_loss =  9.292934e-07\n",
      "bc1_loss =  2.2866576e-08\n",
      "bc2_loss =  2.6265074e-08\n",
      "\n",
      "interface_PINN =  0.016471954\n",
      "interface_Analytical =  0.022007816793130595\n",
      "broke inner loop\n",
      "\n",
      "t =  0.057000000000000044\n",
      " \n",
      "slope at interface =  tensor([[-28.3515]])\n",
      "epoch =  0\n",
      "loss =  2.3145454e-05\n",
      "eq1_loss =  5.6849517e-06\n",
      "bc1_loss =  2.2848553e-08\n",
      "bc2_loss =  1.7437655e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  9.486284e-07\n",
      "eq1_loss =  9.032739e-07\n",
      "bc1_loss =  2.1797778e-08\n",
      "bc2_loss =  2.3556712e-08\n",
      "\n",
      "interface_PINN =  0.016613713\n",
      "interface_Analytical =  0.0222034456785428\n",
      "broke inner loop\n",
      "\n",
      "t =  0.058000000000000045\n",
      " \n",
      "slope at interface =  tensor([[-28.1100]])\n",
      "epoch =  0\n",
      "loss =  2.2195438e-05\n",
      "eq1_loss =  5.3733347e-06\n",
      "bc1_loss =  2.167475e-08\n",
      "bc2_loss =  1.6800428e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  9.040244e-07\n",
      "eq1_loss =  8.579515e-07\n",
      "bc1_loss =  2.1255588e-08\n",
      "bc2_loss =  2.48173e-08\n",
      "\n",
      "interface_PINN =  0.016754262\n",
      "interface_Analytical =  0.022397365916553693\n",
      "broke inner loop\n",
      "\n",
      "t =  0.059000000000000045\n",
      " \n",
      "slope at interface =  tensor([[-27.8749]])\n",
      "epoch =  0\n",
      "loss =  2.1610023e-05\n",
      "eq1_loss =  5.2883993e-06\n",
      "bc1_loss =  2.1186125e-08\n",
      "bc2_loss =  1.6300439e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  8.7715466e-07\n",
      "eq1_loss =  8.350396e-07\n",
      "bc1_loss =  2.0140906e-08\n",
      "bc2_loss =  2.1974135e-08\n",
      "\n",
      "interface_PINN =  0.016893636\n",
      "interface_Analytical =  0.022589621510773508\n",
      "broke inner loop\n",
      "\n",
      "t =  0.060000000000000046\n",
      " \n",
      "slope at interface =  tensor([[-27.6447]])\n",
      "epoch =  0\n",
      "loss =  2.0751922e-05\n",
      "eq1_loss =  5.010767e-06\n",
      "bc1_loss =  2.0242542e-08\n",
      "bc2_loss =  1.5720912e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  8.3719436e-07\n",
      "eq1_loss =  7.942136e-07\n",
      "bc1_loss =  1.9770429e-08\n",
      "bc2_loss =  2.3210362e-08\n",
      "\n",
      "interface_PINN =  0.01703186\n",
      "interface_Analytical =  0.02278025460788358\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06100000000000005\n",
      " \n",
      "slope at interface =  tensor([[-27.4207]])\n",
      "epoch =  0\n",
      "loss =  2.0086416e-05\n",
      "eq1_loss =  4.800872e-06\n",
      "bc1_loss =  1.9770429e-08\n",
      "bc2_loss =  1.5265774e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  7.9927236e-07\n",
      "eq1_loss =  7.5695743e-07\n",
      "bc1_loss =  1.9303886e-08\n",
      "bc2_loss =  2.3011015e-08\n",
      "\n",
      "interface_PINN =  0.017168963\n",
      "interface_Analytical =  0.022969305605524976\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06200000000000005\n",
      " \n",
      "slope at interface =  tensor([[-27.2008]])\n",
      "epoch =  0\n",
      "loss =  1.9514577e-05\n",
      "eq1_loss =  4.699968e-06\n",
      "bc1_loss =  1.9303886e-08\n",
      "bc2_loss =  1.4795305e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  7.7594194e-07\n",
      "eq1_loss =  7.358091e-07\n",
      "bc1_loss =  1.8598257e-08\n",
      "bc2_loss =  2.1534575e-08\n",
      "\n",
      "interface_PINN =  0.017304968\n",
      "interface_Analytical =  0.023156813252259066\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06300000000000004\n",
      " \n",
      "slope at interface =  tensor([[-26.9861]])\n",
      "epoch =  0\n",
      "loss =  1.8837793e-05\n",
      "eq1_loss =  4.5055413e-06\n",
      "bc1_loss =  1.8549517e-08\n",
      "bc2_loss =  1.4313701e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  7.41705e-07\n",
      "eq1_loss =  7.020624e-07\n",
      "bc1_loss =  1.8177971e-08\n",
      "bc2_loss =  2.1464658e-08\n",
      "\n",
      "interface_PINN =  0.017439898\n",
      "interface_Analytical =  0.02334281474030073\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06400000000000004\n",
      " \n",
      "slope at interface =  tensor([[-26.7770]])\n",
      "epoch =  0\n",
      "loss =  1.8330362e-05\n",
      "eq1_loss =  4.4243247e-06\n",
      "bc1_loss =  1.8033607e-08\n",
      "bc2_loss =  1.3888004e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  7.2110606e-07\n",
      "eq1_loss =  6.839692e-07\n",
      "bc1_loss =  1.7383229e-08\n",
      "bc2_loss =  1.975367e-08\n",
      "\n",
      "interface_PINN =  0.017573783\n",
      "interface_Analytical =  0.02352734579165277\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06500000000000004\n",
      " \n",
      "slope at interface =  tensor([[-26.5726]])\n",
      "epoch =  0\n",
      "loss =  1.7702274e-05\n",
      "eq1_loss =  4.237039e-06\n",
      "bc1_loss =  1.7493424e-08\n",
      "bc2_loss =  1.3447741e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.9141333e-07\n",
      "eq1_loss =  6.5446295e-07\n",
      "bc1_loss =  1.6961454e-08\n",
      "bc2_loss =  1.9988931e-08\n",
      "\n",
      "interface_PINN =  0.017706646\n",
      "interface_Analytical =  0.02371044073820647\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06600000000000004\n",
      " \n",
      "slope at interface =  tensor([[-26.3732]])\n",
      "epoch =  0\n",
      "loss =  1.726203e-05\n",
      "eq1_loss =  4.1793332e-06\n",
      "bc1_loss =  1.689941e-08\n",
      "bc2_loss =  1.3065796e-05\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2000\n",
      "loss =  6.7446433e-07\n",
      "eq1_loss =  6.4035953e-07\n",
      "bc1_loss =  1.6103176e-08\n",
      "bc2_loss =  1.8001604e-08\n",
      "\n",
      "interface_PINN =  0.017838512\n",
      "interface_Analytical =  0.023892132596317162\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06700000000000005\n",
      " \n",
      "slope at interface =  tensor([[-26.1782]])\n",
      "epoch =  0\n",
      "loss =  1.6665224e-05\n",
      "eq1_loss =  3.9952147e-06\n",
      "bc1_loss =  1.6300433e-08\n",
      "bc2_loss =  1.2653709e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.4775026e-07\n",
      "eq1_loss =  6.1306946e-07\n",
      "bc1_loss =  1.5952256e-08\n",
      "bc2_loss =  1.8728542e-08\n",
      "\n",
      "interface_PINN =  0.017969402\n",
      "interface_Analytical =  0.024072453136313326\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06800000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.9878]])\n",
      "epoch =  0\n",
      "loss =  1.617826e-05\n",
      "eq1_loss =  3.846508e-06\n",
      "bc1_loss =  1.5847036e-08\n",
      "bc2_loss =  1.2315904e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.2250797e-07\n",
      "eq1_loss =  5.884871e-07\n",
      "bc1_loss =  1.5503762e-08\n",
      "bc2_loss =  1.851706e-08\n",
      "\n",
      "interface_PINN =  0.01809934\n",
      "interface_Analytical =  0.024251432947353876\n",
      "broke inner loop\n",
      "\n",
      "t =  0.06900000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.8008]])\n",
      "epoch =  0\n",
      "loss =  1.5778583e-05\n",
      "eq1_loss =  3.7870252e-06\n",
      "bc1_loss =  1.5488922e-08\n",
      "bc2_loss =  1.1976069e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  6.082556e-07\n",
      "eq1_loss =  5.761593e-07\n",
      "bc1_loss =  1.4901161e-08\n",
      "bc2_loss =  1.7195134e-08\n",
      "\n",
      "interface_PINN =  0.018228343\n",
      "interface_Analytical =  0.024429101498008504\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07000000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.6177]])\n",
      "epoch =  0\n",
      "loss =  1.5278516e-05\n",
      "eq1_loss =  3.6420693e-06\n",
      "bc1_loss =  1.497401e-08\n",
      "bc2_loss =  1.1621472e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.837378e-07\n",
      "eq1_loss =  5.517312e-07\n",
      "bc1_loss =  1.4654805e-08\n",
      "bc2_loss =  1.7351809e-08\n",
      "\n",
      "interface_PINN =  0.018356431\n",
      "interface_Analytical =  0.024605487192900715\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07100000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.4389]])\n",
      "epoch =  0\n",
      "loss =  1.4934098e-05\n",
      "eq1_loss =  3.6098004e-06\n",
      "bc1_loss =  1.4439138e-08\n",
      "bc2_loss =  1.1309859e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.732172e-07\n",
      "eq1_loss =  5.438299e-07\n",
      "bc1_loss =  1.3928059e-08\n",
      "bc2_loss =  1.5459264e-08\n",
      "\n",
      "interface_PINN =  0.018483626\n",
      "interface_Analytical =  0.024780617425722087\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07200000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.2638]])\n",
      "epoch =  0\n",
      "loss =  1.4444631e-05\n",
      "eq1_loss =  3.4577483e-06\n",
      "bc1_loss =  1.4040836e-08\n",
      "bc2_loss =  1.0972843e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.520935e-07\n",
      "eq1_loss =  5.2211175e-07\n",
      "bc1_loss =  1.37877265e-08\n",
      "bc2_loss =  1.6194068e-08\n",
      "\n",
      "interface_PINN =  0.018609945\n",
      "interface_Analytical =  0.02495451862889768\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07300000000000005\n",
      " \n",
      "slope at interface =  tensor([[-25.0927]])\n",
      "epoch =  0\n",
      "loss =  1.4051546e-05\n",
      "eq1_loss =  3.3358897e-06\n",
      "bc1_loss =  1.3592455e-08\n",
      "bc2_loss =  1.0702064e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.2985007e-07\n",
      "eq1_loss =  5.0052296e-07\n",
      "bc1_loss =  1.3329672e-08\n",
      "bc2_loss =  1.5997458e-08\n",
      "\n",
      "interface_PINN =  0.018735409\n",
      "interface_Analytical =  0.025127216320157734\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07400000000000005\n",
      " \n",
      "slope at interface =  tensor([[-24.9244]])\n",
      "epoch =  0\n",
      "loss =  1.3748679e-05\n",
      "eq1_loss =  3.3091778e-06\n",
      "bc1_loss =  1.3302159e-08\n",
      "bc2_loss =  1.0426198e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.214376e-07\n",
      "eq1_loss =  4.9422954e-07\n",
      "bc1_loss =  1.28118e-08\n",
      "bc2_loss =  1.4396196e-08\n",
      "\n",
      "interface_PINN =  0.01886003\n",
      "interface_Analytical =  0.02529873514624795\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07500000000000005\n",
      " \n",
      "slope at interface =  tensor([[-24.7594]])\n",
      "epoch =  0\n",
      "loss =  1.3319652e-05\n",
      "eq1_loss =  3.179384e-06\n",
      "bc1_loss =  1.2906426e-08\n",
      "bc2_loss =  1.0127362e-05\n",
      "\n",
      "epoch =  2000\n",
      "loss =  5.0276816e-07\n",
      "eq1_loss =  4.7532603e-07\n",
      "bc1_loss =  1.2570073e-08\n",
      "bc2_loss =  1.4872072e-08\n",
      "\n",
      "interface_PINN =  0.018983828\n",
      "interface_Analytical =  0.02546909892399025\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07600000000000005\n",
      " \n",
      "slope at interface =  tensor([[-24.5982]])\n",
      "epoch =  0\n",
      "loss =  1.2970547e-05\n",
      "eq1_loss =  3.0726897e-06\n",
      "bc1_loss =  1.2583442e-08\n",
      "bc2_loss =  9.885273e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.8352257e-07\n",
      "eq1_loss =  4.566428e-07\n",
      "bc1_loss =  1.2224977e-08\n",
      "bc2_loss =  1.4654805e-08\n",
      "\n",
      "interface_PINN =  0.019106818\n",
      "interface_Analytical =  0.02563833067888784\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07700000000000005\n",
      " \n",
      "slope at interface =  tensor([[-24.4396]])\n",
      "epoch =  0\n",
      "loss =  1.2709107e-05\n",
      "eq1_loss =  3.055833e-06\n",
      "bc1_loss =  1.23438895e-08\n",
      "bc2_loss =  9.64093e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.776694e-07\n",
      "eq1_loss =  4.524688e-07\n",
      "bc1_loss =  1.18846835e-08\n",
      "bc2_loss =  1.3315912e-08\n",
      "\n",
      "interface_PINN =  0.019229015\n",
      "interface_Analytical =  0.025806452681451618\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07800000000000006\n",
      " \n",
      "slope at interface =  tensor([[-24.2838]])\n",
      "epoch =  0\n",
      "loss =  1.2318704e-05\n",
      "eq1_loss =  2.9393473e-06\n",
      "bc1_loss =  1.1845728e-08\n",
      "bc2_loss =  9.367511e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.6098958e-07\n",
      "eq1_loss =  4.354564e-07\n",
      "bc1_loss =  1.1703438e-08\n",
      "bc2_loss =  1.3829752e-08\n",
      "\n",
      "interface_PINN =  0.019350434\n",
      "interface_Analytical =  0.025973486481410256\n",
      "broke inner loop\n",
      "\n",
      "t =  0.07900000000000006\n",
      " \n",
      "slope at interface =  tensor([[-24.1319]])\n",
      "epoch =  0\n",
      "loss =  1.2007671e-05\n",
      "eq1_loss =  2.843786e-06\n",
      "bc1_loss =  1.1485227e-08\n",
      "bc2_loss =  9.1524e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.4317807e-07\n",
      "eq1_loss =  4.1818484e-07\n",
      "bc1_loss =  1.1345126e-08\n",
      "bc2_loss =  1.3648105e-08\n",
      "\n",
      "interface_PINN =  0.019471092\n",
      "interface_Analytical =  0.02613945293995269\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08000000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.9822]])\n",
      "epoch =  0\n",
      "loss =  1.1706488e-05\n",
      "eq1_loss =  2.7575452e-06\n",
      "bc1_loss =  1.1294393e-08\n",
      "bc2_loss =  8.937649e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.2996987e-07\n",
      "eq1_loss =  4.0569648e-07\n",
      "bc1_loss =  1.09299805e-08\n",
      "bc2_loss =  1.3343438e-08\n",
      "\n",
      "interface_PINN =  0.019591004\n",
      "interface_Analytical =  0.026304372260139593\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08100000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.8349]])\n",
      "epoch =  0\n",
      "loss =  1.147378e-05\n",
      "eq1_loss =  2.736498e-06\n",
      "bc1_loss =  1.1130297e-08\n",
      "bc2_loss =  8.726152e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.240757e-07\n",
      "eq1_loss =  4.010241e-07\n",
      "bc1_loss =  1.06944675e-08\n",
      "bc2_loss =  1.23571375e-08\n",
      "\n",
      "interface_PINN =  0.019710178\n",
      "interface_Analytical =  0.026468264015609363\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08200000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.6902]])\n",
      "epoch =  0\n",
      "loss =  1.1152787e-05\n",
      "eq1_loss =  2.6467837e-06\n",
      "bc1_loss =  1.0719138e-08\n",
      "bc2_loss =  8.495284e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  4.089279e-07\n",
      "eq1_loss =  3.8588865e-07\n",
      "bc1_loss =  1.0522573e-08\n",
      "bc2_loss =  1.2516669e-08\n",
      "\n",
      "interface_PINN =  0.019828629\n",
      "interface_Analytical =  0.026631147177694044\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08300000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.5488]])\n",
      "epoch =  0\n",
      "loss =  1.08832255e-05\n",
      "eq1_loss =  2.5674558e-06\n",
      "bc1_loss =  1.0510348e-08\n",
      "bc2_loss =  8.305259e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.953681e-07\n",
      "eq1_loss =  3.7272918e-07\n",
      "bc1_loss =  1.0255267e-08\n",
      "bc2_loss =  1.2383655e-08\n",
      "\n",
      "interface_PINN =  0.019946372\n",
      "interface_Analytical =  0.026793040141051584\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08400000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.4096]])\n",
      "epoch =  0\n",
      "loss =  1.0619591e-05\n",
      "eq1_loss =  2.4950577e-06\n",
      "bc1_loss =  1.0207035e-08\n",
      "bc2_loss =  8.114326e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.8484396e-07\n",
      "eq1_loss =  3.626909e-07\n",
      "bc1_loss =  9.967582e-09\n",
      "bc2_loss =  1.2185467e-08\n",
      "\n",
      "interface_PINN =  0.02006342\n",
      "interface_Analytical =  0.026953960747912384\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08500000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.2727]])\n",
      "epoch =  0\n",
      "loss =  1.0420168e-05\n",
      "eq1_loss =  2.4770832e-06\n",
      "bc1_loss =  1.00869535e-08\n",
      "bc2_loss =  7.932998e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.801417e-07\n",
      "eq1_loss =  3.5894314e-07\n",
      "bc1_loss =  9.789858e-09\n",
      "bc2_loss =  1.14087015e-08\n",
      "\n",
      "interface_PINN =  0.020179784\n",
      "interface_Analytical =  0.027113926311030673\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08600000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.1380]])\n",
      "epoch =  0\n",
      "loss =  1.01437745e-05\n",
      "eq1_loss =  2.4022745e-06\n",
      "bc1_loss =  9.672263e-09\n",
      "bc2_loss =  7.731827e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.6643098e-07\n",
      "eq1_loss =  3.455908e-07\n",
      "bc1_loss =  9.520452e-09\n",
      "bc2_loss =  1.1319745e-08\n",
      "\n",
      "interface_PINN =  0.020295475\n",
      "interface_Analytical =  0.02727295363542426\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08700000000000006\n",
      " \n",
      "slope at interface =  tensor([[-23.0062]])\n",
      "epoch =  0\n",
      "loss =  9.909678e-06\n",
      "eq1_loss =  2.3341054e-06\n",
      "bc1_loss =  9.578699e-09\n",
      "bc2_loss =  7.5659937e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.5500986e-07\n",
      "eq1_loss =  3.3450212e-07\n",
      "bc1_loss =  9.289241e-09\n",
      "bc2_loss =  1.1218507e-08\n",
      "\n",
      "interface_PINN =  0.020410506\n",
      "interface_Analytical =  0.027431059038979914\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08800000000000006\n",
      " \n",
      "slope at interface =  tensor([[-22.8764]])\n",
      "epoch =  0\n",
      "loss =  9.680218e-06\n",
      "eq1_loss =  2.2715187e-06\n",
      "bc1_loss =  9.335256e-09\n",
      "bc2_loss =  7.3993638e-06\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  2000\n",
      "loss =  3.4580103e-07\n",
      "eq1_loss =  3.2542283e-07\n",
      "bc1_loss =  9.197553e-09\n",
      "bc2_loss =  1.118066e-08\n",
      "\n",
      "interface_PINN =  0.020524887\n",
      "interface_Analytical =  0.027588258371995893\n",
      "broke inner loop\n",
      "\n",
      "t =  0.08900000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.7486]])\n",
      "epoch =  0\n",
      "loss =  9.51041e-06\n",
      "eq1_loss =  2.262556e-06\n",
      "bc1_loss =  9.094947e-09\n",
      "bc2_loss =  7.2387584e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.426489e-07\n",
      "eq1_loss =  3.2361856e-07\n",
      "bc1_loss =  8.835347e-09\n",
      "bc2_loss =  1.0194995e-08\n",
      "\n",
      "interface_PINN =  0.02063863\n",
      "interface_Analytical =  0.027744567035727943\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09000000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.6229]])\n",
      "epoch =  0\n",
      "loss =  9.265826e-06\n",
      "eq1_loss =  2.1954943e-06\n",
      "bc1_loss =  8.801763e-09\n",
      "bc2_loss =  7.0615297e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.3154072e-07\n",
      "eq1_loss =  3.126063e-07\n",
      "bc1_loss =  8.679169e-09\n",
      "bc2_loss =  1.0255267e-08\n",
      "\n",
      "interface_PINN =  0.020751745\n",
      "interface_Analytical =  0.027900000000000025\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09100000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.4998]])\n",
      "epoch =  0\n",
      "loss =  9.06203e-06\n",
      "eq1_loss =  2.135545e-06\n",
      "bc1_loss =  8.668067e-09\n",
      "bc2_loss =  6.9178163e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.209762e-07\n",
      "eq1_loss =  3.0238283e-07\n",
      "bc1_loss =  8.458475e-09\n",
      "bc2_loss =  1.0134901e-08\n",
      "\n",
      "interface_PINN =  0.020864243\n",
      "interface_Analytical =  0.02805457181993697\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09200000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.3784]])\n",
      "epoch =  0\n",
      "loss =  8.861344e-06\n",
      "eq1_loss =  2.0800978e-06\n",
      "bc1_loss =  8.458475e-09\n",
      "bc2_loss =  6.772788e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.1205275e-07\n",
      "eq1_loss =  2.9372856e-07\n",
      "bc1_loss =  8.273119e-09\n",
      "bc2_loss =  1.00510675e-08\n",
      "\n",
      "interface_PINN =  0.020976136\n",
      "interface_Analytical =  0.028208296651871797\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09300000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.2588]])\n",
      "epoch =  0\n",
      "loss =  8.669963e-06\n",
      "eq1_loss =  2.0284033e-06\n",
      "bc1_loss =  8.273119e-09\n",
      "bc2_loss =  6.6332864e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.0496506e-07\n",
      "eq1_loss =  2.8706685e-07\n",
      "bc1_loss =  8.025612e-09\n",
      "bc2_loss =  9.872597e-09\n",
      "\n",
      "interface_PINN =  0.02108743\n",
      "interface_Analytical =  0.028361188268477076\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09400000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.1411]])\n",
      "epoch =  0\n",
      "loss =  8.531584e-06\n",
      "eq1_loss =  2.0235386e-06\n",
      "bc1_loss =  8.2514475e-09\n",
      "bc2_loss =  6.4997944e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  3.030238e-07\n",
      "eq1_loss =  2.8594053e-07\n",
      "bc1_loss =  7.908568e-09\n",
      "bc2_loss =  9.174702e-09\n",
      "\n",
      "interface_PINN =  0.021198135\n",
      "interface_Analytical =  0.02851326007316599\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09500000000000007\n",
      " \n",
      "slope at interface =  tensor([[-22.0249]])\n",
      "epoch =  0\n",
      "loss =  8.319936e-06\n",
      "eq1_loss =  1.968505e-06\n",
      "bc1_loss =  7.813444e-09\n",
      "bc2_loss =  6.3436173e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.9312466e-07\n",
      "eq1_loss =  2.7639717e-07\n",
      "bc1_loss =  7.666618e-09\n",
      "bc2_loss =  9.060873e-09\n",
      "\n",
      "interface_PINN =  0.02130826\n",
      "interface_Analytical =  0.028664525113805774\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09600000000000007\n",
      " \n",
      "slope at interface =  tensor([[-21.9113]])\n",
      "epoch =  0\n",
      "loss =  8.146659e-06\n",
      "eq1_loss =  1.918092e-06\n",
      "bc1_loss =  7.750348e-09\n",
      "bc2_loss =  6.220816e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.8424574e-07\n",
      "eq1_loss =  2.6773068e-07\n",
      "bc1_loss =  7.510849e-09\n",
      "bc2_loss =  9.004225e-09\n",
      "\n",
      "interface_PINN =  0.021417817\n",
      "interface_Analytical =  0.028814996095783214\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09700000000000007\n",
      " \n",
      "slope at interface =  tensor([[-21.7991]])\n",
      "epoch =  0\n",
      "loss =  7.978343e-06\n",
      "eq1_loss =  1.8711563e-06\n",
      "bc1_loss =  7.677059e-09\n",
      "bc2_loss =  6.0995094e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.76635e-07\n",
      "eq1_loss =  2.602034e-07\n",
      "bc1_loss =  7.438704e-09\n",
      "bc2_loss =  8.992917e-09\n",
      "\n",
      "interface_PINN =  0.021526814\n",
      "interface_Analytical =  0.02896468539445926\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09800000000000007\n",
      " \n",
      "slope at interface =  tensor([[-21.6885]])\n",
      "epoch =  0\n",
      "loss =  7.810209e-06\n",
      "eq1_loss =  1.8272136e-06\n",
      "bc1_loss =  7.387385e-09\n",
      "bc2_loss =  5.975608e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.697579e-07\n",
      "eq1_loss =  2.5365654e-07\n",
      "bc1_loss =  7.254787e-09\n",
      "bc2_loss =  8.8465555e-09\n",
      "\n",
      "interface_PINN =  0.021635257\n",
      "interface_Analytical =  0.029113605067047296\n",
      "broke inner loop\n",
      "\n",
      "t =  0.09900000000000007\n",
      " \n",
      "slope at interface =  tensor([[-21.5796]])\n",
      "epoch =  0\n",
      "loss =  7.653916e-06\n",
      "eq1_loss =  1.7855544e-06\n",
      "bc1_loss =  7.305644e-09\n",
      "bc2_loss =  5.8610563e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.6443493e-07\n",
      "eq1_loss =  2.4846838e-07\n",
      "bc1_loss =  7.1536057e-09\n",
      "bc2_loss =  8.81295e-09\n",
      "\n",
      "interface_PINN =  0.021743154\n",
      "interface_Analytical =  0.029261766863947263\n",
      "broke inner loop\n",
      "\n",
      "t =  0.10000000000000007\n",
      " \n",
      "slope at interface =  tensor([[-21.4722]])\n",
      "epoch =  0\n",
      "loss =  7.536163e-06\n",
      "eq1_loss =  1.7843146e-06\n",
      "bc1_loss =  7.093238e-09\n",
      "bc2_loss =  5.7447555e-06\n",
      "\n",
      "epoch =  2000\n",
      "loss =  2.6277422e-07\n",
      "eq1_loss =  2.479172e-07\n",
      "bc1_loss =  6.874078e-09\n",
      "bc2_loss =  7.982951e-09\n",
      "\n",
      "interface_PINN =  0.021850515\n",
      "interface_Analytical =  0.029409182239565956\n",
      "broke inner loop\n",
      "\n",
      "time elapsed =  2756.685474395752\n"
     ]
    }
   ],
   "source": [
    "N_x = 3001\n",
    "N_bc = 30\n",
    "N_t = 100\n",
    "del_t = 0.001\n",
    "x_l = 0\n",
    "x_r = 0.28\n",
    "T_r = 0\n",
    "T_l = 0.5\n",
    "t_i = 0\n",
    "accuracy_cap = 0.00035\n",
    "N_x_test = 251\n",
    "s_initial = 0.0015\n",
    "\n",
    "# Neural network params\n",
    "layer_size = [1, 3, 3, 3, 1]\n",
    "\n",
    "# material params\n",
    "k1 = 0.01\n",
    "k2 = 0.005\n",
    "\n",
    "# Training data and initial data\n",
    "model = ANN(layer_size)\n",
    "print(model)\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total trainable parameters in the model:\", total_trainable_params)\n",
    "\n",
    "# # Setup Loss function and Optimiser\n",
    "lr = 1e-4\n",
    "epochs = 50001\n",
    "optimiser1 = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training model\n",
    "start = time.time()\n",
    "loss_store, T_store_pred, T_store_an, x_test_np, s_pred, s_an, t = train_model(model, optimiser1, epochs, T_r, T_l, k1, k2, N_x, x_l, x_r, N_t, N_bc, accuracy_cap, N_x_test, del_t, s_initial)\n",
    "end = time.time()\n",
    "time_elapsed = end - start\n",
    "print(\"time elapsed = \", time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb512346",
   "metadata": {},
   "source": [
    "# Results Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6502e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 30\n",
    "i = 0\n",
    "k = 201\n",
    "\n",
    "plt.plot(x_test_np[i:k].detach().numpy(), T_store_pred[j][i:k])\n",
    "plt.plot(x_test_np[i:k].detach().numpy(), T_store_an[j-1][i:k])\n",
    "Title = \"Stefan 1-phase using Time stepping, \" + \"time = \" + str((j+1)*del_t) + \", delta_t = \" + str(del_t)\n",
    "plt.title(Title)\n",
    "plt.legend([\"PINN\", \"Analytical\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4b708d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp = []\n",
    "for i in range(len(s_pred)):\n",
    "    tp.append(s_pred[i][0])\n",
    "\n",
    "i = 0\n",
    "j = 100\n",
    "plt.plot(t[i:j], tp[i:j])\n",
    "plt.plot(t[i:j], s_an[i:j])\n",
    "plt.legend([\"PINN\", \"Analytical\"])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Interface position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7028ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.002940918223956595,\n",
       " 0.004159086438149612,\n",
       " 0.005093819784798048,\n",
       " 0.00588183644791319,\n",
       " 0.006576093065034897,\n",
       " 0.0072037490239458,\n",
       " 0.007780938246766908,\n",
       " 0.008318172876299225,\n",
       " 0.008822754671869784,\n",
       " 0.009300000000000006,\n",
       " 0.009753922287982417,\n",
       " 0.010187639569596098,\n",
       " 0.010603631453421993,\n",
       " 0.011003908396565296,\n",
       " 0.011390127303941788,\n",
       " 0.011763672895826381,\n",
       " 0.012125716473676938,\n",
       " 0.012477259314448838,\n",
       " 0.012819165339443918,\n",
       " 0.013152186130069797,\n",
       " 0.01347698037395619,\n",
       " 0.013794129185997947,\n",
       " 0.014104148325935897,\n",
       " 0.014407498047891605,\n",
       " 0.014704591119782978,\n",
       " 0.014995799411835315,\n",
       " 0.015281459354394148,\n",
       " 0.01556187649353382,\n",
       " 0.01583732932031157,\n",
       " 0.016108072510390575,\n",
       " 0.016374339681342897,\n",
       " 0.016636345752598453,\n",
       " 0.01689428897586402,\n",
       " 0.017148352690564788,\n",
       " 0.017398706848498847,\n",
       " 0.017645509343739575,\n",
       " 0.01788890717735437,\n",
       " 0.01812903748134469,\n",
       " 0.01836602842206231,\n",
       " 0.01860000000000002,\n",
       " 0.018831064760124448,\n",
       " 0.019059328424684874,\n",
       " 0.0192848904585948,\n",
       " 0.01950784457596484,\n",
       " 0.019728279195104698,\n",
       " 0.019946277848260332,\n",
       " 0.020161919551471303,\n",
       " 0.0203752791391922,\n",
       " 0.020586427567696172,\n",
       " 0.020795432190748066,\n",
       " 0.02100235701058338,\n",
       " 0.021207262906843986,\n",
       " 0.02141020784579171,\n",
       " 0.02161124707183741,\n",
       " 0.02181043328317897,\n",
       " 0.022007816793130595,\n",
       " 0.0222034456785428,\n",
       " 0.022397365916553693,\n",
       " 0.022589621510773508,\n",
       " 0.02278025460788358,\n",
       " 0.022969305605524976,\n",
       " 0.023156813252259066,\n",
       " 0.02334281474030073,\n",
       " 0.02352734579165277,\n",
       " 0.02371044073820647,\n",
       " 0.023892132596317162,\n",
       " 0.024072453136313326,\n",
       " 0.024251432947353876,\n",
       " 0.024429101498008504,\n",
       " 0.024605487192900715,\n",
       " 0.024780617425722087,\n",
       " 0.02495451862889768,\n",
       " 0.025127216320157734,\n",
       " 0.02529873514624795,\n",
       " 0.02546909892399025,\n",
       " 0.02563833067888784,\n",
       " 0.025806452681451618,\n",
       " 0.025973486481410256,\n",
       " 0.02613945293995269,\n",
       " 0.026304372260139593,\n",
       " 0.026468264015609363,\n",
       " 0.026631147177694044,\n",
       " 0.026793040141051584,\n",
       " 0.026953960747912384,\n",
       " 0.027113926311030673,\n",
       " 0.02727295363542426,\n",
       " 0.027431059038979914,\n",
       " 0.027588258371995893,\n",
       " 0.027744567035727943,\n",
       " 0.027900000000000025,\n",
       " 0.02805457181993697,\n",
       " 0.028208296651871797,\n",
       " 0.028361188268477076,\n",
       " 0.02851326007316599,\n",
       " 0.028664525113805774,\n",
       " 0.028814996095783214,\n",
       " 0.02896468539445926,\n",
       " 0.029113605067047296,\n",
       " 0.029261766863947263,\n",
       " 0.029409182239565956]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d752a714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.0015], dtype=float32),\n",
       " array([0.00316667], dtype=float32),\n",
       " array([0.00395654], dtype=float32),\n",
       " array([0.00455113], dtype=float32),\n",
       " array([0.0050664], dtype=float32),\n",
       " array([0.00552857], dtype=float32),\n",
       " array([0.00595152], dtype=float32),\n",
       " array([0.00634389], dtype=float32),\n",
       " array([0.0067117], dtype=float32),\n",
       " array([0.00705926], dtype=float32),\n",
       " array([0.00738972], dtype=float32),\n",
       " array([0.00770549], dtype=float32),\n",
       " array([0.00800833], dtype=float32),\n",
       " array([0.00829971], dtype=float32),\n",
       " array([0.00858088], dtype=float32),\n",
       " array([0.00885285], dtype=float32),\n",
       " array([0.00911648], dtype=float32),\n",
       " array([0.00937252], dtype=float32),\n",
       " array([0.00962161], dtype=float32),\n",
       " array([0.00986429], dtype=float32),\n",
       " array([0.010101], dtype=float32),\n",
       " array([0.01033217], dtype=float32),\n",
       " array([0.01055818], dtype=float32),\n",
       " array([0.01077937], dtype=float32),\n",
       " array([0.01099602], dtype=float32),\n",
       " array([0.0112084], dtype=float32),\n",
       " array([0.01141677], dtype=float32),\n",
       " array([0.01162134], dtype=float32),\n",
       " array([0.01182232], dtype=float32),\n",
       " array([0.01201987], dtype=float32),\n",
       " array([0.01221417], dtype=float32),\n",
       " array([0.01240537], dtype=float32),\n",
       " array([0.01259363], dtype=float32),\n",
       " array([0.01277906], dtype=float32),\n",
       " array([0.01296181], dtype=float32),\n",
       " array([0.01314197], dtype=float32),\n",
       " array([0.01331967], dtype=float32),\n",
       " array([0.013495], dtype=float32),\n",
       " array([0.01366805], dtype=float32),\n",
       " array([0.01383891], dtype=float32),\n",
       " array([0.01400767], dtype=float32),\n",
       " array([0.01417441], dtype=float32),\n",
       " array([0.01433918], dtype=float32),\n",
       " array([0.01450204], dtype=float32),\n",
       " array([0.01466308], dtype=float32),\n",
       " array([0.01482235], dtype=float32),\n",
       " array([0.01497991], dtype=float32),\n",
       " array([0.01513581], dtype=float32),\n",
       " array([0.0152901], dtype=float32),\n",
       " array([0.01544284], dtype=float32),\n",
       " array([0.01559405], dtype=float32),\n",
       " array([0.01574381], dtype=float32),\n",
       " array([0.01589214], dtype=float32),\n",
       " array([0.01603908], dtype=float32),\n",
       " array([0.01618467], dtype=float32),\n",
       " array([0.01632895], dtype=float32),\n",
       " array([0.01647195], dtype=float32),\n",
       " array([0.01661371], dtype=float32),\n",
       " array([0.01675426], dtype=float32),\n",
       " array([0.01689364], dtype=float32),\n",
       " array([0.01703186], dtype=float32),\n",
       " array([0.01716896], dtype=float32),\n",
       " array([0.01730497], dtype=float32),\n",
       " array([0.0174399], dtype=float32),\n",
       " array([0.01757378], dtype=float32),\n",
       " array([0.01770665], dtype=float32),\n",
       " array([0.01783851], dtype=float32),\n",
       " array([0.0179694], dtype=float32),\n",
       " array([0.01809934], dtype=float32),\n",
       " array([0.01822834], dtype=float32),\n",
       " array([0.01835643], dtype=float32),\n",
       " array([0.01848363], dtype=float32),\n",
       " array([0.01860994], dtype=float32),\n",
       " array([0.01873541], dtype=float32),\n",
       " array([0.01886003], dtype=float32),\n",
       " array([0.01898383], dtype=float32),\n",
       " array([0.01910682], dtype=float32),\n",
       " array([0.01922902], dtype=float32),\n",
       " array([0.01935043], dtype=float32),\n",
       " array([0.01947109], dtype=float32),\n",
       " array([0.019591], dtype=float32),\n",
       " array([0.01971018], dtype=float32),\n",
       " array([0.01982863], dtype=float32),\n",
       " array([0.01994637], dtype=float32),\n",
       " array([0.02006342], dtype=float32),\n",
       " array([0.02017978], dtype=float32),\n",
       " array([0.02029547], dtype=float32),\n",
       " array([0.02041051], dtype=float32),\n",
       " array([0.02052489], dtype=float32),\n",
       " array([0.02063863], dtype=float32),\n",
       " array([0.02075174], dtype=float32),\n",
       " array([0.02086424], dtype=float32),\n",
       " array([0.02097614], dtype=float32),\n",
       " array([0.02108743], dtype=float32),\n",
       " array([0.02119813], dtype=float32),\n",
       " array([0.02130826], dtype=float32),\n",
       " array([0.02141782], dtype=float32),\n",
       " array([0.02152681], dtype=float32),\n",
       " array([0.02163526], dtype=float32),\n",
       " array([0.02174315], dtype=float32),\n",
       " array([0.02185052], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
